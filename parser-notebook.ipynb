{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating raw jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading raw json\n",
    "raw_json_file_names = []\n",
    "raw_jsons = []\n",
    "\n",
    "for file in os.listdir(\".\"):\n",
    "    if file.startswith(\"run_results_\"):\n",
    "        raw_json_file_names.append(file)\n",
    "        \n",
    "for file in raw_json_file_names:\n",
    "    with open(file,'r') as filestream:\n",
    "        raw_jsons.append(pd.read_json(filestream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnessasary stuff\n",
    "for json_table in raw_jsons:\n",
    "    del json_table['remove']\n",
    "    del json_table['listingValue']\n",
    "    json_table.columns = ['html']\n",
    "    json_table['html_str'] = json_table['html'].astype(str)\n",
    "    json_table = json_table.drop_duplicates(subset='html_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating jsons and removing duplicates\n",
    "json_all = raw_jsons[0]\n",
    "for json_table in raw_jsons[1:]:\n",
    "    json_all = pd.concat([json_all,json_table], axis=0, ignore_index=True)\n",
    "json_all = json_all.drop_duplicates(subset=\"html_str\")\n",
    "del json_all[\"html_str\"]\n",
    "json_all.reset_index(drop=True, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output raw json without duplicate as dataframe in pickle\n",
    "with open('raw_json_no_dups.json','w') as fout:\n",
    "    json_all.to_json(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting only user messages\n",
    "Also parsing links to message and authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add empty string in case of empty search\n",
    "link_search = lambda s: '' if s is None else s['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap user messages \n",
    "def scrapFromHTML(soup, row):\n",
    "    row['author'] = \"https://opendatascience.slack.com\" + link_search(soup.find(\"a\", class_=\"c-link c-message__sender_link\"))\n",
    "    row['link'] = link_search(soup.find(\"a\", class_=\"c-link c-timestamp c-timestamp--static\"))\n",
    "    tag = soup.find(\"span\", class_=\"c-message__body\")\n",
    "    if not tag is None:\n",
    "        row['message'] = tag.get_text(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load raw table\n",
    "with open('raw_json_no_dups.json','r') as fin:\n",
    "    html_table = pd.read_json(fin,compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add tables for future scrapped data\n",
    "html_table['author'] = \"\"\n",
    "html_table['link'] = \"\"\n",
    "html_table['message'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping of new information\n",
    "for i in html_table.index:\n",
    "    html_doc = html_table['html'][i]['name']\n",
    "    soup = BeautifulSoup(html_doc,'html5lib')\n",
    "    scrapFromHTML(soup, html_table.loc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy table without non-user messages\n",
    "html_table_usr_msg = html_table[html_table.author!=\"https://opendatascience.slack.com\"]\n",
    "html_table_usr_msg.reset_index(drop=True, inplace=True)\n",
    "del html_table_usr_msg['html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output user messages table\n",
    "with open(\"user_messages.json\",'w') as fout:\n",
    "    html_table_usr_msg.to_json(fout, compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting numbers out of text\n",
    "And removing messages without numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input user messages table\n",
    "with open(\"user_messages.json\",'r') as fin:\n",
    "    usr_msg = pd.read_json(fin, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_msg['numbers'] = usr_msg.apply(lambda x: [], axis=1)\n",
    "usr_msg['hasNumbers'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#scrapping numbers in messages\n",
    "for i in usr_msg.index:\n",
    "    msg = usr_msg['message'][i]\n",
    "    usr_msg['numbers'][i] = re.findall(r'[0-9]+', msg)\n",
    "    if usr_msg['numbers'][i]:\n",
    "        usr_msg['hasNumbers'][i] = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy table without only-word messages (other are candidates for having vacancy information)\n",
    "usr_msg_clear = usr_msg[usr_msg.hasNumbers]\n",
    "usr_msg_clear.reset_index(drop=True, inplace=True)\n",
    "del usr_msg_clear['hasNumbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output clear user messages table\n",
    "with open(\"user_messages_clear.json\",'w') as fout:\n",
    "    usr_msg_clear.to_json(fout, compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapDateTime(row, link):\n",
    "\n",
    "    usr = \"ksetherg@gmail.com\"\n",
    "    pwd = \"l'dbl1996\"\n",
    "\n",
    "    driver = webdriver.Chrome('/opt/chromedriver')\n",
    "    driver.get(link.replace('archives','messages'))\n",
    "\n",
    "    elem = driver.find_element_by_id(\"email\")\n",
    "    elem.send_keys(usr)\n",
    "    elem = driver.find_element_by_id(\"password\")\n",
    "    elem.send_keys(pwd)\n",
    "    elem.send_keys(Keys.RETURN)\n",
    "#    elem.send_keys(\"Posted using Python's Selenium WebDriver bindings!\")\n",
    "#    elem = driver.find_element_by_id(\"signin_btn\")\n",
    "#    elem.click()\n",
    "    time.sleep(10)\n",
    "\n",
    "    elem1 = driver.find_element_by_class_name('c-message_list__day_divider__label__pill')\n",
    "    row['date'] = elem1.text\n",
    "    elems = driver.find_elements_by_class_name('c-message__content_header')\n",
    "    for elem in elems:\n",
    "        if link in elem.get_attribute('innerHTML'):\n",
    "            row['time'] = re.search('data-stringify-suffix=\"]\"(.+?)</span>', elem.get_attribute('innerHTML')).group(1)\n",
    "\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input user messages table\n",
    "with open(\"user_messages_clear.json\",'r') as fin:\n",
    "    usr_msg_clear = pd.read_json(fin, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_msg_clear['date'] = ''\n",
    "usr_msg_clear['time'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-3d5e81e49051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musr_msg_clear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m      \u001b[0mscrapDateTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musr_msg_clear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musr_msg_clear\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-3bc50a6f83ee>\u001b[0m in \u001b[0;36mscrapDateTime\u001b[0;34m(row, link)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#    elem = driver.find_element_by_id(\"signin_btn\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#    elem.click()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0melem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c-message_list__day_divider__label__pill'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in usr_msg_clear.index:\n",
    "     scrapDateTime(usr_msg_clear.loc[i,:], usr_msg_clear['link'][i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlackUser:\n",
    "\n",
    "    def __init__(self, link='https://opendatascience.slack.com/archives/C04DA5FUF', filename='slack_dump.json'):\n",
    "        self.data = {}\n",
    "        self.channel_url = link\n",
    "        self.filename = filename\n",
    "\n",
    "        self._session: Optional[aiohttp.ClientSession] = None\n",
    "\n",
    "    @property\n",
    "    def session(self) -> aiohttp.ClientSession:\n",
    "        if self._session is None:\n",
    "            self._session = aiohttp.ClientSession()\n",
    "        return self._session\n",
    "\n",
    "    async def close(self):\n",
    "        if self._session is not None:\n",
    "            await self.session.close()\n",
    "\n",
    "    def dump_exist(self, filename: str = None):\n",
    "        return is_non_zero_file(filename or self.filename)\n",
    "\n",
    "    def load(self, filename: str = None):\n",
    "        with open(filename or self.filename, 'r', encoding='utf-8') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "    def dump(self, filename: str = None):\n",
    "        with open(filename or self.filename, 'w', encoding='utf-8') as file:\n",
    "            json.dump(self.data, file, indent=True, ensure_ascii=False)\n",
    "\n",
    "    async def request(self, url, method='GET', data=None, headers=None):\n",
    "        async with self.session.request(method, url, data=data, headers=headers) as response:\n",
    "            return await response.read()\n",
    "\n",
    "    async def authorization_on_slack(self, username, password):\n",
    "        login_url = self.channel_url\n",
    "        login_page = await self.request(login_url)\n",
    "        auth_token = BeautifulSoup(login_page, features='lxml').find('input', {'name': 'crumb'})['value']\n",
    "\n",
    "        data = {'_username': username, '_password': password, '_remember_me': 'on', 'crumb': auth_token}\n",
    "        headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "        await self.request(f'{self.lmsu_url}/login_check', method='POST', data=data, headers=headers)\n",
    "\n",
    "    async def scrap_user(self, user_id):\n",
    "        response = await self.request(f'{self.lmsu_url}/rus/user/achievement/user/{user_id}/list')\n",
    "        soup = BeautifulSoup(response, features=\"lxml\")\n",
    "        name_field = soup.find('h3', {'class': 'achievements-user__name'}) or \\\n",
    "        soup.find('a', {'class': 'user-block__link user-block__link--logged'})\n",
    "        user_data = {'name': name_field.text.strip(), 'achievements': []}\n",
    "        subsection(f'Processing user \\\"{user_data[\"name\"]}\\\"')\n",
    "        for achievement in soup.find_all(\"article\", {\"class\": \"achievement\"}):\n",
    "            curr_data = {\n",
    "                          'title': achievement.find(\"a\", {\"class\": \"achievement__link\"}).text.strip(),\n",
    "                          'category': achievement.find(\"p\", {\"class\": \"achievement__more\"}).text.strip(),\n",
    "                          'score': int(achievement.find(\"span\", {\"class\": \"ach-pill\"}).text),\n",
    "                          'checked': bool(achievement.find(\"input\", {\"checked\": \"checked\"})),\n",
    "                          'url': self.lmsu_url + achievement.find(\"a\", {\"class\": \"achievement__link\"})['href'],\n",
    "                          'date': '',\n",
    "                          'file': '',\n",
    "                          'comment': '',\n",
    "                          'comment_our': '',\n",
    "                        }\n",
    "            user_data['achievements'].append(curr_data)\n",
    "        return user_id, user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating raw jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading raw json\n",
    "raw_json_file_names = []\n",
    "raw_jsons = []\n",
    "\n",
    "for file in os.listdir(\".\"):\n",
    "    if file.startswith(\"run_results_\"):\n",
    "        raw_json_file_names.append(file)\n",
    "        \n",
    "for file in raw_json_file_names:\n",
    "    with open(file,'r') as filestream:\n",
    "        raw_jsons.append(pd.read_json(filestream))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnessasary stuff\n",
    "for json_table in raw_jsons:\n",
    "    del json_table['remove']\n",
    "    del json_table['listingValue']\n",
    "    json_table.columns = ['html']\n",
    "    json_table['html_str'] = json_table['html'].astype(str)\n",
    "    json_table = json_table.drop_duplicates(subset='html_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenating jsons and removing duplicates\n",
    "json_all = raw_jsons[0]\n",
    "for json_table in raw_jsons[1:]:\n",
    "    json_all = pd.concat([json_all,json_table], axis=0, ignore_index=True)\n",
    "json_all = json_all.drop_duplicates(subset=\"html_str\")\n",
    "del json_all[\"html_str\"]\n",
    "json_all.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output raw json without duplicate as dataframe in pickle\n",
    "with open('raw_json_no_dups.json','w') as fout:\n",
    "    json_all.to_json(fout,orient='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting only user messages\n",
    "Also parsing links to message and authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add empty string in case of empty search\n",
    "link_search = lambda s: '' if s is None else s['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrap user messages \n",
    "def scrapFromHTML(soup, row):\n",
    "    row['author'] = \"https://opendatascience.slack.com\" + link_search(soup.find(\"a\", class_=\"c-link c-message__sender_link\"))\n",
    "    row['link'] = link_search(soup.find(\"a\", class_=\"c-link c-timestamp c-timestamp--static\"))\n",
    "    tag = soup.find(\"span\", class_=\"c-message__body\")\n",
    "    if not tag is None:\n",
    "        row['message'] = tag.get_text(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load raw table\n",
    "with open('raw_json_no_dups.json','r') as fin:\n",
    "    html_table = pd.read_json(fin,compression=None,orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add tables for future scrapped data\n",
    "html_table['author'] = \"\"\n",
    "html_table['link'] = \"\"\n",
    "html_table['message'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping of new information\n",
    "for i in html_table.index:\n",
    "    html_doc = html_table['html'][i]['name']\n",
    "    soup = BeautifulSoup(html_doc,'html5lib')\n",
    "    scrapFromHTML(soup, html_table.loc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy table without non-user messages\n",
    "html_table_usr_msg = html_table[html_table.author!=\"https://opendatascience.slack.com\"]\n",
    "html_table_usr_msg.reset_index(drop=True, inplace=True)\n",
    "del html_table_usr_msg['html']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output user messages table\n",
    "with open(\"user_messages.json\",'w') as fout:\n",
    "    html_table_usr_msg.to_json(fout, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting numbers out of text\n",
    "And removing messages without numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input user messages table\n",
    "with open(\"user_messages.json\",'r') as fin:\n",
    "    usr_msg = pd.read_json(fin, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_msg['numbers'] = usr_msg.apply(lambda x: [], axis=1)\n",
    "usr_msg['hasNumbers'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#scrapping numbers in messages\n",
    "for i in usr_msg.index:\n",
    "    msg = usr_msg['message'][i]\n",
    "    usr_msg['numbers'][i] = re.findall(r'[0-9]+', msg)\n",
    "    if usr_msg['numbers'][i]:\n",
    "        usr_msg['hasNumbers'][i] = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy table without only-word messages (other are candidates for having vacancy information)\n",
    "usr_msg_clear = usr_msg[usr_msg.hasNumbers]\n",
    "usr_msg_clear.reset_index(drop=True, inplace=True)\n",
    "del usr_msg_clear['hasNumbers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output clear user messages table\n",
    "with open(\"user_messages_clear.json\",'w') as fout:\n",
    "    usr_msg_clear.to_json(fout, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing data and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapDateTime(row, link):\n",
    "\n",
    "    usr = \"ksetherg@gmail.com\"\n",
    "    pwd = \"l'dbl1996\"\n",
    "\n",
    "    options = webdriver.chrome.options.Options()\n",
    "    options.headless = True\n",
    "    \n",
    "    driver = webdriver.Chrome('/opt/chromedriver', options=options)\n",
    "    driver.get(link.replace('archives','messages'))\n",
    "\n",
    "    elem = driver.find_element_by_id(\"email\")\n",
    "    elem.send_keys(usr)\n",
    "    elem = driver.find_element_by_id(\"password\")\n",
    "    elem.send_keys(pwd)\n",
    "    elem.send_keys(Keys.RETURN)\n",
    "#    elem.send_keys(\"Posted using Python's Selenium WebDriver bindings!\")\n",
    "#    elem = driver.find_element_by_id(\"signin_btn\")\n",
    "#    elem.click()\n",
    "    try:\n",
    "        WebDriverWait(driver,15).until(\n",
    "             EC.presence_of_element_located((By.CLASS_NAME,'p-archives_banner')))\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        WebDriverWait(driver,5).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME,'c-message_list__day_divider__label__pill')))\n",
    "        elem1 = driver.find_element_by_class_name('c-message_list__day_divider__label__pill')\n",
    "        row['date'] = elem1.text\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except StaleElementReferenceException:\n",
    "        elem1 = driver.find_element_by_class_name('c-message_list__day_divider__label__pill')\n",
    "        row['date'] = elem1.text\n",
    "        \n",
    "    try:\n",
    "        WebDriverWait(driver,5).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME,'c-message__content_header')))\n",
    "        elems = driver.find_elements_by_class_name('c-message__content_header')\n",
    "        for elem in elems:\n",
    "            if link in elem.get_attribute('innerHTML'):\n",
    "                row['time'] = re.search('data-stringify-suffix=\"]\"(.+?)</span>', elem.get_attribute('innerHTML')).group(1)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except StaleElementReferenceException:\n",
    "        elems = driver.find_elements_by_class_name('c-message__content_header')\n",
    "        for elem in elems:\n",
    "            if link in elem.get_attribute('innerHTML'):\n",
    "                row['time'] = re.search('data-stringify-suffix=\"]\"(.+?)</span>', elem.get_attribute('innerHTML')).group(1)\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input user messages table\n",
    "with open(\"user_messages_clear.json\",'r') as fin:\n",
    "    usr_msg_clear = pd.read_json(fin, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_msg_clear['date'] = ''\n",
    "usr_msg_clear['time'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/244 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/244 [02:52<11:39:34, 172.73s/it]\u001b[A\n",
      "  1%|          | 2/244 [08:42<15:11:05, 225.89s/it]\u001b[A\n",
      "  1%|          | 3/244 [12:20<14:57:02, 223.33s/it]\u001b[A\n",
      "  2%|▏         | 4/244 [17:23<16:28:40, 247.17s/it]\u001b[AException in thread Thread-58:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-2416fdc9f08c>\", line 29, in scrapDateTime\n",
      "    elem1 = driver.find_element_by_class_name('c-message_list__day_divider__label__pill')\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 564, in find_element_by_class_name\n",
      "    return self.find_element(by=By.CLASS_NAME, value=name)\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"class name\",\"selector\":\"c-message_list__day_divider__label__pill\"}\n",
      "  (Session info: headless chrome=73.0.3683.75)\n",
      "  (Driver info: chromedriver=2.37.544315 (730aa6a5fdba159ac9f4c1e8cbc59bf1b5ce12b7),platform=Linux 5.1.0-parrot1-3t-amd64 x86_64)\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 5/244 [20:10<14:49:23, 223.28s/it]\u001b[AException in thread Thread-73:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-2416fdc9f08c>\", line 29, in scrapDateTime\n",
      "    elem1 = driver.find_element_by_class_name('c-message_list__day_divider__label__pill')\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 564, in find_element_by_class_name\n",
      "    return self.find_element(by=By.CLASS_NAME, value=name)\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"class name\",\"selector\":\"c-message_list__day_divider__label__pill\"}\n",
      "  (Session info: headless chrome=73.0.3683.75)\n",
      "  (Driver info: chromedriver=2.37.544315 (730aa6a5fdba159ac9f4c1e8cbc59bf1b5ce12b7),platform=Linux 5.1.0-parrot1-3t-amd64 x86_64)\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 6/244 [23:40<14:29:46, 219.27s/it]\u001b[A\n",
      "  3%|▎         | 7/244 [28:17<15:34:23, 236.56s/it]\u001b[AException in thread Thread-88:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-2416fdc9f08c>\", line 29, in scrapDateTime\n",
      "    elem1 = driver.find_element_by_class_name('c-message_list__day_divider__label__pill')\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 564, in find_element_by_class_name\n",
      "    return self.find_element(by=By.CLASS_NAME, value=name)\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"/home/rancher/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {\"method\":\"class name\",\"selector\":\"c-message_list__day_divider__label__pill\"}\n",
      "  (Session info: headless chrome=73.0.3683.75)\n",
      "  (Driver info: chromedriver=2.37.544315 (730aa6a5fdba159ac9f4c1e8cbc59bf1b5ce12b7),platform=Linux 5.1.0-parrot1-3t-amd64 x86_64)\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 8/244 [32:55<16:19:40, 249.07s/it]\u001b[A\n",
      "  4%|▎         | 9/244 [35:49<14:47:10, 226.51s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for i in tqdm(usr_msg_clear.index[::10]):\n",
    "    threads = []\n",
    "    for j in range(i,min(i + 10,usr_msg_clear.index[-1])):\n",
    "        thread = threading.Thread(target=scrapDateTime, args=[usr_msg_clear.loc[j,:], usr_msg_clear['link'][j]])\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usr_msg_clear['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlackUser:\n",
    "\n",
    "    def __init__(self, link='https://opendatascience.slack.com/archives/C04DA5FUF', filename='slack_dump.json'):\n",
    "        self.data = {}\n",
    "        self.channel_url = link\n",
    "        self.filename = filename\n",
    "\n",
    "        self._session: Optional[aiohttp.ClientSession] = None\n",
    "\n",
    "    @property\n",
    "    def session(self) -> aiohttp.ClientSession:\n",
    "        if self._session is None:\n",
    "            self._session = aiohttp.ClientSession()\n",
    "        return self._session\n",
    "\n",
    "    async def close(self):\n",
    "        if self._session is not None:\n",
    "            await self.session.close()\n",
    "\n",
    "    def dump_exist(self, filename: str = None):\n",
    "        return is_non_zero_file(filename or self.filename)\n",
    "\n",
    "    def load(self, filename: str = None):\n",
    "        with open(filename or self.filename, 'r', encoding='utf-8') as file:\n",
    "            self.data = json.load(file)\n",
    "\n",
    "    def dump(self, filename: str = None):\n",
    "        with open(filename or self.filename, 'w', encoding='utf-8') as file:\n",
    "            json.dump(self.data, file, indent=True, ensure_ascii=False)\n",
    "\n",
    "    async def request(self, url, method='GET', data=None, headers=None):\n",
    "        async with self.session.request(method, url, data=data, headers=headers) as response:\n",
    "            return await response.read()\n",
    "\n",
    "    async def authorization_on_slack(self, username, password):\n",
    "        login_url = self.channel_url\n",
    "        login_page = await self.request(login_url)\n",
    "        auth_token = BeautifulSoup(login_page, features='lxml').find('input', {'name': 'crumb'})['value']\n",
    "\n",
    "        data = {'_username': username, '_password': password, '_remember_me': 'on', 'crumb': auth_token}\n",
    "        headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "        await self.request(f'{self.lmsu_url}/login_check', method='POST', data=data, headers=headers)\n",
    "\n",
    "    async def scrap_user(self, user_id):\n",
    "        response = await self.request(f'{self.lmsu_url}/rus/user/achievement/user/{user_id}/list')\n",
    "        soup = BeautifulSoup(response, features=\"lxml\")\n",
    "        name_field = soup.find('h3', {'class': 'achievements-user__name'}) or \\\n",
    "        soup.find('a', {'class': 'user-block__link user-block__link--logged'})\n",
    "        user_data = {'name': name_field.text.strip(), 'achievements': []}\n",
    "        subsection(f'Processing user \\\"{user_data[\"name\"]}\\\"')\n",
    "        for achievement in soup.find_all(\"article\", {\"class\": \"achievement\"}):\n",
    "            curr_data = {\n",
    "                          'title': achievement.find(\"a\", {\"class\": \"achievement__link\"}).text.strip(),\n",
    "                          'category': achievement.find(\"p\", {\"class\": \"achievement__more\"}).text.strip(),\n",
    "                          'score': int(achievement.find(\"span\", {\"class\": \"ach-pill\"}).text),\n",
    "                          'checked': bool(achievement.find(\"input\", {\"checked\": \"checked\"})),\n",
    "                          'url': self.lmsu_url + achievement.find(\"a\", {\"class\": \"achievement__link\"})['href'],\n",
    "                          'date': '',\n",
    "                          'file': '',\n",
    "                          'comment': '',\n",
    "                          'comment_our': '',\n",
    "                        }\n",
    "            user_data['achievements'].append(curr_data)\n",
    "        return user_id, user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing amount of lines and numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines(x):\n",
    "    return sum([1 for i in x.splitlines() if i.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numbers(x):\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_messages_clear_w_dt.json\",'r') as fout:\n",
    "    msg_dt = pd.read_json(fout, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(msg_dt['message'].apply(np.vectorize(count_lines))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(msg_dt['numbers'].apply(count_numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking data with key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_key_words(x, numbers, key_words):\n",
    "    for key in key_words:\n",
    "        key_found = re.search(key, x, re.IGNORECASE)\n",
    "        if key_found:\n",
    "            for i, n in enumerate(numbers):\n",
    "                number_found = re.search(str(n), x[key_found.start():])\n",
    "                if number_found:\n",
    "                    if key_found.start() + number_found.end() < len(x):\n",
    "                        if not x[key_found.start() + number_found.end()].isdigit():\n",
    "                            if i + 1 < len(numbers):\n",
    "                                return (len(x[:key_found.start() + number_found.end()].splitlines()), n, numbers[i + 1] if (n < numbers[i + 1]) else n)\n",
    "                            else:\n",
    "                                return (len(x[:key_found.start() + number_found.end()].splitlines()), n, n)\n",
    "    return (None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_dt['salary_line'] = None\n",
    "msg_dt['up_fork'] = None\n",
    "msg_dt['low_fork'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = ['pay', 'fork', 'вилка', 'зп']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_vectorized = lambda x,y: search_by_key_words(x, y, key_words)\n",
    "#(msg_dt['salary_line'][0], msg_dt['low_fork'][0], msg_dt['up_fork'][0]) = search_vectorized(msg_dt['message'][0], msg_dt['numbers'][0])\n",
    "#(msg_dt['salary_line'], msg_dt['low_fork'], msg_dt['up_fork']) = np.vectorize(search_vectorized)(msg_dt['message'], msg_dt['numbers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(msg_dt.index):\n",
    "    (msg_dt['salary_line'][i], msg_dt['low_fork'][i], msg_dt['up_fork'][i]) = search_by_key_words(msg_dt['message'][i], msg_dt['numbers'][i], key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      salary_line  low_fork  up_fork\n",
      "0            51.0     100.0    250.0\n",
      "1            20.0     200.0    250.0\n",
      "2             7.0      50.0     70.0\n",
      "3             NaN       NaN      NaN\n",
      "4             NaN       NaN      NaN\n",
      "5             NaN       NaN      NaN\n",
      "6            10.0     200.0    200.0\n",
      "7            27.0      70.0     90.0\n",
      "8            44.0      70.0    110.0\n",
      "9            13.0     150.0    300.0\n",
      "10            NaN       NaN      NaN\n",
      "11           17.0     150.0     80.0\n",
      "12           36.0     140.0    160.0\n",
      "13           43.0     100.0      0.0\n",
      "14            9.0     100.0      0.0\n",
      "15            NaN       NaN      NaN\n",
      "16           26.0    2500.0   4500.0\n",
      "17           26.0      80.0    120.0\n",
      "18           50.0     250.0    300.0\n",
      "19            4.0     130.0    170.0\n",
      "20            7.0     480.0    510.0\n",
      "21            8.0     160.0      0.0\n",
      "22            4.0     130.0    170.0\n",
      "23            NaN       NaN      NaN\n",
      "24            6.0     100.0    140.0\n",
      "25            NaN       NaN      NaN\n",
      "26           35.0    4000.0   5000.0\n",
      "27            7.0     130.0    230.0\n",
      "28            NaN       NaN      NaN\n",
      "29           50.0     100.0    150.0\n",
      "...           ...       ...      ...\n",
      "2402          NaN       NaN      NaN\n",
      "2403          NaN       NaN      NaN\n",
      "2404          NaN       NaN      NaN\n",
      "2405         14.0      90.0    160.0\n",
      "2406          NaN       NaN      NaN\n",
      "2407          NaN       NaN      NaN\n",
      "2408          NaN       NaN      NaN\n",
      "2409          NaN       NaN      NaN\n",
      "2410          NaN       NaN      NaN\n",
      "2411          NaN       NaN      NaN\n",
      "2412          NaN       NaN      NaN\n",
      "2413         11.0    1000.0   5000.0\n",
      "2414          NaN       NaN      NaN\n",
      "2415          NaN       NaN      NaN\n",
      "2416          NaN       NaN      NaN\n",
      "2417          NaN       NaN      NaN\n",
      "2418          NaN       NaN      NaN\n",
      "2419          NaN       NaN      NaN\n",
      "2420          NaN       NaN      NaN\n",
      "2421          NaN       NaN      NaN\n",
      "2422          NaN       NaN      NaN\n",
      "2423          NaN       NaN      NaN\n",
      "2424          NaN       NaN      NaN\n",
      "2425         71.0      60.0     80.0\n",
      "2426          NaN       NaN      NaN\n",
      "2427         24.0      80.0    150.0\n",
      "2428          NaN       NaN      NaN\n",
      "2429          NaN       NaN      NaN\n",
      "2430         14.0     200.0    200.0\n",
      "2431         33.0      60.0     40.0\n",
      "\n",
      "[2431 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(msg_dt[['salary_line', 'low_fork', 'up_fork']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_messages_clear_w_dt.json\",'w') as fout:\n",
    "    msg_dt.to_json(fout, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying training examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_messages_clear_w_dt.json\",'r') as fout:\n",
    "    msg_dt = pd.read_json(fout, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_dt_true = msg_dt.loc[msg_dt['salary_line'].notnull()]\n",
    "msg_dt_true.reset_index(inplace=True)\n",
    "msg_dt_true = msg_dt_true.sample(100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_check(msg):\n",
    "    print()\n",
    "    lines = msg['message'].splitlines()\n",
    "    for n, line in enumerate(lines):\n",
    "        print(\"{} {}\".format(n, line))\n",
    "    print('Is message a vacancy post? (y/n)')\n",
    "    c = input()\n",
    "    if c == 'y':\n",
    "        print('Input a number of salary line:')\n",
    "        msg.loc['salary_line'] = int(input())\n",
    "        print('Input down salary value:')\n",
    "        msg.loc['low_fork'] = float(input())\n",
    "        print('Input top salary value:')\n",
    "        msg.loc['up_fork'] = float(input())\n",
    "        #return False\n",
    "    #return True\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 Всем привет, разыскиваю коллегу\n",
      "1 Позиция\n",
      "2 : \n",
      "3 Machine Learning Engineer\n",
      "4  в Must (\n",
      "5 https://mustapp.com/\n",
      "6 )\n",
      "7 Условия\n",
      "8 : 100 - 150 тыс net, удаленно\n",
      "9 О нас\n",
      "10 Must - это небольшая команда творческих, профессиональных и влюбленных в свое дело людей. Наш продукт начался с простой записной книжки фильмов, а сейчас у нас полноценная социальная сеть с фоловингом, друзьями, нотификациями, покупкой билетов и прочими интересными штуками.\n",
      "11 О задачах\n",
      "12 Мониторинг и имплементация решений в области персонализации. Конкретные кейсы:\n",
      "13 - рекомендации фильмов, сериалов, прочего контента\n",
      "14 - схожесть пользователя и фильма\n",
      "15 - поиск похожих фильмов и пользователей\n",
      "16 - анализ рецензий, трендовых тем и персон в киноиндустрии\n",
      "17 - проведение аб-тестов и оценка значимости результатов\n",
      "18 Также есть другие ml-задачи в других проектах команды.\n",
      "19 Отмечу, что в проде уже крутятся решения для персонализации, по этому с нуля продумывать ничего не придется и можно будет относительно быстро увидеть результаты своих трудов.\n",
      "20 О вас\n",
      "21 - знаете прикладную статистику и имеете практический опыт применения машинного обучения, глубокого обучения\n",
      "22 - не брезгаете feature engineering-ом\n",
      "23 - владеете ds стеком на питоне (pandas, numpy, tensorflow, pytorch, lightgbm, sklearn, etc)\n",
      "24 - приветствуется опыт работы с чем то из списка: sql, docker, git, gitlab-ci, asyncio, aiohttp, kafka, clickhouse\n",
      "25 Контакты\n",
      "26 Вопросы и резюме можно кидать мне в слак или на почту \n",
      "27 fahmedzade@mustapp.me\n",
      "28 , \n",
      "29 mprikazchikova@mustapp.me\n",
      "30  (Мария)\n",
      "31  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "8\n",
      "Input down salary value:\n",
      "100\n",
      "Input top salary value:\n",
      "150\n",
      "\n",
      "0 Всем привет, разыскиваю коллегу\n",
      "1 Позиция\n",
      "2 : \n",
      "3 Machine Learning Engineer\n",
      "4  в Must (\n",
      "5 https://mustapp.com/\n",
      "6 )\n",
      "7 Условия\n",
      "8 : 100 - 150 тыс net, удаленно\n",
      "9 О нас\n",
      "10 Must - это небольшая команда творческих, профессиональных и влюбленных в свое дело людей. Наш продукт начался с простой записной книжки фильмов, а сейчас у нас полноценная социальная сеть с фоловингом, друзьями, нотификациями, покупкой билетов и прочими интересными штуками.\n",
      "11 О задачах\n",
      "12 Мониторинг и имплементация решений в области персонализации. Конкретные кейсы:\n",
      "13 - рекомендации фильмов, сериалов, прочего контента\n",
      "14 - схожесть пользователя и фильма\n",
      "15 - поиск похожих фильмов и пользователей\n",
      "16 - анализ рецензий, трендовых тем и персон в киноиндустрии\n",
      "17 - проведение аб-тестов и оценка значимости результатов\n",
      "18 Также есть другие ml-задачи в других проектах команды.\n",
      "19 Отмечу, что в проде уже крутятся решения для персонализации, по этому с нуля продумывать ничего не придется и можно будет относительно быстро увидеть результаты своих трудов.\n",
      "20 О вас\n",
      "21 - знаете прикладную статистику и имеете практический опыт применения машинного обучения, глубокого обучения\n",
      "22 - не брезгаете feature engineering-ом\n",
      "23 - владеете ds стеком на питоне (pandas, numpy, tensorflow, pytorch, lightgbm, sklearn, etc)\n",
      "24 - приветствуется опыт работы с чем то из списка: sql, docker, git, gitlab-ci, asyncio, aiohttp, kafka, clickhouse\n",
      "25 Контакты\n",
      "26 Вопросы и резюме можно кидать мне в слак или на почту \n",
      "27 fahmedzade@mustapp.me\n",
      "28 , \n",
      "29 mprikazchikova@mustapp.me\n",
      "30  (Мария)\n",
      "31  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "8\n",
      "Input down salary value:\n",
      "100\n",
      "Input top salary value:\n",
      "150\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 3 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Data Scientist, B2B-Center\n",
      "1  130-180 тыс. руб. net\n",
      "2 Сейчас стоит задача разработки рекомендательной системы, так что ребята с \n",
      "3 #recommender_systems\n",
      "4  строго приветствуются.\n",
      "5 Так же, в будущем, есть чем заняться в улучшении поиска, прогнозировании оттока и других задачах\n",
      "6 Чем придется заниматься:\n",
      "7  \n",
      "8  \n",
      "9  \n",
      "10  \n",
      "11 - работать с большим количеством разнородых данных\n",
      "12  \n",
      "13  \n",
      "14  \n",
      "15  \n",
      "16 - решать задачи методами ML\n",
      "17  \n",
      "18  \n",
      "19  \n",
      "20  \n",
      "21 - придумывать новые факторы для улучшения существующих моделей\n",
      "22  \n",
      "23  \n",
      "24  \n",
      "25  \n",
      "26 - разрабатывать дизайн экспериментов и метрик для задач\n",
      "27  \n",
      "28  \n",
      "29  \n",
      "30  \n",
      "31 - объяснять полученные результаты с технической и бизнес сторон\n",
      "32 Требуется:\n",
      "33  \n",
      "34  \n",
      "35  \n",
      "36  \n",
      "37 - отличное знание теории вероятностей, математической статистики\n",
      "38  \n",
      "39  \n",
      "40  \n",
      "41  \n",
      "42 - уверенное знание Python, инструментов для работы с данными и ML из его экосистемы\n",
      "43  \n",
      "44  \n",
      "45  \n",
      "46  \n",
      "47 - опыт работы с Unix-like системами\n",
      "48  \n",
      "49  \n",
      "50  \n",
      "51  \n",
      "52 - опыт работы с СУБД\n",
      "53  \n",
      "54  \n",
      "55  \n",
      "56  \n",
      "57 - опыт применения алгоритмов ML, знать, как они устроены внутри, границы применимости ресурсоемкость, способы измерения качества\n",
      "58  \n",
      "59  \n",
      "60  \n",
      "61  \n",
      "62 - уметь проектировать, учить и писать оптимально, чтобы можно было встроить в production\n",
      "63 Будут плюсом: \n",
      "64  \n",
      "65  \n",
      "66  \n",
      "67  \n",
      "68 - образование по специальности Computer Science, ШАД\n",
      "69  \n",
      "70  \n",
      "71  \n",
      "72  \n",
      "73 - наличие научных публикаций в области ML\n",
      "74  \n",
      "75  \n",
      "76  \n",
      "77  \n",
      "78 - успешное участие в конкурсах по ML (Kaggle, KDD Cup и другие)\n",
      "79  \n",
      "80  \n",
      "81  \n",
      "82  \n",
      "83 - опыт руководства командой программистов-исследователей\n",
      "84  \n",
      "85  \n",
      "86  \n",
      "87  \n",
      "88 - опыт разработки рекомендательной систем\n",
      "89  \n",
      "90  \n",
      "91  \n",
      "92  \n",
      "93 - умение работать с графовыми структурами данных\n",
      "94 Пишите на почту:\n",
      "95 a.shuvalova@b2b-center.ru\n",
      "96 Вакансия на HH\n",
      "97 https://hh.ru/vacancy/20031419\n",
      "98  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "1\n",
      "Input down salary value:\n",
      "130\n",
      "Input top salary value:\n",
      "180\n",
      "\n",
      "0 https://www.uber.com/jobs/60031\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 12 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Head of Data Science\n",
      "1 Company: \n",
      "2 BIG Loyalty\n",
      "3   \n",
      "4 airasiabig.com\n",
      "5 Kuala Lumpur, Malaysia\n",
      "6 We are looking for a Head of Data Scientist that will help us to discover the information hidden in vast amounts of data to help us make smarter decisions and deliver better products. The primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our products ie: automate scoring system using machine learning techniques, route recommendation engine, automate internal A/B testing procedures, member point auto reward model, fraud detection etc.\n",
      "7 Responsibilities\n",
      "8 • \n",
      "9  \n",
      "10  \n",
      "11  \n",
      "12 Translate & implement company strategy through data science/machine learning project\n",
      "13 • \n",
      "14  \n",
      "15  \n",
      "16  \n",
      "17 Define the objective and scope of the machine learning\n",
      "18 • \n",
      "19  \n",
      "20  \n",
      "21  \n",
      "22 Data preparation which include processing, cleansing, and verifying the integrity of data used for analysis\n",
      "23 • \n",
      "24  \n",
      "25  \n",
      "26  \n",
      "27 Selecting features, building and optimizing classifiers using machine learning techniques\n",
      "28 • \n",
      "29  \n",
      "30  \n",
      "31  \n",
      "32 Develop and be the custodian for smart features factory\n",
      "33 • \n",
      "34  \n",
      "35  \n",
      "36  \n",
      "37 Applied various modelling technique using state-of-the-art methods to achieve optimal result\n",
      "38 • \n",
      "39  \n",
      "40  \n",
      "41  \n",
      "42 Evaluate machine learning performance in term of accuracy and ROI\n",
      "43 • \n",
      "44  \n",
      "45  \n",
      "46  \n",
      "47 Monthly model monitoring, refresh or rebuild the model when the model performance has deteriorated\n",
      "48 • \n",
      "49  \n",
      "50  \n",
      "51  \n",
      "52 Extending company’s data with third party sources of information when needed\n",
      "53 • \n",
      "54  \n",
      "55  \n",
      "56  \n",
      "57 Enhancing data collection procedures to include information that is relevant for building analytic systems\n",
      "58 • \n",
      "59  \n",
      "60  \n",
      "61  \n",
      "62 Performing strategic and tactical analysis and presenting results in a clear and easy to understand manner\n",
      "63 • \n",
      "64  \n",
      "65  \n",
      "66  \n",
      "67 Creating automated anomaly detection systems and constant tracking of its performance\n",
      "68 • \n",
      "69  \n",
      "70  \n",
      "71  \n",
      "72 Lead, manage and develop the department to ensure it achieves the highest possible standards of excellence in all its activities\n",
      "73 Requirements\n",
      "74 • \n",
      "75  \n",
      "76  \n",
      "77  \n",
      "78 Degree in a field such as Computer Science, Computer Engineer, Statistic, Applied Statistics, Actuarial, AI, Data Science, Mathematics or relevant\n",
      "79 • \n",
      "80  \n",
      "81  \n",
      "82  \n",
      "83 10 years or more of experience with real data. Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\n",
      "84 • \n",
      "85  \n",
      "86  \n",
      "87  \n",
      "88 A minimum of years of responsible leadership experiences in management or supervisory positions\n",
      "89 • \n",
      "90  \n",
      "91  \n",
      "92  \n",
      "93 Experience with common data science toolkits, such as R, Python, Tensor Flow, Keras, NumPy, MatLab, SPSS, SAS etc. Excellence in at least one of these is highly desirable\n",
      "94 • \n",
      "95  \n",
      "96  \n",
      "97  \n",
      "98 Great data visualization, presentation and story-telling skills\n",
      "99 • \n",
      "100  \n",
      "101  \n",
      "102  \n",
      "103 Experience with data visualisation tools, such as D3.js, GGplot, Power BI, Google Data Studio, Tableau, Qlikview etc\n",
      "104 • \n",
      "105  \n",
      "106  \n",
      "107  \n",
      "108 Proficiency in using query languages such as SQL (MS SQL, MySQL, Postgres), HQL, Hive, Pig, Spark etc\n",
      "109 • \n",
      "110  \n",
      "111  \n",
      "112  \n",
      "113 Experience with NoSQL databases, such as MongoDB, Cassandra, HBase\n",
      "114 • \n",
      "115  \n",
      "116  \n",
      "117  \n",
      "118 Good applied statistics skills, such as distributions, statistical testing, regression, etc.\n",
      "119 • \n",
      "120  \n",
      "121  \n",
      "122  \n",
      "123 Data-oriented personality\n",
      "124 • \n",
      "125  \n",
      "126  \n",
      "127  \n",
      "128 Experience in Loyalty Program is an advantage\n",
      "129 • \n",
      "130  \n",
      "131  \n",
      "132  \n",
      "133 Machine Learning and Statistics is fundamental, experience in AI is an advantage\n",
      "134 • \n",
      "135  \n",
      "136  \n",
      "137  \n",
      "138 Excellent English communication skills\n",
      "139 Salary range\n",
      "140  20-25k MYR gross + bonuses\n",
      "141 Contact: you can ask me any questions here; send your CVs to \n",
      "142 recruitment@airasiabig.com\n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "140\n",
      "Input down salary value:\n",
      "20\n",
      "Input top salary value:\n",
      "25\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 https://podolsk.hh.ru/vacancy/19667100\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Я уже здесь размещал пару-тройку месяцев назад подобный job offer. Опыт оказался положительным, несмотря на баны и занимательные дискуссии. Поэтому опять размещаюсь здесь, предвкушая новый троллинг, баны, и в конечном итоге нахождение нужного человека :))\n",
      "1 Наш стартап занимается “оцифровкой” мирового рынка предметов питания и созданием на этой основе ряда приложений для потребителей и производителей/поставщиков ( модель “B2B2C”).\n",
      "2 Наша конечная цель - дать потребителям из любой части света инструмент, позволяющий без усилий и знания диетологии выбирать из всего многообразия предложения именно те продукты, которые наиболее подходят для конкретного человека согласно его образу жизни, физической активности, вкусовым предпочтениям, особенностям ДНК и пр. \n",
      "3 Мы разрабатываем инструмент,который позволит потребителям перевернуть существующую модель рынка мирового еды, при которой десяток монополистов тратят миллиардные рекламные бюджеты, навязывая нам всем свои продукты, полезные лишь для самих этих компаний. На стороне же потребителей эта “полезность” выражается в росте числа страдающих ожирением, диабетом, раком и пр. подобными заболеваниями.\n",
      "4 Несмотря на некоторую напыщенность и лозунгообразность вышесказанного, у нас есть четкая бизнес модель, мы прошли первый раунд финансирования, имеем неплохую капитализацию на частном инвестиционном рынке Великобритании (мы зарегистрированы в туманном Альбионе).  \n",
      "5 Сейчас в компании работает 8 человек, и мы продолжаем формировать команду.\n",
      "6 В частности, нам нужен Data Scientist для следующей (ближайшей) задачи:\n",
      "7 - преобразование полуструктурированных данных, полученных путем парсинга веб сайтов, в данные структурированные с последующим наполнением SQL баз данных\n",
      "8 В дальнейшем будет много задач, связанных как с NLP, так и другими областями ML.\n",
      "9 Для этой работы требуется знание Python, работа с текстами, обработка и подготовка данных, разработка архитектурных решений\n",
      "10 - Python, вкл. основные библиотеки (pandas, numpy, sci-kit learn и пр.)\n",
      "11 - NLP (NLTK/Gensim/Spacy, Word2Vec/fastText, text retrieval, etc.)\n",
      "12 - JSON\n",
      "13 - XPath (или аналоги)\n",
      "14 - SQL\n",
      "15 Мы работаем по принципу распределенной работы (в настоящий момент наши девелоперы работают удаленно из Москвы, Минска, Воронежа, Вильнюса); \n",
      "16 примерно раз в 2 мес. собираем всех на неделю в одном из приятных для времяпровождения городов. \n",
      "17 В компании помимо фиксированной оплаты предусмотрены опционы, которые выпускаются по английскому законодательству и имеют реальную ценность\n",
      "18 Нам нужны сотрудники, которые :\n",
      "19 - уже имеют хороший опыт программирования от 5 лет, \n",
      "20 - хорошее математическое образование, \n",
      "21 - не только читают технический английский, но и могут на английском общаться (оксфордский акцент и цитаты из Мильтона не обязательны)\n",
      "22 - хотят расти дальше и осваивать новые технологии\n",
      "23 - для которых работа - не просто способ заработка, а еще и способ воздействия на окружающий мир\n",
      "24 Дополнительные бонусы:\n",
      "25 - мы не предлагаем печенюшек, кофеюшек и пр. “юшек”\n",
      "26 - у нас нет совконутых/сбербанутых и пр. “нутых” начальников\n",
      "27 - не нужно каждый день переться в open space, чтобы обсуждать, чем он отличается от привокзальной площади\n",
      "28 - гибкий график\n",
      "29 - возможность частичной занятости\n",
      "30 Будучи стартапом на ранней стадии, мы не можем предложить компенсации в звонкой монете, которую предлагают некоторые более жирные компании\n",
      "31 Мы платим до $ 2,500 в мес. при полной занятости\n",
      "32 плюс \n",
      "33 опционы, начиная с 6-го месяца работы\n",
      "34 Естественно, что данное письмо еще не является job offer, а есть приглашение выразить Вашу заинтересованность в данной работе. Если такая заинтересованность появилась, пишите мне  \n",
      "35 на почту \n",
      "36 denis.smyslov@100nuts.ai\n",
      "37 С уважением,\n",
      "38 Смыслов Денис\n",
      "39 100nuts.ai\n",
      "40 Co-founder\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "31\n",
      "Input down salary value:\n",
      "2500\n",
      "Input top salary value:\n",
      "2500\n",
      "\n",
      "0 left #_jobs along with \n",
      "1 2 others\n",
      "2 . Also, \n",
      "3 tahhu\n",
      "4  and \n",
      "5 29 others\n",
      "6  joined. \n",
      "7 dariasupernova\n",
      "8  joined and left.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Всем привет!\n",
      "1 Есть вакансия\n",
      "2 Требования:\n",
      "3 • Высшее техническое образование / наличие научных публикаций в плюс / Математическая подготовка, знание теории вероятности, математической статистики и машинного обучения \n",
      "4 • Участие в Kaggle / победы в плюс\n",
      "5 • технологии:  \n",
      "6 Python, sckiit­learn, pandas, numpy, nltk, MognoDb\n",
      "7 Основные обязанности:\n",
      "8 Требуется улучшение алгоритмов автоматической классификации данных, исследование данных и построение предиктивных моделей. \n",
      "9 По деньгами от 100 000 руб. далее в зависимости от вашего уровня\n",
      "10 писать можно мне в личку.\n",
      "11  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "9\n",
      "Input down salary value:\n",
      "100\n",
      "Input top salary value:\n",
      "100\n",
      "\n",
      "0 СПб, у нас снова нанимают инженера по computer vision. Небольшие, но интересные проекты в области распонавания лиц, HDR фото и по автомобильной тематике.\n",
      "1 По-моему, из всего списка требований больше всего уделяется внимания имеющемуся опыту.\n",
      "2 http://spb.hh.ru/vacancy/15522358\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 >>>\n",
      "1 В 2014 году ряд российских страховых компаний (Intouch, «Важно. Новое страхование», СК Уралсиб и АльфаСтрахование) запустили успешные пилотные проекты по умному страхованию. В частности, они начали устанавливать навигационно-связное оборудование для сбора информации о стиле вождения страхователей в обмен на скидки и бонусы. Опыт показал, что услуга действительно востребована среди владельцев транспорта.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 про открытие инфа 50%\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Привеееет!\n",
      "1 Я сейчас помогаю молодой компании NtechLab, ребята разрабатывают передовые продукты на базе собственной технологии распознавания лиц, лучшей в мире. Например, недавно они получили первое место в соревновании, которое организовала IARPA, также они постоянно в лидерах тестирования FRVT NIST. Ребята создают крутые продукты и сервисы, которые меняют рынок, предоставляют своим клиентам функционал, который полтора года назад работал только в боевиках с Джейсоном Борном. Помогают снизить преступность в Москве, анализируя видеопотоки с подъездных камер.\n",
      "2 Среди клиентов компании: крупнейшие государственные  \n",
      "3 структуры, финансовые институты, предприятия розничной торговли.\n",
      "4 Алгоритм NtechLab превосходит по качеству алгоритм Google.\n",
      "5 Если вы энергичный и целеустремленный профессионал, предпочитаете динамичную стартап-культуру бюрократии, то нам нужно срочно познакомиться! А резюме можно направлять мне, я буду рада поделиться деталями: \n",
      "6 hr@ntechlab.com\n",
      "7 Вы нам подойдете, если\n",
      "8 - у вас есть высшее техническое образование;\n",
      "9 - вы обладаете хорошей математической подготовкой;\n",
      "10 - у вас есть знания алгоритмов машинного обучения и нейронных сетей и большой практический опыт их применения;\n",
      "11 - у вас есть опыт работы хотя бы с одной из библиотек: pytorch, mxnet, tensorflow, caffe;\n",
      "12 - вы любите Python;\n",
      "13 - у вас есть базовые знания C++.\n",
      "14 Будет плюсом:\n",
      "15 - опыт разработки на CUDA;\n",
      "16 - участие в kaggle соревнованиях;\n",
      "17 - опыт продакшн-разработки;\n",
      "18 - интерес к области распознавания лиц;\n",
      "19 - умение самостоятельно продумывать и делать эксперименты от момента постановки задачи до получения желаемого результата.\n",
      "20 Примеры задач, которыми занимается лаборатория:\n",
      "21 - участие в создании алгоритмов распознавания лиц для соревнования NIST FRVT;\n",
      "22 - улучшение точности и скорости работы алгоритмов распознавания лиц;\n",
      "23 - улучшение точности и скорости работы алгоритмов детектирования объектов;\n",
      "24 - разработка алгоритмов распознавания объектов на видео.\n",
      "25 Вас ждет\n",
      "26 - белая заработная плата - до 300 тыр на руки;\n",
      "27 - работа в команде экспертов по нейронным сетям;\n",
      "28 - участие в международных соревнованиях по распознаванию лиц;\n",
      "29 - интересные и сложные задачи по машинному обучению;\n",
      "30 - топовые сервера для обучения нейронных сетей, включая nvidia dgx-1;\n",
      "31 - премии по результатам работы в каждом полугодии;\n",
      "32 - удобное расположение рядом с метро Белорусская;\n",
      "33 - большая веранда с настольным теннисом;\n",
      "34 - ДМС после испытательного срока, бесплатные фрукты, смузи, чай, кофе.\n",
      "35  (edited) \n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "26\n",
      "Input down salary value:\n",
      "300\n",
      "Input top salary value:\n",
      "300\n",
      "\n",
      "0 Мы – настоящие монстры обработки данных и адепты маркетинговой аналитики и оптимизации. Последние  \n",
      "1 7 лет мы работали с Big data в США и теперь мы вернулись с миссией поднять уровень образования и профессионализма на Родине. Вот такой промышленный шпионаж, да!\n",
      "2 А еще наша мечта – создать настоящее российское Big Data сообщество. \n",
      "3 Компания занимается тем, что несет свет бигдаты из Калифорний в немытую Россию\n",
      "4 (edited)\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 TL;DR — ML researcher в medical imaging стартап (Москва)\n",
      "1 О нас\n",
      "2 Мы — Diagnocat, делаем ML-диагноста по медицинским снимкам. Наш пилотный продукт — стоматологическая диагностика по компьютерной томограмме челюсти: на входе DICOM файл с 3D-сканом, на выходе различные визуализации + структурированная диагностика на понятном врачу языке, которую он может сразу прикрепить к истории болезни. Это очень крутая вертикаль в medical imaging (описывать все 32 зуба — очень трудоемко, мало кто из врачей умеет/любит работать с 3D снимками, etc).\n",
      "3 Что у нас уже есть?\n",
      "4 - Небольшая, компетентная и сфокусированная команда рисечеров и инженеров\n",
      "5 - Быстрая команда аннотаторов, вооруженная мощными in-house разметочными тулами\n",
      "6 - Понимающие специфику области врачи, партнеры-клиники\n",
      "7 - Первая рабочая версия продукта, которая сейчас тестируется в крупной сети стоматологических клиник\n",
      "8 - >25,000 DICOM-ов в датасете\n",
      "9 - Желание и возможность публиковаться\n",
      "10 - Финансовая стабильность\n",
      "11 Кого мы ищем?\n",
      "12 Умный, прокачанный researcher/engineer, которого драйвит тема ML в медицине. Примерный профиль:\n",
      "13 - Общий интеллект и креативность\n",
      "14 - 2+ года опыта с сетками, 5+ лет работы в технической десциплине\n",
      "15 - Хороший технический английский, привычка читать arxiv перед сном\n",
      "16 - Опыт с нашим, довольно стандартным, стеком (Python, PyTorch, matplotlib, scipy, sklearn, ndimage, linux, …)\n",
      "17 - Техническое понимание работы DL фреймворков (на что расходуется память, от чего зависит скорость, как это оптимизировать, природу IO боттлнеков — вот это все)\n",
      "18 - Адекватное умение кодить\n",
      "19 - Ориентация на продуктовый/бизнесовый результат\n",
      "20 - Желание работать именно в стартапе\n",
      "21 - Мы рассматриваем и чистых рисечеров с уклоном в математику, и более инженерно-ориентированных. Идеальный кандидат будет совмещать инженерные и рисеч компетенции.\n",
      "22 Что надо будет делать?\n",
      "23 - Реализовывать архитектуры из статей, гонять эксперименты, тюнить параметры, писать сопутствующие data processing тулы. Отвечать за продуктовый результат всего этого.\n",
      "24 - Креативить — идентифицировать проблемы текущего пайплайна, находить новые подходы к их решению, искать релевантные метрики. Генерить прочие идеи по бизнесу.\n",
      "25 - Бежать с максимальной скоростью, добиваться результата. Прокачиваться, прокачивать коллег, быть прокачанным в ответ.\n",
      "26 Что мы предлагаем?\n",
      "27 - Очень даже нескучную работу\n",
      "28 - Конкурентная компенсация: 150к - 300к (middle+ → senior++)\n",
      "29 - Работа из современного офиса в Москве (можем рассмотреть удаленные варианты)\n",
      "30 - Опыт работы в компетентном стартапе\n",
      "31 - Возможность получить опцион\n",
      "32 Пишите на \n",
      "33 matvey@diagnocat.com\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "28\n",
      "Input down salary value:\n",
      "150\n",
      "Input top salary value:\n",
      "300\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @rasim.akhunzyanov\n",
      "1 : это удаленная работа, с оплатой в 8$ в час; тем временем средняя оплата на апворке, тоже удаленная работа, для датасаенса около 40$ в час; зачем работать удаленно за 8 если можно за 40\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 6 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 ну в билайне 100500 дата сайентистов судя по какому то интервью\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 22 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 коллеги, нужен напарник на небольшой проект\n",
      "1  - нужно по истории бронирований построить модель для прогнозирования занятости номеров;  \n",
      "2  нужно сделать упор на извлечение признаков, тк прогнозирование занятости не является конечной целью; полученный датасет позже будет использоваться эконометристом для оценки  \n",
      "3 эластичности спроса; в общем такой странный кегло-проектик, так что можно считать, что участие в конкурсах и хорошие результаты хоть в одном нужны\n",
      "4  - 25$/час, работа через апворк - это значит за первые 500 баксов вы отдадите 20% апворку, после 500$ будите отдавать 10% \n",
      "5  - первая фаза проекта 3-4 недели по 15-25 часов в неделю\n",
      "6  - лс\n",
      "7  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "4\n",
      "Input down salary value:\n",
      "25\n",
      "Input top salary value:\n",
      "25\n",
      "\n",
      "0 Всем привет! Попросили выложить\n",
      "1 -Кто? Аналитик в группу разработки аналитических сервисов \n",
      "2 Куда? Рейтинговое агенство АКРА, Москва. \n",
      "3 -Что делать? Моделировать вероятности дефолта клиентов, создавать модели LGD, модели для IFRS9 корпоративного сегмента, модели рыночного риска, валидации, стресс-тестирования + много других интересных задач, связанных с машинным обучением и бизнес-аналитикой. \n",
      "4 -Что необходимо? Ищем человека с базовым техническим образованием (Мехмат, ВМК, Физтех, ФКН) и отличным знанием статистики, эконометрики и навыками программирования. \n",
      "5 -Что предлагаем? Работа в комфортном офисе у метро Павелецкая, страховка, оплачиваемое обучение. Подразделение новое, зарплатных ограничений нет, все зависит от уровня навыков и позиции. Частичная занятость обсуждаема. \n",
      "6 Резюме и вопросы на почтовый адрес: \n",
      "7 o.yaropolov@yandex.ru\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Вакансии пятничного вечера) Ищем хорошего человека) компания Gett.\n",
      "1 Role & responsibilities:\n",
      "2  In the beginning you will be improving Supply function:\n",
      "3 ●  \n",
      "4  \n",
      "5  \n",
      "6  \n",
      "7  \n",
      "8 Develop and constantly improve a model based on machine learning approach to set optimal product settings worldwide (up to 100 settings) to drive our business at the most efficient way. At the first steps, most of the time will be devoted to routing algorithm optimization\n",
      "9 ●  \n",
      "10  \n",
      "11  \n",
      "12  \n",
      "13  \n",
      "14 Monitor model performance (i.e., the effectiveness of settings) and solve \"something went wrong\" situations on a daily basis together with operational supply team\n",
      "15 ●  \n",
      "16  \n",
      "17  \n",
      "18  \n",
      "19  \n",
      "20 Develop the holistic and practical demand/supply model, which predicts key business indicators\n",
      "21 Education & Experience:\n",
      "22 ●  \n",
      "23  \n",
      "24  \n",
      "25  \n",
      "26  \n",
      "27 Bachelor or Master degree from leading university (preferably in Applied Math, Sciences or Engineering)\n",
      "28 ●  \n",
      "29  \n",
      "30  \n",
      "31  \n",
      "32  \n",
      "33 1+ years of experience in a business sphere\n",
      "34 ●  \n",
      "35  \n",
      "36  \n",
      "37  \n",
      "38  \n",
      "39 Top places on olympiads and Kaggle competitions as a plus\n",
      "40 Technical and Behavioral Skills:\n",
      "41 ●  \n",
      "42  \n",
      "43  \n",
      "44  \n",
      "45  \n",
      "46 Programming: R or Python. Working knowledge of libraries for geodata as a plus\n",
      "47 ●  \n",
      "48   \n",
      "49   \n",
      "50 Basic SQL. “Select”, “join”, “where”, “group by” keywords. Indices.\n",
      "51 ●  \n",
      "52  \n",
      "53  \n",
      "54  \n",
      "55  \n",
      "56 Working knowledge of algorithms and optimization techniques that can be applied when working with geodata as a plus\n",
      "57 ●  \n",
      "58  \n",
      "59  \n",
      "60  \n",
      "61  \n",
      "62 Oral and written English: at least upper-intermediate level\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Привет\n",
      "1 Ищем в Rambler&Co  \n",
      "2 специалиста на позицию Machine Learning Engineer в автомобильный классифайд \n",
      "3 am.ru\n",
      "4 .\n",
      "5 Нужно будет:\n",
      "6 1) автоматизировать модерацию объявлений,\n",
      "7 2) научиться рекомендовать пользователям оптимальную цену для продажи их автомобиля в зависимости от того, как быстро нужно его продать,\n",
      "8 3) научиться использовать накопленные данные и разметку для других продуктовых решений.\n",
      "9 Что мы ожидаем от кандидата:\n",
      "10 1) знание теории вероятности и математической статистики;\n",
      "11 2) успешные кейсы решения бизнес-задач с помощью алгоритмов machine learning;\n",
      "12 3) сильные навыки программирования на Python;\n",
      "13 4) умение использовать готовые библиотеки для различных стеков.\n",
      "14 С нас:\n",
      "15 - Интересные задачи;\n",
      "16 - Возможность поработать одновременно в крупной известной компании и небольшой сплоченной команде проекта \n",
      "17 am.ru\n",
      "18 ;\n",
      "19 - Полное соблюдение ТК РФ;\n",
      "20 - \"Белая\" заработная плата (обсуждается индивидуально);\n",
      "21 - Офис недалеко от м. Тульская, корпоративный транспорт от м. Павелецкая/ Коломенская;\n",
      "22 - Медицинское страхование (ДМС), скидки на фитнес;\n",
      "23 - Есть возможность работать в Санкт-Петербурге.\n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "\n",
      "0 Manifest (MNFST) — это рекламная сеть нового формата. Мы создаем уникальный продукт в сфере influencer marketing, который позволит брендам стать известными большой аудитории без траты времени на согласование рекламных форматов, бюджета, сроков и прочего, а пользователям социальных сетей — монетизировать свой профиль в несколько кликов. Мы запустились в 2018, до этого разработка шла около года, в команде более 20 человек в Москве и Лондоне.\n",
      "1 Наш сайт: \n",
      "2 https://mnfst.com\n",
      "3 Ищем Python разработчика, который займется сбором и организацией хранения данных.\n",
      "4 Требования\n",
      "5 — Опыт программирования на Python/Ruby/Go от 1 года\n",
      "6 — Опыт работы с  \n",
      "7 PostgreSQL и нереляционными базами данных MongoDB и Neo4j\n",
      "8 — Базовое знание HTTP, JS, HTML, DOM\n",
      "9 — Понимание ООП\n",
      "10 — Опыт работы по сбору, обработке и хранению данных\n",
      "11 — Представление о работе современных баз данных\n",
      "12 Задачи\n",
      "13 — Работа с RESTful API\n",
      "14 — Написание многопоточных парсеров\n",
      "15 — Сборка и минимизация данных\n",
      "16 — Поставка данных для работы с ML\n",
      "17 — Написание тестов\n",
      "18 Что мы предлагаем\n",
      "19 — Работа с серийными предпринимателями, все фаундеры компании основали\n",
      "20 или руководят известными и успешными интернет-компаниями\n",
      "21 — З/п от 70-120 тыс. руб.\n",
      "22 Пишите \n",
      "23 jobs@mnfst.com\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "21\n",
      "Input down salary value:\n",
      "70\n",
      "Input top salary value:\n",
      "120\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 20 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 за 2 недели можно найти человека, выдать оффер и выйти на работу\n",
      "1  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Очередная тема от рекрутера с линкедина:\n",
      "1 Artificial Intelligence Lead с релокацией в Латвию для международной IT компании.\n",
      "2 По требованиям:\n",
      "3 - Phd. Could be scientist.\n",
      "4 - 5+ years of experience in Artificial Intelligence.\n",
      "5 - Should be technology lead as subject matter expert.\n",
      "6 - Practical experience in developing AI solutions.\n",
      "7 - Self-driven, enthusiastic personality.\n",
      "8 - Experience in at least one of following: machine vision systems, robotics, voice-recognition systems.\n",
      "9 Компания полностью берет на себя расходы по релокации сотрудника и его семьи.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 мопед не мой, вакансия, по словам человека, еще не на \n",
      "1 hh.ru\n",
      "2 , практически эксклюзив:\n",
      "3 «МегаФон» — не только лидер телекоммуникационного рынка России, но компания возможностей. Мы идём в ногу со временем, динамично растём, открываем новые области для бизнеса и инновационные проекты, направленные на улучшение качества сервисов и расширения спектра услуг. Мы твердо уверены, что технологии анализа данных способны изменить не только телеком отрасль, но и мир, вокруг нас. Если Вам интересно направление Big Data, есть желание работать с одним из самых больших в России объемов накопленных данных и стремитесь к ежедневному совершенствованию, давайте творить историю вместе. Будущее зависит от тебя!\n",
      "4 Мы ищем Аналитика, специализирующегося на машинном обучении и анализе данных,\n",
      "5 • которому интересно решение прикладных задач в области анализа данных и машинного обучения,\n",
      "6 • который не боится сложных амбициозных задач и готов разбираться в проблемах, встающих перед бизнесом,\n",
      "7 • готов к постоянному самосовершенствованию и поиску самых эффективных технологий и решений. \n",
      "8 Вашими задачами будут:\n",
      "9 • Изучение проблем, встающих перед бизнесом, с использованием статистического анализа, постановка математической задачи, формирование гипотез для дальнейшего анализа;\n",
      "10 • Построение математических моделей анализа клиентских предпочтений, прогнозирования спроса и трафика, анализа качества работы сети и удовлетворенности клиентов, выявления фактов мошенничества;\n",
      "11 • Участие в проектах создания систем автоматического принятия решений и аналитических сервисов и математическая поддержка разработчиков (программистов);\n",
      "12 Мы ожидаем от вас:\n",
      "13 • Фундаментальные знания в области математики, теории вероятности, мат. статистики (высшее образование, наличие ученой степени будет дополнительным плюсом);\n",
      "14 • Опыт работы Data scientist аналитиком и/или участия в соревнованиях по data mining (например, kaggle) – просьба подробно осветить в резюме;\n",
      "15 • Владение Python (Pandas, NumPy , scipy, scikit-learn) / Matlab / Octave\n",
      "16 • Знание основных методов и алгоритмов Machine Learning\n",
      "17 • Сертификаты и дипломы ШАД-а или курсов по машинному обучению и анализу данных (Coursera, edX и т.п.) будут большим плюсом.\n",
      "18 Дополнительным плюсом будет, но при этом вовсе не обязательно:\n",
      "19 • Опыт разработки на C++, Java\n",
      "20 • Знание SQL;\n",
      "21 • Опыт работы с какими-либо библиотеками машинного обучения (OpenCV, Torch, Caffe, cuDNN, TensorFlow, Theano) – напишите в резюме с чем работали;\n",
      "22 • Знание технологического стека Hadoop (HDFS, Hive, Spark)\n",
      "23 Что мы предлагаем:\n",
      "24 • Интересные задачи и уникальный опыт работы в крупнейшей телекоммуникационной компании;\n",
      "25 • работу с одним из самым больших в России объемом накопленных данных;\n",
      "26 • дружный коллектив специалистов;\n",
      "27 • возможность заниматься действительно важными и интересными задачами, развиваться и расти вместе с командой;\n",
      "28 • Оформление по ТК РФ с официальной заработной платой и бонусной программой;\n",
      "29 • Удобный и эргономичный офис;\n",
      "30 • Соц. Пакет (ДМС, фитнес, мобильная связь и многое другое);\n",
      "31 • Возможность гибкого рабочего дня;\n",
      "32 • м. Савеловская (5 мин. пешком).\n",
      "33 контакт: \n",
      "34 ntmrlabs@gmail.com\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Мопэд не мой, но может кому-то будет интересно:\n",
      "1 Руководитель направления Big Data и продвинутой аналитики в X5 Retail Group\n",
      "2 Цель должности:\n",
      "3 - Определять стратегическое направление, операционные процессы, стандарты, компетенции команды по продвинутой аналитике\n",
      "4 - Создать и руководить центром продвинутой аналитики с использованием внутренних и внешних ресурсов и экспертных знаний\n",
      "5 - Оценивать потенциал и развивать использование больших данных и перспективной аналитики в бизнес-единицах\n",
      "6 - Формировать требования, определять и интегрировать инструменты для работы с большими данными\n",
      "7 Обязанности: \n",
      "8 - Определение стратегических и/или долгосрочных приоритетов с руководством бизнес-единиц для команды продвинутой аналитики;\n",
      "9 - Формирование и внедрение операционных процессов и стандартов проведения продвинутой аналитики;\n",
      "10 - Создание команды, определение и развитие ключевых компетенций для продвинутой аналитики;\n",
      "11 - Регулярные рабочие встречи с командой аналитиков для оценки статуса работы по ключевым приоритетам, совместного с бизнес-единицами формирования и тестирования ключевых гипотез, формирования плана дальнейших действий;\n",
      "12 - Регулярные встречи с высшим руководством для обсуждения приоритетов и прогресса, продвижения использования возможностей перспективной аналитики;\n",
      "13 - Принятие решения по выбору инструментов для обработки больших данных и контроль их интеграции с существующими бизнес-системами.\n",
      "14 Требования:\n",
      "15 - Не менее 10 лет на позиции, связанной с аналитикой данных и формированием выводов/рекомендаций\n",
      "16 - Не менее 5 лет работы в должности с функциями руководителя;\n",
      "17 - Успешный опыт внедрения и работы с платформами обработки больших данных;\n",
      "18 - Требования к образованию: степень магистра в области статистики/аналитики/математических наук,  \n",
      "19 дополнительное преимущество - наличие MBA в области статистики/аналитики/финансов;\n",
      "20 - Навыки и компетенции: развитые аналитически навыки, знание инструментов анализа больших данных и особенностей их интеграции, способность к формированию гипотез и выводов из полученных данных, коммуникабельность, бизнес-экспертиза, опыт взаимодействия с топ-менеджментом компании и способность четко и аргументировано излагать свою позицию, навыки работы с базами данных, навыки проектного управления, способность стратегически мыслить и оценивать потенциал кроссфункционального взаимодействия.\n",
      "21 Вилки нет\n",
      "22 Контакты: +79166886310, \n",
      "23 Marina.Maksimova@x5.ru\n",
      "24 , Марина Максимова\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Котаны, мопед не мой, но может кому-нибудь пригодиться:\n",
      "1 Аналитик данных\n",
      "2 News Media Digital - \n",
      "3 http://go-promo.ru/\n",
      "4 Студия Go-Promo разрабатывает и поддерживает большинство digital-проектов\n",
      "5 одного из крупнейших медиахолдингов России News Media, в том числе, телеканала\n",
      "6 L!FE и газеты \"Известия\". Мы также занимается разработкой персональных сайтов,\n",
      "7 высокопосещаемых информационных порталов, клиент-серверных приложений для\n",
      "8 автоматизации бизнес- процессов и мобильных приложений под Android и iOS\n",
      "9 различной направленности.\n",
      "10 В отдел аналитики ищем опытного специалиста по машинному обучению с\n",
      "11 опытом анализа больших объемов данных. Мы работаем над одним из крупнейших\n",
      "12 новостных проектов Рунета, более 100 млн. просмотров в месяц, свыше 12 млн.\n",
      "13 уникальных посетителей. Кроме этого проект включает в себя один из самых\n",
      "14 цитируемых телеканалов в России.\n",
      "15 Обязанности\n",
      "16 • \n",
      "17  \n",
      "18  \n",
      "19  \n",
      "20 Исследование и внедрение алгоритмов машинного обучения и анализа данных.\n",
      "21 • \n",
      "22  \n",
      "23  \n",
      "24  \n",
      "25 Участие в разработке собственного алгоритма коллаборативной фильтрации и рекомендательной системы на его основе для веб-портала телеканала L!FE.\n",
      "26 • \n",
      "27  \n",
      "28  \n",
      "29  \n",
      "30 Активное взаимодействие с backend- и frontend-разработчиками.\n",
      "31 Требования\n",
      "32 • \n",
      "33  \n",
      "34  \n",
      "35  \n",
      "36 Владение хотя бы одним языком программирования: С++, Java и/или Python.\n",
      "37 • \n",
      "38  \n",
      "39  \n",
      "40  \n",
      "41 Базовые знания и умение реализовывать на языке программирования алгоритмы машинного обучения (методы классификации, кластеризации, регрессии, нейронные сети, LSTM), численные методы оптимизации (стахостический градиентный спуск, Alternating Least Squares), а также рекомендательные системы (коллаборативная фильтрация).\n",
      "42 • \n",
      "43  \n",
      "44  \n",
      "45  \n",
      "46 Умение работать с большими массивами данных, понимание многопоточности.\n",
      "47 • \n",
      "48  \n",
      "49  \n",
      "50  \n",
      "51 Желательно знание и опыт работы с Apache Spark, Pandas и/или Hadoop.\n",
      "52 Условия\n",
      "53 • \n",
      "54  \n",
      "55  \n",
      "56  \n",
      "57 Заработная плата от 120 000 до 150 000 рублей в месяц.\n",
      "58 • \n",
      "59  \n",
      "60  \n",
      "61  \n",
      "62 Испытательный срок - 2 месяца.\n",
      "63 • \n",
      "64  \n",
      "65  \n",
      "66  \n",
      "67 Официальное трудоустройство по ТК РФ, полностью \"белая\" заработная плата.\n",
      "68 • \n",
      "69  \n",
      "70  \n",
      "71  \n",
      "72 Работа в офисе в Москве рядом со ст. м. \"Савёловская\" (Бумажный проезд, дом 14/2) или в Нижнем Новгороде (Нижний Новгород, улица Белинского, дом 36).\n",
      "73 • \n",
      "74  \n",
      "75  \n",
      "76  \n",
      "77 Достойным кандидатам при необходимости готовы оказать помощь при переезде.\n",
      "78 • \n",
      "79  \n",
      "80  \n",
      "81  \n",
      "82 Часто очень интересные и нестандартные проекты общероссийского масштаба.\n",
      "83 • \n",
      "84  \n",
      "85  \n",
      "86  \n",
      "87 Команда из 2-х аналитиков. Вся команда разработчиков в Нижнем Новгороде - около 50-ти человек, в Москве формируется команда из 30-ти человек.\n",
      "88 Контакт - Маргарита Куликова, \n",
      "89 margot.kulikova@gmail.com\n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "57\n",
      "Input down salary value:\n",
      "120\n",
      "Input top salary value:\n",
      "150\n",
      "\n",
      "0 @sovcharenko\n",
      "1 : его нет, у меня всего в 2 стартапа были собеседования по теме ds/ml, все остальное в финансах\n",
      "2 В одной нужен был Lead, который им построит систему скоринга микрокредитов в real time, мне они не понравились + опыта у меня не хватает явно\n",
      "3 Вторая компания - flocktory, тут уже обсуждали ее\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 нормально чуваки это когда вы говорите что 5%, не нормально - когда вы тратите чужие ресурсы на просчет проектов которых 95% не будет\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Камрады, а вот в телеграмме вопрос\n",
      "1 Интересно кому?\n",
      "2 \"Кто мы:\n",
      "3 Brain Company \n",
      "4 brain-company.ru\n",
      "5  – компания, существующая на базе факультета психологии НИУ ВШЭ, мы занимаемся нейромаркетинговыми исследованиями, то есть такими исследованиями маркетингового материала, которые идут с помощью нейробиологических методов (электроэнцефалограмма, кожно-гальваническая реакция, кардиограмма, трекинг глаз, анализ микромимики и прочее). В итоге мы понимаем эмоциональные реакции человека, его ценности и потребности, что и предоставляем нашим клиентам. \n",
      "6  Так сложилась наша жизнь, что нам срочно нужен дата сайнтист, готовый приступить к работе завтра и проработать с нами до конца августа, а затем, если мы понравимся друг другу – войти в команду. \n",
      "7  Требования довольно простые:\n",
      "8  Базовое понимание статистики и линейной алгебры\n",
      "9  Идеально, если вы умеете кодить на матлабе. Если не умеете – желательно, чтобы вы умели кодить на Python/R/C/C++/C#/Java.\n",
      "10  Совсем благодать, если вы имели опыт работы с биологическими данными – с ЭЭГ,КГР,ЭМГ,МПГ\n",
      "11  Ваш уровень должен быть студент 2+ курса профильного факультета\n",
      "12  Вам должно быть интересно развиваться в этой сфере\n",
      "13 Что с нас:\n",
      "14 Опыт и получение знаний в сфере нейронаук\n",
      "15 Вот так! Пишите в личку. #Москва\n",
      "16 @balexey\"\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 29 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 27 others\n",
      "2 . Also, \n",
      "3 UNKNOWN\n",
      "4  left.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Всем привет. Мы небольшой стартап из Лондона (\n",
      "1 https://chattermill.io\n",
      "2 ). Ищем специалистов по deep learning особенно с текстовыми данными. Сейчас мы используем LSTM-модель в keras / tensorflow, но хотим ее улучшить / дополнить. У самих на все идеи не хватает времени, так что я ищу кого-нибудь, кто мог бы помочь. Вначале фриланс, если пойдет хорошо, может взять на фултайм, если интересно и помочь переехать в Лондон (опять же, если интересно). Можно писать тут или на \n",
      "3 mikhail@chattermill.io\n",
      "4 . По фрилансу $25 - $40 в час в зависимости от опыта.\n",
      "5  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "4\n",
      "Input down salary value:\n",
      "25\n",
      "Input top salary value:\n",
      "40\n",
      "\n",
      "0 как тебе сказать. если бы мне не было так хреново на прошлой работе (просто устал за 2,5 года), и если бы я точно понимал, что здесь в реальности происходит, то вряд ли бы я сюда пошел. а сейчас искать что-то еще и куда-то опять устраиваться я не готов \n",
      "1 :disappointed:\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @b00ris\n",
      "1 : ну откуда мне знать. Нагугли)\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Call for Visiting Researchers to join the Alan Turing Institute\n",
      "1 Posted on 21st September 2016\n",
      "2 The Alan Turing Institute invites leading data scientists from the UK and around the world to become a Visiting Researcher at the Institute during its first academic year.\n",
      "3 The aim of the Visiting Researcher Programme is to generate collaborations, facilitate knowledge exchange and explore new or emerging research topics in data science;  \n",
      "4 https://turing.ac.uk/jobs/call-visiting-researchers/\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 ну может, хотя наверное в таких случаях либо пишут, что требуются люди разной квалификации, ну или еще лучше - создают несколько разных вакансий с разными требованиями, а то как то писать 100500 требований, не упоминая что 80% из них не обязательны - это странный подход для поиска новичка\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 5 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 моя знакомая из JetBrains ищет сотрудника:\n",
      "1 http://spb.hh.ru/vacancy/13661467?query=jetbrains\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Добрый день. #2\n",
      "1 На разовый проект нужен человек с опытом работы по компьютерному зрению. Работа удаленная.  \n",
      "2  \n",
      "3 Идеально для тех, кто хочет развиваться в области и у кого есть пара часов день свободного времени.\n",
      "4 Суть задачи: необходимо помочь в разработке системы контроля посещаемости.  \n",
      "5  \n",
      "6 В специализированных классах, где проводится обучение, нужно проверять, что человек проходивший экзамен или выполняющий тесты, является тем, кто зарегистрировался при поступлении.\n",
      "7 Система будет состоять из двух модулей:\n",
      "8 - Создания эталонного фотоизображения, на этапе поступления  \n",
      "9 Тут нужна помощь в описании требований по фотографии. Конвертации фотографии в характеристики.\n",
      "10 - Поиск в базе фотоизображений человек, на этапе прохождения тестов.  \n",
      "11 Тут необходимо решение, позволяющее с видеопотока получать характеристики аналогичные полученным ранее на первом этапе, для последующего поиска id профиля человека.\n",
      "12 Бюджет ещё не сформирован. Нужна оценка по срокам.\n",
      "13 Оплата может быть и почасовой и сдельной, как удобнее исполнителю. Всё обсуждаемо.  \n",
      "14 При почасовой оплате верхний предел примерно 1000 ₽ за час, но всё обсуждаемо и зависит от общего времени.\n",
      "15 Эта задача вполне решается с помощью openface, tf, dlib, etc\n",
      "16 Но лучше когда есть человек, который понимает, как и что делается.\n",
      "17 DS найдись!\n",
      "18  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "14\n",
      "Input down salary value:\n",
      "1000\n",
      "Input top salary value:\n",
      "1000\n",
      "\n",
      "0 я не владею точными цифрами по з/п. По моим ощущениям это 30-300. Т.е. я могу представить людей, кого мы бы взяли на верхний и кого на нижний предел.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 http://www.cnews.ru/news/line/2016-03-01_superjob_issledoval_zarplaty_analitikov_big_data\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Ищу специалиста по анализу данных с реализованными проектами в крупных банках (топ5-10 по активам в РФ) для участия в проекте )\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 9 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Добрый день. Так случилось, что неожиданно пришло время искать новую работу. Немного о себе: 4 года работала в страховой компании актуарием в Минске, 1,5 месяца аналитиком в геймпроекте на удаленке. С цифрами все в порядке. Пока еще не совсем уверенно чувствую себя именно в характеристиках игр. Но я работаю над этим. Возможно кому-то нужен джун аналитик без диких замашек и с вполне себе реальным желанием развиваться\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Привет всем!\n",
      "1 Ищем Data Scientist в Киеве.\n",
      "2 Для проверки правописания и улучшения текста у нас используются практически все известные подходы от ручных правил до deep learning и статьи 2015-2016 годов. Соответственно, нужен человек, который будет улучшать и реализовывать новые алгоритмы во всём спектре NLP. А также руководить исследовательскими проектами и передавать знания начинающим.\n",
      "3 Подробное описание по ссылке, в кратце нужен опыт и умение применять обучение машин в NLP. Ищем людей уровня middle и senior (или junior, желающий и умеющий быстро учиться).\n",
      "4 https://www.grammarly.com/jobs/engineering/researcher-%2F-ml-%2F-nlp-engineer-?gh_jid=120716\n",
      "5  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @chudo19\n",
      "1 , вакансия между junior и lead data scientist планируется?\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Data Engineer в стартап\n",
      "1 100nuts.ai\n",
      "2 WE ARE REVOLUTIONIZING THE GLOBAL FOOD CONSUMPTION\n",
      "3 Оплата\n",
      "4 •$ 2500 в мес.,\n",
      "5 •оплата на банк. счет физ лица или ИП по долгосрочному консультационному соглашению с английской компанией\n",
      "6 •После 6 мес. работы предусматриваются опционы\n",
      "7 Удаленная работа\n",
      "8 •Наши разработчики работают удаленно из разных городов России (Москва, Воронеж, Йошкар Ола, Томск) и др. стран (Беларусь, Литва, Монтенегро).\n",
      "9 •Раз в два месяца вся команда собирается на неделю в приятном городе за пределами РФ. Текущая работа ведется с помощью популярных средств типа Jira, Zoom, и т.д.\n",
      "10 Функционал\n",
      "11 •Реализация алгоритмов нашей собственной разработки в  \n",
      "12 production level коде;\n",
      "13 •Адаптация и имплементация в продакшн нейронных сетей\n",
      "14 •Работать придется с большим массивом данных, множеством параметров, выбором из триллионов комбинаций\n",
      "15 •При наличии достаточных знаний участие в разработке и тестировании алгоритмов будет только приветствоваться\n",
      "16 Опыт работы  \n",
      "17 и знания\n",
      "18 •Опыт написания хорошего уровня production code на Питоне, оптимизации, профайлинга\n",
      "19 •Знание основных библиотек Питона (в т.ч. numpy, pandas);\n",
      "20 •Понимание принципов ООП, функционального программирования,  \n",
      "21 написания чистого кода, SOLID, DRY etc, покрытие тестами;\n",
      "22 •опыт работы с SQL и noSQL бд, кэш сервером redis;\n",
      "23 •Предпочтение будет отдаваться профессионалам с математическим бэкграундом, знанием и опытом применения алгоритмов машинного обучения;\n",
      "24 •разговорный английский на хорошем уровне\n",
      "25 О компании\n",
      "26 •Наш стартап занимается “оцифровкой” мирового рынка еды и построением алгоритмов, помогающих любому человеку в любом крупном городе мира выбирать полезную для него еду\n",
      "27 •Более подробная инфа здесь: \n",
      "28 100nuts.ai\n",
      "29 •Сейчас в компании работает 10 человек.\n",
      "30 •Стадия - ‘pre-market’. Пользователей еще нет, ведется разработка продукта, запуск планируется на осень 2019 в Лондоне\n",
      "31 •У компании акционеры из Великобритании, Франции и Гон Конга, неплохая капитализация и достаточное финансирование для достижения наших целей.\n",
      "32 Моя эл. почта:\n",
      "33 denis.smyslov@100nuts.ai\n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "4\n",
      "Input down salary value:\n",
      "2500\n",
      "Input top salary value:\n",
      "2500\n",
      "\n",
      "0 да, условия больничных и страховок отличаются от компании к компании. И да, если отколбасить 160 часов в месяц на почасовой оплате - мозги расплавятся (при условии, что это - реальные часы, а не нарисованные). Мой-то пойнт был в том, что между ставкой 600р в час и з/п 100к в месяц (так же, как и между ставкой $40 в час и з/п $6400 в месяц) лежит пропасть\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @artem\n",
      "1  нашему боту лука вроде нравится, но он видно не оч впечатлен\n",
      "2 natekin [11:38 PM]  \n",
      "3  что про луку думаешь?\n",
      "4 markov-botBOT [11:38 PM]  \n",
      "5 @natekin\n",
      "6 : что про свои сны и воспоминания, но не долго, а вот если тебя всё будет хорошо\n",
      "7 natekin [11:38 PM]  \n",
      "8  они крутые?\n",
      "9 markov-botBOT [11:38 PM]  \n",
      "10 @natekin\n",
      "11 : было же, там еле касается стены не твои и это будет мой финальный ролл аюмии на 47 b 47\n",
      "12 natekin [11:38 PM]  \n",
      "13  тоесть у луки норм дл?\n",
      "14 markov-botBOT [11:38 PM]  \n",
      "15 @natekin\n",
      "16 : у меня норм лал 0 тоже как настоящий нищук решил выебнуться не самым большим х*ем останешься ты\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 класс, 100к слов. первая задача должна быть интересная. а к словам вопросы уже есть?\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Company: Yousician\n",
      "1 Role: Data Engineer\n",
      "2 Location: Helsinki, Finland (on-site)\n",
      "3 Salary TBD (3500€ - 5000€)\n",
      "4 About us\n",
      "5 Yousician is a revolutionary music platform for anyone to learn, play, create and teach music. Millions of people around the world use Yousician to advance their music skills and play the music they love. \n",
      "6 https://company.yousician.com/careers\n",
      "7 As a Data Engineer, you will be building and maintaining a scalable data pipeline and providing the tools for the teams that facilitate data-driven decision making. You will be involved in all aspects of data analysis, designing and implementing our data architecture and the algorithms that drive our product.\n",
      "8 What you’ll do\n",
      "9 Develop and maintain our data pipeline.\n",
      "10 Improve the scaling, optimization, tests and our internal tools to enhance data quality & reliability.\n",
      "11 Work with diverse data processing frameworks and technologies and bring new ideas to the table.\n",
      "12 Help the team in all aspects of data analysis but with focus on data engineering.\n",
      "13 Who you are\n",
      "14 You have experience of building or maintaining a data warehouse or ETL pipeline.\n",
      "15 You have hands-on experience with data warehousing technologies (e.g. Redshift, Hadoop, Druid, Spark, Apache drill).\n",
      "16 Good experience with TDD in Python and SQL languages.\n",
      "17 Strong interest in learning/discovering new big data technologies.\n",
      "18 You have some Linux administration system knowledge.\n",
      "19 Experience with AWS and Google Cloud Platform.\n",
      "20 Experience with developing complex ETL workflow (Airflow).\n",
      "21 What we offer\n",
      "22 You'll have a meaningful and profound impact on the lives of millions of musicians and future musicians all around the world.\n",
      "23 You'll get a competitive compensation package - salary, stock options, crazy perks - and work in an awesome new office in the heart of Helsinki.\n",
      "24 We have lots of perks and quirks: daily push-up sessions, jam sessions (with more instruments than you can shake a drumstick at!), board game tournaments and sauna evenings, and our famous Greece, Thailand, Tenerife, Bali and Curacao work retreats.\n",
      "25 If you’d be curious to learn more about the Data Engineer role and what we’re up to at Yousician, please drop me a message or email me at \n",
      "26 magnus@yousician.com\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "3\n",
      "Input down salary value:\n",
      "3500\n",
      "Input top salary value:\n",
      "5000\n",
      "\n",
      "0 Привет, товарищи!)\n",
      "1 Ищу \n",
      "2 Middle, Senior аналитик\n",
      "3  с опытом в маркетинговой аналитике\n",
      "4 Город: \n",
      "5 Москва\n",
      "6  (часть недели можно работать удаленно)\n",
      "7 Компания: \n",
      "8 IBS\n",
      "9 130-180 т.р.\n",
      "10 Мы занимаемся оутсорсом найма для ритейла. Ищу в команду аналитика на построение внутренней аналитики от маркетинговых каналов привлечения до найма и анализа последующего жизненного цикла сотрудника.\n",
      "11 Есть команда DWH, сейчас строим аналитический стек. Вакансия подходит для тех, кто в процессе перехода из операционной, маркетинговой аналитики в datascience.\n",
      "12 Задачи разделены на две части:\n",
      "13 Операционная аналитика:\n",
      "14 - Строить отчетность по воронке привлечения.( маркетинг + бизнес процесс)\n",
      "15 - Писать аналитически записки по результату, а как надоест. автоматизировать коммуникацию по основным метрика.\n",
      "16 - Построить процесс аналитика → гипотезы → тест → изменение бизнес процесса на основе данных.\n",
      "17 - Выступать в роли эксперта для бизнеса при оптимизации бизнес процессов.\n",
      "18 - Выстраивать процесс разметки данных вместе с подрядчиком по маркетинговой аналитике. ( на их стороне ETL, на нашей анализ)\n",
      "19 Вакансия подходит для тех, кто переходит в datascience т.к. есть задачи( следующий шаг после операционной аналитики):\n",
      "20 - Построить модель прогноза конверсий,\n",
      "21 - Приоритезировать выбор кандидатов при обзвоне,\n",
      "22 - Скоринг резюме,\n",
      "23 - Построить процесс А/Б тестирования\n",
      "24 Ожидаем опыт в маркетинговой аналитике, знание python,  \n",
      "25 понимание статистике. Опыт построения системы метрик для бизнес процессов и их оптимизация.\n",
      "26 Можно работать удаленно? - Хоть из антарктиды, если процессы аналитики работают и ты знаешь как работать удаленно.\n",
      "27 Вы скучный корпорат? - Это не банкинг, где от ты коннектор к SQL базе. Всю аналитическую практику нужно строить с нуля. Хороший вызов. Но и не смузи офис к сожалению.\n",
      "28 Могу ли я нанимать команду? - Если скажешь, что тебе нужен человек потому что \n",
      "29 placeholder\n",
      "30 , наймем.\n",
      "31 Какой стек? - Хранилище Postgres, Superset для визуализации, airflow.\n",
      "32 Что еще важно? - Если ты ищешь готовый технологический стек и тех кто будет тебе говорить как надо делать работу, то это не ко мне. У нас тут пока аналитический дикий запад. Кто лучше разбирается в процессе, данных, тот и рулит.\n",
      "33 Вопросы в личку. Резюме на \n",
      "34 avnikolayev@ibs.ru\n",
      "35  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "9\n",
      "Input down salary value:\n",
      "130\n",
      "Input top salary value:\n",
      "180\n",
      "\n",
      "0 I.  \n",
      "1   \n",
      "2   \n",
      "3   \n",
      "4 ПРОЕКТ: Большие Данные (супермассивы данных) – ТОП-3 Телеком Компания\n",
      "5  \n",
      "6 Вакансия:\n",
      "7 1)  \n",
      "8   \n",
      "9  Аналитик Big Data, Data Scientist, Researcher (Hadoop)\n",
      "10 Локация – Москва\n",
      "11 Количество вакансий – 3\n",
      "12 Отдается предпочтение кандидатам с опытом участия в соревнованиях Kaggle!\n",
      "13  \n",
      "14   \n",
      "15   \n",
      "16 II.  \n",
      "17   \n",
      "18   \n",
      "19   \n",
      "20 ПРОЕКТ: Большие Данные (супермассивы данных) – ТОП-5 IT-Компания (банкинг)\n",
      "21  \n",
      "22 Вакансии: Санкт-Петербург\n",
      "23  \n",
      "24 2)  \n",
      "25   \n",
      "26  Руководитель Разработки (Java, Hadoop)\n",
      "27 Количество  \n",
      "28 вакансий: 1\n",
      "29  \n",
      "30 3)  \n",
      "31   \n",
      "32  Аналитик Супермассивов данных \\ Data Scientist (с использованием Hadoop, Spark, Machine Learning)\n",
      "33 Количество  \n",
      "34 вакансий: 1\n",
      "35  \n",
      "36 4)  \n",
      "37   \n",
      "38  Разработчик (Java, Hadoop)\n",
      "39 Количество  \n",
      "40 вакансий: 2\n",
      "41  \n",
      "42 Вакансии: Москва\n",
      "43  \n",
      "44 5)  \n",
      "45   \n",
      "46  Аналитик Супермассивов данных \\ Data Scientist (с использованием Hadoop, Spark, Machine Learning)\n",
      "47 Количество  \n",
      "48 вакансий: 1\n",
      "49  \n",
      "50 6)  \n",
      "51   \n",
      "52  Разработчик (Java, Hadoop)\n",
      "53 Количество  \n",
      "54 вакансий: 2\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 по-моему да, но я не уверен, что 1) именно этот; 2) что они выберут именно этот вариант\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Ищем аналитиков в Центр Анализа Данных при Правительстве Москвы.\n",
      "1 Что придется делать:\n",
      "2 - проводить explorative-анализ данных (\n",
      "3 \"а что у них там вообще происходит?\"\n",
      "4 )\n",
      "5 - строить прогнозы (\n",
      "6 \"сколько придет посетителей?\", \"сколько потребуется денег?\"\n",
      "7 );\n",
      "8 - выявлять аномалии (\n",
      "9 \"где было необычно много посещений?\", \"кто произвел неожиданно большие расходы?\"\n",
      "10 );\n",
      "11 - писать понятный, поддерживаемый, переиспользуемый код (преимущественно на python'е)\n",
      "12 - регулярно встречаться с заказчиками и на понятном языке рассказывать им: что делали, чего уже достигли, что пока не получилось и как будем это исправлять.\n",
      "13 Требования:\n",
      "14 - знать в вузовском объеме математику и статистику;\n",
      "15 - хотеть узнать еще больше математики и статистики;\n",
      "16 - любить каждый день программировать на python'е;\n",
      "17 - не бояться разговаривать с людьми, которые с вами не согласны.\n",
      "18 На собеседовании вам точно встретятся:\n",
      "19 - дифференцирование;\n",
      "20 - максимальное правдоподобие;\n",
      "21 - дерево и лес;\n",
      "22 - градиентный спуск;\n",
      "23 - экспоненциальное семейство распределений;\n",
      "24 и ими дело, конечно же, не ограничится.\n",
      "25 Условия работы:\n",
      "26 - комфортный офис на тихой улочке рядом с м.Курская с диванами, кофе, чаем и учебным классом;\n",
      "27 - постоянное обучение анализу данных и конструктивному взаимодействию с людьми;\n",
      "28 - структурированная система повышения квалификации и зарплаты;\n",
      "29 - небольшой 300-ядерный кластер со 100 ТБ хранилищем;\n",
      "30 - серьезные и сложные задачи, которые требуют знаний и ответственности;\n",
      "31 - возможен неполный рабочий день для студентов и аспирантов.\n",
      "32 Начальная зарплата: 75-120 тыс.руб.\n",
      "33 Можем взять сразу 3-5 человек. Так что не стесняйтесь.\n",
      "34 Резюме отправлять на \n",
      "35 careers@analysiscenter.ru\n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "32\n",
      "Input down salary value:\n",
      "75\n",
      "Input top salary value:\n",
      "120\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 8 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 3 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 просто у меня есть знакомые, которые работают в рисках, они особо ничем не занимаются, но получают 100 - 150к\n",
      "1 а тут человек реально что-то делать будет)\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 19 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 11 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @tutk1ja\n",
      "1 : ну, по тому что я вижу - предполагается, что соискатель таки уже имеет phd\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 вообщем вот: \n",
      "1 Tasks in Customer Intelligence:\n",
      "2 - work collaboratively to generate customer insights from different data sources\n",
      "3 - develop models to automatically derive these insights from constantly updating data sources\n",
      "4 - implement interactive visualizations to communicate these insights internally\n",
      "5 Requirements:\n",
      "6 - Proficiency in R / Python or similar\n",
      "7 - Machine Learning / Statistics theoretical and practical knowledge\n",
      "8 - ability to communicate results clearly and concisely\n",
      "9 - natural curiosity about how to find business value in data\n",
      "10 - big plus: experience with Flask / Django / JS / D3.js\n",
      "11 - big plus: experience with pair programming\n",
      "12 - big plus: experience with different data storage technologies (relational databases, Hadoop, NoSQL)\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 https://hh.ru/vacancy/16435417\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Доброго дня!\n",
      "1 Коллеги попросили вбросить вакансию \n",
      "2 https://hh.ru/vacancy/17187767\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 22 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 5 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 #вакансия #bigdata_teamlead #москва #толькоофис #\n",
      "1 Название позиции: \n",
      "2 Big Data Team Lead\n",
      "3 Компания: \n",
      "4 BCS Digital\n",
      "5  (проект в рамках ФГ БКС)\n",
      "6 Место: \n",
      "7 Москва, м. Проспект Мира\n",
      "8 , 6 мин пешком.\n",
      "9 О проекте:\n",
      "10 Мы создаем цифровую платформу B2C для наших банков - партнеров и для физических лиц. Продуктовая команда создает marketplace и экосистему для простого доступа к финансовым инструментам партнеров: кредитам, ипотеке, автокредитам, рефинансированию, сервисам оптимизации расходов, системам лояльности и так далее.\n",
      "11 Продуктовая команда создает marketplace и экосистему для простого доступа к финансовым инструментам. Мы ожидаем, что наш ИТ - продукт, созданный на стыке маркетинга, скоринга, больших данных, поведенческого анализа, может изменить привычный уклад вещей в банковском секторе. Пользовательский интерфейс, удобство использования - это первое, что увидит наш клиент, и это очень важно для нас.\n",
      "12 Работа в проекте сочетает в себе дух стартапа и поддержку одной из крупнейших финансовых групп в России.\n",
      "13 Сейчас, как и полагается стартапу, продукт находится в стадии MVP, поэтому придётся много тестировать, переделывать и запускать.\n",
      "14 Задачи:\n",
      "15  - Управление командой DataScience, методология, построение моделей.\n",
      "16  - Превращение сырых данных в информацию, необходимую для принятия решений (например рекламные сети, логи посещений, события систем и проч).\n",
      "17  - Проведение исследований в области предиктивных моделей, создания экспертных систем для оценки рисков, сегментации клиентов и оптимизации бизнес-процессов на основе больших объемов данных и машинного обучения.\n",
      "18  - Визуализация и представление результата исследований, проверки гипотез.\n",
      "19  - Подготовка экспертного заключения по проблематике, проведенного анализа.\n",
      "20  - Эксплуатация и развитие автоматизированных систем для анализа данных на основе современного инструментария DataScience (Python, Apache Spark, Jupyter, Zeppelin, R, etc..)\n",
      "21  - Развитие внутренней инфраструктуры для обработки, хранения и анализа данных, построения моделей.\n",
      "22  - Обогащение имеющихся наборов данных.\n",
      "23 Требования:\n",
      "24  - Хорошее знание Python или R и соответствующих модулей.\n",
      "25  - Опыт управления командами DataScience по таким задачам как: работа с сырыми данными, построение моделей, анализ результатов, формулировка гипотез и их валидация.\n",
      "26  - Отличные знания в областях математической статистики, теории вероятностей и методов оптимизации.\n",
      "27  - Знания в области машинного обучения, понимание методологии построения моделей и метрик оценки их качества.\n",
      "28  - Реальный опыт построения систем с использованием инструментов (Kafka, Spark, Flume, Hadoop, Cassandra, HBase или их аналогов)\n",
      "29 Условия:\n",
      "30  \n",
      "31  - 200К - 300К gross + квартальные премии;\n",
      "32  - Амбициозные задачи, свобода в принятии решений; \n",
      "33  - Одна из ключевых ролей проекта;\n",
      "34  Контакты \n",
      "35 sipatovaAS@msk.bcs.ru\n",
      "36  Анастасия Сипатова\n",
      "37 +74957855336 добавочный 5418\n",
      "38 telegram: \n",
      "39 @foxy\n",
      "40 _fox\n",
      "41  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "31\n",
      "Input down salary value:\n",
      "200\n",
      "Input top salary value:\n",
      "300\n",
      "\n",
      "0 Коллега-разраб ( php) до этого \"работал\" в глассдор, прошел все круги ада собеседований, а потом сидел 3 месяца дома без работы, так как проектов не было. Обещаниями кормили знатно.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Коллеги! Есть довольно интересная вакансия на позицию CTO\n",
      "1 Требования:\n",
      "2 • Высшее техническое образование / КТН или выше / наличие научных публикаций в плюс / Математическая подготовка, знание теории вероятности, математической статистики и машинного обучения \n",
      "3 • Опыт использования СУБД MS SQL Server, MySQL, PostgreSQL, MongoDB\n",
      "4 • Участие в Kaggle / победы \n",
      "5 • Владение методологиями PMBoK, Scrum, Kanban, умение комбинировать их элементы\n",
      "6 • знание MapReduce и Hadoop\n",
      "7 • Готовность к командировкам \n",
      "8 • Стрессоустойчивость \n",
      "9 • Опыт руководства подразделениями и сотрудниками\n",
      "10 •  \n",
      "11   \n",
      "12   \n",
      "13  Python, java, C++ \n",
      "14 По деньгами от 200 000 руб. оформление по ТК РФ / соц пакет\n",
      "15 (писать можно на почту \n",
      "16 daniil.danin@socialcraft.ru\n",
      "17  | 8 903 516 76 42)\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "14\n",
      "Input down salary value:\n",
      "200\n",
      "Input top salary value:\n",
      "200\n",
      "\n",
      "0 @artem\n",
      "1  нашему боту лука вроде нравится, но он видно не оч впечатлен\n",
      "2 natekin [11:38 PM]  \n",
      "3 @markov-bot\n",
      "4  что про луку думаешь?\n",
      "5 markov-botBOT [11:38 PM]  \n",
      "6 @natekin\n",
      "7 : что про свои сны и воспоминания, но не долго, а вот если тебя всё будет хорошо\n",
      "8 natekin [11:38 PM]  \n",
      "9 @markov-bot\n",
      "10  они крутые?\n",
      "11 markov-botBOT [11:38 PM]  \n",
      "12 @natekin\n",
      "13 : было же, там еле касается стены не твои и это будет мой финальный ролл аюмии на 47 b 47\n",
      "14 natekin [11:38 PM]  \n",
      "15 @markov-bot\n",
      "16  тоесть у луки норм дл?\n",
      "17 markov-botBOT [11:38 PM]  \n",
      "18 @natekin\n",
      "19 : у меня норм лал 0 тоже как настоящий нищук решил выебнуться не самым большим х*ем останешься ты\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Всем привет! \n",
      "1 В Розничном бизнесе ПАО Сбербанк (г. Москва) в команду по разработке моделей развития сети подразделений (офисы/устройства самообслуживания) всё ещё требуются: \n",
      "2 • \n",
      "3  \n",
      "4  \n",
      "5  \n",
      "6 Data Scientist \n",
      "7 • \n",
      "8  \n",
      "9  \n",
      "10  \n",
      "11 Data Engineer - руководитель проекта.\n",
      "12 Вам предстоит работа в команде, где есть  \n",
      "13 методологи, аналитики, разработчики. Команда занимается анализом геоаналитики и данных по транзакциям в системах Банка, разрабатывает модели развития сети подразделений с использованием математической статистики и машинного обучения.  \n",
      "14   \n",
      "15   \n",
      "16   \n",
      "17   \n",
      "18   \n",
      "19   \n",
      "20   \n",
      "21   \n",
      "22   \n",
      "23   \n",
      "24   \n",
      "25   \n",
      "26   \n",
      "27   \n",
      "28   \n",
      "29   \n",
      "30   \n",
      "31   \n",
      "32   \n",
      "33   \n",
      "34   \n",
      "35   \n",
      "36   \n",
      "37   \n",
      "38   \n",
      "39   \n",
      "40   \n",
      "41   \n",
      "42   \n",
      "43   \n",
      "44   \n",
      "45   \n",
      "46   \n",
      "47   \n",
      "48   \n",
      "49   \n",
      "50   \n",
      "51   \n",
      "52   \n",
      "53   \n",
      "54   \n",
      "55   \n",
      "56   \n",
      "57   \n",
      "58   \n",
      "59   \n",
      "60   \n",
      "61   \n",
      "62   \n",
      "63   \n",
      "64   \n",
      "65   \n",
      "66   \n",
      "67   \n",
      "68   \n",
      "69   \n",
      "70   \n",
      "71   \n",
      "72   \n",
      "73   \n",
      "74   \n",
      "75   \n",
      "76   \n",
      "77   \n",
      "78   \n",
      "79   \n",
      "80   \n",
      "81   \n",
      "82   \n",
      "83   \n",
      "84   \n",
      "85   \n",
      "86   \n",
      "87   \n",
      "88   \n",
      "89   \n",
      "90   \n",
      "91   \n",
      "92   \n",
      "93   \n",
      "94   \n",
      "95   \n",
      "96   \n",
      "97   \n",
      "98   \n",
      "99   \n",
      "100   \n",
      "101   \n",
      "102   \n",
      "103   \n",
      "104   \n",
      "105   \n",
      "106   \n",
      "107   \n",
      "108   \n",
      "109   \n",
      "110   \n",
      "111   \n",
      "112   \n",
      "113   \n",
      "114   \n",
      "115   \n",
      "116   \n",
      "117   \n",
      "118   \n",
      "119   \n",
      "120   \n",
      "121   \n",
      "122   \n",
      "123   \n",
      "124   \n",
      "125   \n",
      "126   \n",
      "127   \n",
      "128   \n",
      "129   \n",
      "130   \n",
      "131   \n",
      "132   \n",
      "133   \n",
      "134   \n",
      "135   \n",
      "136   \n",
      "137   \n",
      "138   \n",
      "139   \n",
      "140   \n",
      "141   \n",
      "142   \n",
      "143   \n",
      "144   \n",
      "145   \n",
      "146  \n",
      "147 1. \n",
      "148  \n",
      "149  \n",
      "150  \n",
      "151 Data Scientist\n",
      "152 Функциональные обязанности: \n",
      "153 • \n",
      "154  \n",
      "155  \n",
      "156  \n",
      "157 Проверка гипотез на сверхбольших массивах данных с использованием методов машинного обучения\n",
      "158 • \n",
      "159  \n",
      "160  \n",
      "161  \n",
      "162 Выявление ключевых факторов и причинно-следственных связей \n",
      "163 • \n",
      "164  \n",
      "165  \n",
      "166  \n",
      "167 Статистический анализ данных\n",
      "168 • \n",
      "169  \n",
      "170  \n",
      "171  \n",
      "172 Построение сложных математических моделей\n",
      "173 • \n",
      "174  \n",
      "175  \n",
      "176  \n",
      "177 Работа с Teradata\n",
      "178 Для построения моделей будут применяться алгоритмы:\n",
      "179 ∙  \n",
      "180   \n",
      "181 Классификации на основе логистической регрессии, XGBoost, Random Forest;\n",
      "182 ∙  \n",
      "183   \n",
      "184 Регрессионные деревья решений;\n",
      "185 ∙  \n",
      "186   \n",
      "187 Кластерный анализ, поиск аномалий;\n",
      "188 ∙  \n",
      "189   \n",
      "190 Анализ транзакций Банка для построения моделей и т.д.\n",
      "191 Основные требования:\n",
      "192 - Опыт работы data scientist’ом от года\n",
      "193 - Высшее образование (математика/физика/программирование);\n",
      "194 - Опыт решения задач machine learning;\n",
      "195 - Уверенные навыки работы с  \n",
      "196 Python (jupyter, numpy, scipy, pandas, scikit-learn, xgboost);\n",
      "197 - Опыт работы с базами данных (Teradata, MS SQL), навыки работы с массивами данных;\n",
      "198 - Преимуществом будут высокие места на соревнованиях по Data Science \n",
      "199 - Хорошие коммуникативные навыки\n",
      "200 - Хорошие аналитические способности\n",
      "201 2. \n",
      "202  \n",
      "203  \n",
      "204  \n",
      "205 Data Engineer\n",
      "206 Функциональные обязанности: \n",
      "207 • \n",
      "208  \n",
      "209  \n",
      "210  \n",
      "211 Отвечает за развитие и доработку моделей по управлению сетью подразделений, внедрение изменений в существующую модель,\n",
      "212 • \n",
      "213  \n",
      "214  \n",
      "215  \n",
      "216 Проектирование витрин данных, создание процедур, анализ полученных результатов\n",
      "217 • \n",
      "218  \n",
      "219  \n",
      "220  \n",
      "221 Работа с базами данных в SQL (Teradata), оптимизация существующего кода,\n",
      "222 • \n",
      "223  \n",
      "224  \n",
      "225  \n",
      "226 Применение алгоритмов машинного обучения для доработки модели,\n",
      "227 • \n",
      "228  \n",
      "229  \n",
      "230  \n",
      "231 Построение сложных математических моделей, исследование зависимостей на большом объеме информации \n",
      "232 Основные требования:\n",
      "233 • \n",
      "234  \n",
      "235  \n",
      "236  \n",
      "237 Опыт работы Data Engineer’ом от 3 лет\n",
      "238 • \n",
      "239  \n",
      "240  \n",
      "241  \n",
      "242 Опыт работы с базами данных (Teradata, MS SQL) от 3 лет, навыки оптимизации процедур;\n",
      "243 • \n",
      "244  \n",
      "245  \n",
      "246  \n",
      "247 Опыт самостоятельной реализации крупных проектов;\n",
      "248 • \n",
      "249  \n",
      "250  \n",
      "251  \n",
      "252 Опыт Team Lead от года;\n",
      "253 • \n",
      "254  \n",
      "255  \n",
      "256  \n",
      "257 Высшее образование (математика/физика/программирование);\n",
      "258 • \n",
      "259  \n",
      "260  \n",
      "261  \n",
      "262 Уверенные навыки работы с  \n",
      "263 Python (jupyter, numpy, scipy, pandas, scikit-learn, xgboost);\n",
      "264 • \n",
      "265  \n",
      "266  \n",
      "267  \n",
      "268 Хорошие коммуникативные навыки;\n",
      "269 • \n",
      "270  \n",
      "271  \n",
      "272  \n",
      "273 Высокие аналитические способности;\n",
      "274 • \n",
      "275  \n",
      "276  \n",
      "277  \n",
      "278 Преимуществом будут высокие места на соревнованиях по Data Science\n",
      "279 Мы предлагаем:\n",
      "280 • \n",
      "281  \n",
      "282  \n",
      "283  \n",
      "284 Возможность участвовать в амбициозных проектах по развитию сети крупнейшего Банка страны;\n",
      "285 • \n",
      "286  \n",
      "287  \n",
      "288  \n",
      "289 Разнообразные и интересные задачи в области моделирования бизнес-показателей;\n",
      "290 • \n",
      "291  \n",
      "292  \n",
      "293  \n",
      "294 Возможности для профессионального и личностного роста в динамично развивающемся коллективе большой компании;\n",
      "295 • \n",
      "296  \n",
      "297  \n",
      "298  \n",
      "299 Профессиональное развитие в области работы с данными;\n",
      "300 • \n",
      "301  \n",
      "302  \n",
      "303  \n",
      "304 Конкурентная заработная плата: \n",
      "305 • \n",
      "306  \n",
      "307  \n",
      "308  \n",
      "309 для Data Scientist 120-180 т.р.  \n",
      "310 (по договоренности+ годовой бонус)\n",
      "311 • \n",
      "312  \n",
      "313  \n",
      "314  \n",
      "315 для Data Engineer - от 220 т.р. (по договоренности+ годовой бонус)\n",
      "316 • \n",
      "317  \n",
      "318  \n",
      "319  \n",
      "320 Cоциальный пакет (ДМС, НПФ, льготные путевки)\n",
      "321 Заинтересованных просим отправлять вопросы и резюме по адресу \n",
      "322 AVProkofyev@sberbank.ru\n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "315\n",
      "Input down salary value:\n",
      "220\n",
      "Input top salary value:\n",
      "220\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 5 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Data Scientist at IBM in Moscow: \n",
      "1 http://u.rfer.us/IBEeYB3G8S\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 4 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 3я вакансия и правда была релевантна\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Всем привет! Я к опять вам с работой.\n",
      "1 Итак, снова Центр Компетенций Больших Данных в компании Техносерв ищет сотрудников!\n",
      "2 Разыскиваются дата сатанисты в рангах от junior до middle. Есть вариант стажерских позиций, но чуть позже (мы согласовываем).\n",
      "3 Техносерв — это такой большой интегратор, который занимается ВСЕМ (от строительства до систем интеллектуального видеонаблюдения).\n",
      "4 В нашем подразделении атмосфера сильно отличается от большого Техносерва. Условно - мы стартап внутри интегратора. У нас не применяются ни корпоративный стиль одежды, ни учет приходов и уходов, ни запреты на использования рабочего ноутбука в личных целях, ни прочая специфика \n",
      "5 :galera:\n",
      "6  или \n",
      "7 :rospil:\n",
      "8 . Как только мы станем уверены в сотруднике, то сможем его на 1-2 дня в неделю отпускать поработать из дома. Мы устраиваем хакатоны для всей компании (чуть позже - начнем внешние), регулярные собрания подразделения по теме дел ЦК, текущих проектов и всякого интересного. Собираемся поставить PS4 в переговорку (пока свои притаскиваем, недавно в VR резались) \n",
      "9 :slightly_smiling_face:\n",
      "10 Направление деятельности — консалтинг с уклоном в продуктизацию решений. Флагманский проект — BigData для маркетинга Аэрофлота. Есть куча всяких разных веселых пресейлов и парочка собственных продуктов.\n",
      "11 Стараемя жить по Scrum, если заказчик не требует иного. Работаем в Jira, Confluence, Bitbucket/GitLab, TeamCity.\n",
      "12 Мы НЕ занимаемся ляпаньем проектов на скорость. У нас собственные продажники и руководители проектов в команде. Отмечу, что overtime у нас в этом году случался всего пару раз.\n",
      "13 У нас есть уютный кластер на 192 ядра и 1 Тб памяти с хадупом, спарком и цеппелином. Даже даск я туда вкорячил!\n",
      "14 У нас исторически все любят Python (кроме главного разработчика), в проде все на скале или джаве.\n",
      "15 Расположение — м. Академическая (+автобус) или МЦК Крымская, БЦ Березки. Прям напротив ДАС МГУ.\n",
      "16 К лету случится переезд всей компании из четырех офисов к м.Павелецкая, на Дербеневскую набережную, в модный офис в стиле лофт. Или не случится, если коллективно откажемся.\n",
      "17 Из минусов в офисе отмечу отсутствие нормальной кухни (но можно сбегать в столовую через двор БЦ, пинаем собственника БЦ на разрешение микроволновки) и тупняк с закупкой чая/кофе (решаем, пока скидываемся).\n",
      "18 Из сложностей - полиграф и собеседование с психологом. Мы стараемся убрать полиграф, так как он исторически был введен для контроля продавцов (ну и кроме того, это лженаучная херота!)\n",
      "19 :electric_plug:\n",
      "20  — дело тонкое. Примерно пролегает между 80к и 180к рублей. Стажер — до 60к.\n",
      "21 В первый год на ДМС 50% скидка после испытательного срока (вместе со стоматологией получается 15к с рассрочкой на финансовый год, апрель–апрель). Фитнес со скидкой 50% (правда, это илитная Зебра, так что в итоге цена 15–30к). Можно выбирать онлайн и оффлайн курсы в размере ~30к рублей (с хорошим обоснованием можно и больше) на полгода.\n",
      "22 Резюме в личку. \n",
      "23 :troll:\n",
      "24 , \n",
      "25 :bombanoolo:\n",
      "26  и \n",
      "27 :be-a-man:\n",
      "28  - в \n",
      "29 :thread-please:\n",
      "30 . А еще можете меня найти на \n",
      "31 :christmas_tree:\n",
      "32 .\n",
      "33  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "20\n",
      "Input down salary value:\n",
      "80\n",
      "Input top salary value:\n",
      "180\n",
      "\n",
      "0 Локация - Новосибирск\n",
      "1 Зарплата до 350К\n",
      "2 О нас:\n",
      "3 JarSoft.ru\n",
      "4   \n",
      "5 – компания, более 15 лет специализирующаяся на разработке AdTech систем для Web и Мобильных платформ. Наша команда обладает широкой экспертизой в разработке высоконагруженных распределенных систем, работой с большими базами данных.\n",
      "6 О проекте:\n",
      "7 Около двух лет мы работаем с \n",
      "8 Persona.ly\n",
      "9  и разрабатываем для проекта систему показа рекламы (DSP), обрабатывающую до 500 тысяч запросов в секунду. Система получает траффик от других систем SSP (агрегаторы траффика с рекламных площадок) по OpenRTB протоколу.\n",
      "10 SSP системы проводят аукцион каждого запроса на рекламный баннер в реальном времени среди всех подписанных агрегаторов рекламных компаний (DSP). В аукционе побеждает DSP, предложившая лучшую цену. Наша система работает с мобильным траффиком и получает вознаграждение от рекламодателей за установку приложений, а платит SSP за показ рекламных баннеров, отсюда и вытекает бизнес задача оптимизации расходов.\n",
      "11 Задачи:\n",
      "12 В настоящий момент перед нами две актуальные задачи по Data Science:\n",
      "13 1. \n",
      "14  \n",
      "15  \n",
      "16  \n",
      "17 Определение фейкового траффика, а он составляет около половины от всех запросов.\n",
      "18 2. \n",
      "19  \n",
      "20  \n",
      "21  \n",
      "22 Разработка и внедрение алгоритмов определения цены конкретного показа конкретному пользователю. Необходимо вычислять вероятность установки данным пользователем рекламируемого приложения, основываясь на истории запросов и поведения, а также учитывать проведение аукционов и необходимость предложения лучшей цены среди участвующих DSP.\n",
      "23 Для каждой рекламной компании предполагается разработка собственных алгоритмов расчета цены и определения фейкового траффика, т.к. их эффективность зависит от контента. Следовательно, подразумевается создание и постоянное совершенствование Data Science алгоритмов.\n",
      "24 Что есть для решения задач:\n",
      "25 логи по триллиону запросов на показ баннера;\n",
      "26 результат трех миллиардов наших ставок на показ баннера;\n",
      "27 есть вся информация, доступная по OpenRTB;\n",
      "28 инструментарий для анализа логов;\n",
      "29 инструментарий для внедрения алгоритмов в систему;\n",
      "30 Кто нам нужен:\n",
      "31 Для решения этих задач, а также формирования, обучения и управления командой, мы рады обсудить возможность работы со специалистами, имеющими:\n",
      "32 Успешный опыт работы в крупных проектах по анализу данных / машинному обучению;\n",
      "33 Академическое/техническое образование, дающее отличное знание дисциплин математической логики, теории вероятностей, математической статистики;\n",
      "34 Python / Scala\n",
      "35 Hadoop / Hive /Pig / Spark\n",
      "36 Знание английского языка, достаточное для коммуникаций с англоговорящими коллегами.\n",
      "37 Мы предлагаем:\n",
      "38 Мы готовы обсудить ЛЮБЫЕ финансовые ожидания;\n",
      "39 Возможен частичный Home Office. Критерий качества работы – выполнение задач;\n",
      "40 Свобода выбора инструментария и формирования команды;\n",
      "41 Помощь иногородним при переезде.\n",
      "42 Дополнительные инструкции\n",
      "43 Если Вас, это заинтересовало, пожалуйста свяжитесь с нами по \n",
      "44 hh@jarsoft.ru\n",
      "45 Нас не заинтересуют: Предложения об удаленной работе и предложения услуг от Data Science компаний!\n",
      "46 https://moikrug.ru/vacancies/1000047303\n",
      "47 https://www.linkedin.com/pulse/нужен-team-lead-data-scientist-до-350000-новосибирск-stepan-pakhanov/?published=t\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "1\n",
      "Input down salary value:\n",
      "350\n",
      "Input top salary value:\n",
      "350\n",
      "\n",
      "0 Компания:\n",
      "1  \n",
      "2  \n",
      "3  \n",
      "4  \n",
      "5 Стартап Tess. (\n",
      "6 https://mytess.com\n",
      "7 ) - это чатбот для женщин, который помогает с подбором одежды. Стартап находится в Лондоне. \n",
      "8 Детали:\n",
      "9  \n",
      "10  \n",
      "11  \n",
      "12  \n",
      "13 У нас есть доступ к подробному описанию каждой вещи у ритейлеров. Пользователь начинает диалог с ботом, где у него уточняются стилевые предпочтения (мини-анкета). После этого бот спрашивает, какие вещи ищет пользователь и дает рекомендации - краткие описания и ссылки на вещи у ритейлеров. 90% проекта - это рекомендательная система. Для бота используется \n",
      "14 Wit.ai\n",
      "15 . Проект находится в начальной стадии - рекомендации базируются на GBDT(Gradient Boosting Decision Tree). Больше всего кода по подготовке фич, которые берутся из текстового описания вещей. Используется scikit-learn, numpy, pandas. \n",
      "16  \n",
      "17  \n",
      "18  \n",
      "19  \n",
      "20 Вакансия:\n",
      "21  \n",
      "22  \n",
      "23  \n",
      "24  \n",
      "25 Ищем Senior Data Scientist (Python), который бы взял на себя создание рекомендательной системы. Поскольку по сути ищем Team Lead-a, то руки у него будут полностью развязаны - можно использовать любой подход, который будет необходим для выполнения задач. Очевидно, что у кандидата должен быть опыт в создании рекомендательных или поисковых систем.\n",
      "26  \n",
      "27  \n",
      "28  \n",
      "29  \n",
      "30 Условия:\n",
      "31  \n",
      "32  \n",
      "33  \n",
      "34  \n",
      "35 1. Оклад 300+\n",
      "36  \n",
      "37  \n",
      "38  \n",
      "39  \n",
      "40 2. Опцион в стартапе\n",
      "41  \n",
      "42  \n",
      "43  \n",
      "44  \n",
      "45 3. Работа удаленная. Со временем возможен переезд в Англию.\n",
      "46 Контакты:\n",
      "47  \n",
      "48  \n",
      "49  \n",
      "50  \n",
      "51 - можно тут, в личку\n",
      "52  \n",
      "53  \n",
      "54  \n",
      "55  \n",
      "56 - Александр, \n",
      "57 alex@mytess.com\n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "35\n",
      "Input down salary value:\n",
      "300\n",
      "Input top salary value:\n",
      "300\n",
      "\n",
      "0 Всем привет! Вакансия не моя, но хорошие ребята из \n",
      "1 NAIVE\n",
      "2  - Neural Artificial Intelligence Video Editor (стартап) ищут:\n",
      "3 - \n",
      "4 специалиста по Deep Learning и Computer Vision\n",
      "5 , который так же как и NAIVE, любит создавать новые алгоритмы для обработки изображений, аудио и видео, нацелен на развитие и открыт для новых идей и решений. Они разрабатывают приложение по автоматическому монтажу видео для видеографов и простых пользователей, которые хотят получить емкий ролик по итогам отснятого материала с материалов.\n",
      "6 - \n",
      "7 удаленка\n",
      "8  / \n",
      "9 Москва\n",
      "10  офис 5 мин от м. Бауманская\n",
      "11 Обязанности:\n",
      "12 Исследование и разработка DL алгоритмов обработки видео и аудио, интеграция с решения для пользовательского интерфейса и тестирования работы для ускорения монтажа.\n",
      "13 Требования:\n",
      "14 - Опыт работы более двух лет;\n",
      "15 - Знание опыт программирования на Python, C++;\n",
      "16 - Знание Machine learning, deep learning, neural networks, tensorflow/theano/caffe;\n",
      "17 - Опыт работы с Computer vision относительно одной из следующих задач: распознавание и индексация лиц на видео; семантическая сегментация объектов; повышение разрешения и/или устранения размытия на видео; определение действий на видео.\n",
      "18 - Опыт работы с одним из следующих инструментов будет вашим плюсом: Tensorflow, Caffe, Theano.\n",
      "19 - Хорошая математическая подготовка (math & data modeling, algorithms, regression analysis, statistics, probability theory).\n",
      "20 NAIVE предлагает:\n",
      "21 оклад + бонусы + работу над молодым стартапом с последующим выходом на европейский и американский рынок\n",
      "22 - junior 60-90 или неполный день\n",
      "23 - middle (one task) 100-140\n",
      "24 - senior 140-180\n",
      "25 Но все очень зависит от опыта, загруженности и числа задач. Возможен и частичный и полный рабочий день (5-ти дневная рабочая неделя. Рабочий день ненормированный, присутственное время: 11\n",
      "26 :00-16:\n",
      "27 00)\n",
      "28 Просим при отклике на вакансию указывать ваши зарплатные ожидания (за полный месяц), основные проекты над которыми работали и описание что в этих проектах делали. Писать Илье Макарову на \n",
      "29 iamakarov@hse.ru\n",
      "30  или @iamakarov\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "22\n",
      "Input down salary value:\n",
      "60\n",
      "Input top salary value:\n",
      "90\n",
      "\n",
      "0 не меньше 1 недели, на сколько помню.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Нужна помощь в реализации классификатора, если кому интересно в свободное время повозится с ворд2век + LSTM и заодно подзаработать пишите. Вкратце суть задачи такая: Есть 100Млн предложений, надо сделать ворд2век словарь из этих данных,  \n",
      "1 потом запилить LSTM, обучить на размеченных данных  \n",
      "2 (думаю их где-то около 500К ) и классифицировать все эти 100млн. (разбить на бренд, категория, модель) нужна точность в 90% готов дать денег ))  \n",
      "3 ~ 100K рублей.\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "3\n",
      "Input down salary value:\n",
      "100\n",
      "Input top salary value:\n",
      "100\n",
      "\n",
      "0 4) вилка?\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Есть небольшой конкурс от МАГАТЭ по компьютерому зрению (подсчет твэлов по видео) с призом 5-7K евро:\n",
      "1 Краткое описание на русском: \n",
      "2 https://new.vk.com/feed?w=wall741057_1893\n",
      "3 Описание на сайте ООН: \n",
      "4 https://www.ungm.org/Public/Notice/45386\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @semenoffalex\n",
      "1 :  \n",
      "2 смотря чем заниматься, например жсники легко получают щас 4-5к$ удаленно; в датасаенсе конесно труднее найти работу удаленно, но если найти то збс; я как то нашел и 4 года отработал так\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 7 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Привет! А кто бы согласился часов на 40 учебный курс по машинному обучению для аудиторов провести? Сложность основная в том, что контингент довольно разнородный, около 50 человек, от вчерашних студентов до бабулек. Поэтому желателен бОльший уклон в прикладную часть, чем в теорию. Территориально - Москва. Какая именно компания - в личном общении.\n",
      "1 Об оплате готов в достаточно широких пределах обсуждать (от 10К/день, верхней границы нет).\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 народ мне снова ай нид ёр хелп\n",
      "1 короче нужны рекомендации\n",
      "2 за успешную рекомендацию много денег\n",
      "3 Люксофт сейчас ищет BigData топа для нового направления,  \n",
      "4 это такое core чувак, нужен опыт 5-10 лет, европейское или американское гражданство предпочтительно. там и пресейл, и архитектура и проч\n",
      "5 подробное описание скину попозже, ато мне сейчас только маякнули\n",
      "6 денег очень очень много, пока рассматриваем разные варианты\n",
      "7 есть кто у вас знакомые?\n",
      "8 мне можно скидывать в лс ссылки или почты, рекомендации могут быть анонимными (когда о рекомендателе не сообщается)\n",
      "9  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @iesh00a\n",
      "1 : маловато будет? \n",
      "2 :trollface:\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rancher/.local/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 я не владею точными цифрами по з/п. По моим ощущениям это 30-300. Т.е. я могу представить людей, кого мы бы взяли на верхний и кого на нижний предел.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 я не владею точными цифрами по з/п. По моим ощущениям это 30-300. Т.е. я могу представить людей, кого мы бы взяли на верхний и кого на нижний предел.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @nyjonx\n",
      "1  а зарплата от 0 до \\inf ?\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Ищу джуниор дата-аналитика/data-scientistа в команду. Фуллтайм. Можно вообще без опыта работы. \n",
      "1 Нужен человек, который заинтересован в дс и мл, cфера интернет-рекламы. Компания международная (\n",
      "2 weborama.com\n",
      "3 ), со штабом в Париже, мы же собираем команду в московском офисе. Текущие задачи —  \n",
      "4 кластеризация пользователей, cкоринговые модели (предсказать покупку), attribution models, анализ поведения пользователей в сети, рекомендательные системы. Из более редких — встречаются задачи по обработке текстов или звонков (которые тоже, впрочем, переводили в тексты).\n",
      "5 Ожидаем, что кандидат знаком с Python/R и соответствующими библиотеками для анализа данных и умеет пользоваться гуглом. Под текущие сервисы уже есть заготовки и примеры в ноутбуках. Есть статьи и идеи, что мы хотим реализовать в будущем. Рассмотрим кандидатов без опыта работы. Нам важно, чтобы человек был увлечен дс, проявлял инициативу, не стеснялся придумывать и реализовывать новые продукты и сервисы и предлагать их нам и клиентам. Всему что умеем — научим, будет круто, если научат и нас. Мы это заметим и поощрим \n",
      "6 :slightly_smiling_face:\n",
      "7 Как у нас все устроено.\n",
      "8 Хранилище данных на локальном сервере + bigquery. Данные под проект готовим сами, для этого достаточного базового sql и базовых shell-команд. Например, прогревать логи. C этим поможем.  \n",
      "9 Далее — аналитика и построение моделей — пока хватает локальных ноутбуков и памяти 32 гб, или ресурсов гугла, но при необходимости — арендуем/проапгрейдим железо. В случае кластеризации и других проектов, направленных на поиск инсайтов и получения нового знания для клиента, делаем отчет в виде презезентации или, чаще, интерактивного дэшборда (bime, google data studio и прочие) и презентуем. То есть можно провести исследование, а затем съездить в Икею на встречу и выступить c результатами перед топами, сразу увидеть реакцию. Но такие встречи как раз по желанию, если вы не ловите кайф от общения, заставлять не будем) Цикл таков: взять задачу, понять, спросить, cделать, визуализировать результаты, если есть, что визуализировать, cдать проект. Если считаете, что ваше дело написать ноутбук, а визуализировать и вытащить результаты и выводы по вашему проекту в дэшборд или презентацию должен кто-то другой, будет неловко. У нас не очень большая команда, и каждый ведет свой проект самостоятельно вплоть до финиша. Но на любом этапе работы мы всегда готовы помочь, побрейнштормить или объяснить столько, cколько потребуется. Мы вообще довольно милые. \n",
      "10 Всегда рады и интересный онлайн-курс в свободное от проектов время пройти, и статью интересную обсудить, и в конкурсах поучаствовать, и поощрить любое саморазвитие. Регулярно участвуем в конференциях и с удовольствием отправим тебя выступать на любую. Команда в московском офисе у нас маленькая, зато в ней очень легко проявить себя, наработать опыт и подняться по карьерной лестнице \n",
      "11 :slightly_smiling_face:\n",
      "12  \n",
      "13 Позиция стартовая, поэтому готовы предложить от 50к на испытательный срок подходящему кандидату вообще без опыта работы. (Обсуждаем индивидуально). После прохождения испытательного срока оклад повышается (+10к сразу, далее — по результатам). Оформление по ТК, офис в бизнес-центре на Комсомольской, бесплатные обеды (!), чай, кофе, печеньки. Нанять готовы вчера.  \n",
      "14 Писать можно в личку или на \n",
      "15 t.suvorina@weborama.com.ru\n",
      "16 , телеграм — tsuvery\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "13\n",
      "Input down salary value:\n",
      "50\n",
      "Input top salary value:\n",
      "50\n",
      "\n",
      "0 Вот совсем стартовая должность, кроме знаний SPSS ничего особо не требующая. Правда и деньги небольший (70k). Может кому из студентов подойдёт: \n",
      "1 http://career.ru/vacancy/13306880?query=TNS\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "0\n",
      "Input down salary value:\n",
      "70\n",
      "Input top salary value:\n",
      "70\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 2 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 SteppeChange (\n",
      "1 http://steppechange.com/\n",
      "2 ) – российско – американская компания, занимающаяся аутсорсингом крупных проектов по обработке данных в сфере BI, e-commerce, cloud  \n",
      "3 и др.\n",
      "4 Офис компании располагается в Калифорнии, в Силиконовой долине. Существует коло 7 лет. В России отдел разработки существует около 4х лет. Центральный офис компании находится в Санкт-Петербурге, а часть команды работает удаленно из Москвы и других городов.\n",
      "5 Проект:  \n",
      "6 Разработка «data management» платформы для европейского телекоммуникационного оператора, аналитика поступающих данных.\n",
      "7 Задачи специалиста:\n",
      "8 -  \n",
      "9 Извлечение, проверка и очистка данных;\n",
      "10 - Разработка алгоритмов для работы с большими объемами структурированных и неструктурированных данных;\n",
      "11 - Визуализация результатов;\n",
      "12 Инструменты:\n",
      "13 - R/ Python/ SAS + Matlab;\n",
      "14 - В зависимости от задач инструменты варьируются от простых линейных регрессий до передовых методов машинного обучения, анализа графов и т.д.\n",
      "15 Вроде выглядит неплохо, если кому интересно - пишите мне в личку.\n",
      "16  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Всем привет! Букавально пару дней назад в соседней команде, которая только формируется, открылась интересная вакансия. Хочу поделиться для видимости, может быть кому-то интересно будет.\n",
      "1 Software Development Engineer (Berlin)\n",
      "2 https://www.amazon.jobs/en/jobs/544672\n",
      "3 Суть вакансии вот в этой строчке.\n",
      "4 >\n",
      "5 “We are looking for Software Development Engineers (SDE’s) to help us building an optimized version of a deep learning library (MXNet) for mobile and IoT devices”\n",
      "6 От себя\n",
      "7 По целеуказаниям от Алекса Смолы и других не менее уважаемых людей уровня ICML и NIPS Program Committee надо будет хорошенько доработать MXNet для работы на мобильных устройствах. Если есть хорошие знания С / С++ и желание внести свой вклад в развитие инструментов для deep learning, то милости просим. Если еще есть и понимание, как работают популярные фреймворки изнутри, то настоятельно рекомендую. Резюме можно закидывать через сайт или мне в приватный чат, а я уже передам дальше по назначению. На вопросы, по возможности, буду рад ответить в треде. По вилке точно не скажу, но предположу, что на Glassdoor представлены корректные цифры. C оформлением визы и переездом компания помогает.\n",
      "8  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 3 месяца искали, перепробовали кучу народа. В тех редких случаях, когда специалист был действительно стоящий, возникали проблемы с тем, что человеку было не интересно у них работать. В итоге одного нашли и неспешно ищут ещё одного. Если у кого-то есть интерес, могу скинуть контакты человека, под чьим руководством предстоит работать.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Вакансия от близких друзей\n",
      "1 Data Scientist в Биоинформатике\n",
      "2 Компания:\n",
      "3  В биоинформатический стартап ProteiQ (\n",
      "4 proteiq.com\n",
      "5 ) (протеомика для спортивной медицины и лекарственных препаратов) нужен биоинформатик или дата сайнтист с опытом программирования и интересом в биохимии и биологии.\n",
      "6 Работа удаленная, головной офис в Минске.\n",
      "7 Задачи:\n",
      "8 — построение статистических моделей с элементами машинного обучения;\n",
      "9 — подготовка данных для статистического анализа (нормализация, батч-коррекция)\n",
      "10 — анализ экспериментальных данных большой размерности (PCA, Factor Analysis, Lasso / Ridge regressions, Bayesian Models, sPLS-DA);\n",
      "11 — визуализация результатов.\n",
      "12 Требования:\n",
      "13 — математическое или физическое образование с хорошим пониманием теории вероятности, биоинформатика;\n",
      "14 — опыт в статистическом анализе данных, визуализации;\n",
      "15 — знание R и/или Python;\n",
      "16 Плюсом будет опыт в разработке, практические знания Байесовской статистики.\n",
      "17 Зарплата:\n",
      "18  $1500 — $2300\n",
      "19 Контакт:\n",
      "20  Резюме и вопросы на почту \n",
      "21 vita@blastim.ru\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "18\n",
      "Input down salary value:\n",
      "1500\n",
      "Input top salary value:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2300\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 14 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 попросили запостить, все оформлено ок\n",
      "1 Вакансия Hadoop Engineer в Санкт-Петербурге \n",
      "2 от 100,000\n",
      "3 Компания \n",
      "4 https://vk.com/dins_spb\n",
      "5 Мы ищем талантливых и целеустремленных инженеров для работы в Санкт-Петербургском центре разработок. \n",
      "6 Вам предстоит: \n",
      "7 • Решать различные задачи по анализу данных используя Hive, Impala и Spark \n",
      "8 • Проектировать и создавать ETL в HDFS/Hive и Vertica как с помощью Java/Scala так и с помощью Talend \n",
      "9 • Тестировать созданные процессы \n",
      "10 Наши ожидания: \n",
      "11 • Знание принципов работы Hadoop, MR и HDFS \n",
      "12 • Опыт работы с Hive \n",
      "13 • У вас есть опыт разработки на Java/Scala \n",
      "14 • Умение создавать Oozie Workflow \n",
      "15 • Вы уверенный пользователь Linux \n",
      "16 • Знание Английского языка и возможность общаться с коллегами из США \n",
      "17 Будет плюсом: \n",
      "18 • Опыт работы с Apache Spark \n",
      "19 • Опыт работы с Talend \n",
      "20 • Знание Vertica \n",
      "21 • Умение создавать отчеты в Tableau \n",
      "22 Мы предлагаем: \n",
      "23 • Индексируемую заработную плату. \n",
      "24 • 100% оплату больничного. \n",
      "25 • Отпуск 28 календарных дней, оплачиваемый 100% в соответствии с текущей ставкой. \n",
      "26 • Медицинское сопровождение (ДМС, офисный врач, стоматология). \n",
      "27 • Корпоративные обучающие программы, курсы английского языка. \n",
      "28 • Широкие возможности для самореализации, профессионального и карьерного роста. \n",
      "29 • Возможность командировок и дальнейшей работы в зарубежных представительствах компании (в т.ч. H1-B США, Филиппины, Китай). \n",
      "30 • Комфортные условия работы, современный бизнес-центр, удобные кресла, велопарковку, оборудованные кухни, чай, кофе, прохладительные напитки и сладости. \n",
      "31 • Корпоративные праздники, выезды, спорт. \n",
      "32 • Офис в 10-ти минутах ходьбы от метро. \n",
      "33 • Иногородним кандидатам предоставляется Relocation Bonus и помощь в поиске жилья в Санкт-Петербурге. \n",
      "34 Свои резюме присылайте по адресу \n",
      "35 job@dins.ru\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 3 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 13 others\n",
      "2 . Also, \n",
      "3 qwerasdf\n",
      "4  left.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Senior/Lead Data Scientist\n",
      "1  at Kayzen\n",
      "2 Location:\n",
      "3  Berlin, Germany\n",
      "4 Who we are\n",
      "5 Kayzen powers the world’s best mobile marketing teams to take programmatic in-house. Built on the three key pillars of performance, transparency, and control, Kayzen is a software platform which enables leading app developers, agencies and entrepreneurs to run programmatic user acquisition, retargeting and upper funnel campaigns in-house. With engineering teams across Berlin and Bangalore, we work on some of the most complex problems in ad-tech building scalable systems listening to 60bn daily ad requests from 1bn+ unique users worldwide. Kayzen platform is based on sophisticated network of microservices accessible via API and elegant user interface.\n",
      "6 Responsibilities:\n",
      "7 – Build and enhance precision of our prediction models which has a direct impact on marketer’s campaigns globally\n",
      "8 – Design and develop algorithmic solutions and models for mission-critical problems, delivering high-accuracy and performance in data extraction\n",
      "9 – Contribute in all phases of the Product Development Lifecycle\n",
      "10 – Create efficient solutions and methodologies to address problems related to Real Time Bidding (RTB) such as bid optimization, publisher quality, audience expansion, fraud detection and prevention and more\n",
      "11 – Optimize implementations for maximum speed, performance and scalability\n",
      "12 Requirements:\n",
      "13 – Excellent programming skills - (at least one of) Python/Java\n",
      "14 – Experience with ML tools and libraries such as PySpark, Vowpal Wabbit, Scikit-learn, R, Spark, TensorFlow\n",
      "15 Strong background in learning algorithms (multi-class, classifications, decision trees, support vector machines and deep learning)\n",
      "16 – Experience with Unix/Linux\n",
      "17 – A willingness to dive deep, experiment rapidly and get things done\n",
      "18 – Attention to detail, data accuracy, and quality of output\n",
      "19 – Being passionate about creating great products and experiences for our customers\n",
      "20 – Strong analytical skills are necessary as the work involves projecting outcomes and isolating issues that need to be resolved to make programs more effective\n",
      "21 – 3+ years of experience applying machine learning and NLP to solving real-world problems\n",
      "22 – High levels of creativity and quick problem-solving capabilities, a self-starter with goal-driven focus\n",
      "23 – Ad-tech industry experience preferred\n",
      "24 – Fluent English\n",
      "25 What do we offer?\n",
      "26 – An opportunity to work in the exciting and growing mobile ad-tech space\n",
      "27 – You get valuable insights into mobile marketing, entrepreneurship and have a high impact on shaping the expansion and success of Kayzen across the globe\n",
      "28 – You get an opportunity to be responsible for and manage your own projects\n",
      "29 – You work directly with decision makers and have an impact in the organization\n",
      "30 – You experience an excellent learning culture\n",
      "31 – You are part of a fun, international team of outstanding talents\n",
      "32 – You enjoy a competitive remuneration package and much more\n",
      "33 Salary range\n",
      "34 €60K–€90K yearly\n",
      "35 Interested? Write us at \n",
      "36 vladimir@kayzen.io\n",
      "37 .\n",
      "38  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "34\n",
      "Input down salary value:\n",
      "60\n",
      "Input top salary value:\n",
      "90\n",
      "\n",
      "0 А в Касперском забавные hr-ы. Прислали письмо на текущую почту и почту которой я пользовался 5 лет назад (в копии)\n",
      "1 >\n",
      "2 Петр, добрый день!\n",
      "3 >\n",
      "4 Как у вас идут дела?\n",
      "5 >\n",
      "6 Я хотел бы поинтересоваться у вас, насколько вы сейчас открыты к обсуждениям предложений о работе?\n",
      "7 >\n",
      "8 Дело в том, что мы ищем в Лабораторию Касперского разработчика BigData (описание во вложении), вам такого >рода занятие может быть интересным?\n",
      "9 >\n",
      "10 А вообще к нашей компании как относитесь? J\n",
      "11 >\n",
      "12 Заранее спасибо за ваш ответ!\n",
      "13 >\n",
      "14  … но откуда у вас моя почта? даже две ...\n",
      "15 (edited)\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 и это навевает мысль о том, что хотят нанять человека за копейки, приманивая обещанием помочь с натурализацией через 10 лет\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Под \"быть настоящим математиком\" подразумевается понимать, как работают инструменты в DS, а не просто уметь запустить xgboost, к примеру. \n",
      "1 @notabene\n",
      "2  2 последних пункта - да, это как раз подходит под видение компании. Ещё лучше - уметь предложить нестандартный подход к решению задачи. Первые два пункта будут огромным плюсом, но всё же опциональны.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Data Scientist\n",
      "1 Dubai, United Arab Emirates\n",
      "2 dubizzle.com\n",
      "3  \n",
      "4 (OLX Group / Naspers Classifieds)\n",
      "5 What you will be doing:\n",
      "6 * Driving research activities, discovering new trends and patterns.\n",
      "7 * Solving key prediction and classification problems.\n",
      "8 * Working on forecasting, anomaly detection, and time-series analysis.\n",
      "9 * Building item-to-item and user-to-item recommendation systems.\n",
      "10 * Developing internal standalone data-serving products in collaboration with Engineering team.\n",
      "11 * Providing support for data-driven decisions.\n",
      "12 Who we’re looking for:\n",
      "13 * 2+ years of relevant experience in Analytics.\n",
      "14 * Bachelor’s or Master’s degree in Computer Science, Mathematics, Physics, Information Technology or related areas.\n",
      "15 * Hands-on experience with Machine Learning algorithms, such as Linear and Logistic Regression, Naïve Bayes, Gradient Boosting, Neural Networks.\n",
      "16 * Proficiency in Python for Data Analysis.\n",
      "17 * Knowledge of SQL and experience working with relational databases;\n",
      "18 * Good visualization and presentation skills.\n",
      "19 * Knowledge of statistical analysis and experience with A/B testing will be a plus;\n",
      "20 * Experience in E-commerce or Internet projects will be a plus.\n",
      "21 What we’ll give you:\n",
      "22 * A great international environment of Software Engineers, Analysts, and Data Scientists.\n",
      "23 * Ability to work with a large amount of valuable data.\n",
      "24 * An opportunity to become a part of a data-driven company.\n",
      "25 * Empowerment to come up with new ideas and projects to monetize on data and execute on it.\n",
      "26 * A career in a big international company and travel opportunities;\n",
      "27 * Competitive tax-free salary and great benefits.\n",
      "28 More information\n",
      "29 : \n",
      "30 https://www.joinolx.com/careers/job/1082117\n",
      "31 Salary\n",
      "32 : 7-8k$ (25k-30k AED). \n",
      "33 Depends on experience.\n",
      "34  (edited) \n",
      "Is message a vacancy post? (y/n)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "Input a number of salary line:\n",
      "32\n",
      "Input down salary value:\n",
      "7\n",
      "Input top salary value:\n",
      "8\n",
      "\n",
      "0 привет\n",
      "1 человек ищет работу\n",
      "2 посмотрите кто кого ищет щас \n",
      "3 большой опыт работы руководителем проектов различных направлений, последний год-полтора - \"big data\" и всякое такое. учит математику и python чтобы и руками уметь работать, пока прошел этак 20% пути по его словам\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Москва с Питером - наверное как раз на те самые 500-1000 (или скорее процентов 25 от зп). а с другими городами типа Нижнего Новгорода будет уже наверное в два раза\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 @evgenyorlov\n",
      "1 : \n",
      "2 http://www.superjob.ru/research/articles/111737/analitik-big-data/\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 [LaTeX] [opensource] [офтопик]\n",
      "1 Всем привет! Нам нужно доработать один из пакетов LaTeX: (\n",
      "2 https://github.com/latex-g7-32/latex-g7-32\n",
      "3 ).\n",
      "4 Денег у меня немного, около 10K, зато проектом будет \n",
      "5 можно и нужно\n",
      "6  поделиться с окружающими. В идеале — вообще сделать Pull Request в основной репозиторий (желательно так, чтобы там его приняли = )\n",
      "7 Кто хочет помочь прогрессивной общественности писать отчёты по-человечески — вот моя почта: \n",
      "8 alexey.golovizin@yandex.ru\n",
      "9 P.S. Увы, сам сделать не могу: плохо в LaTeXе разбираюсь, только как пользователь. \n",
      "10 P.P.S. Знаю, что это офтопик, но внутренний голос мне подсказывает, что здесь таки есть людей, которые умеют в LaTeX = )\n",
      "11  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 выглядит, как задача не для w2v и lstm\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Machine Learning Engineer (Shanghai)\n",
      "1 BuyInt is AI based matching system that matches all kinds of business demands. It can automatically find, understand and match business demands for companies worldwide. Since 2013, we have been exploiting artificial intelligence technologies to reach completely automatic M&A process that consists of everything from opportunity recognition, screening, matching to outcome delivery. \n",
      "2 Requirements:\n",
      "3 - MSc or Higher Degree in Data science, IT, Computer Science or related major\n",
      "4 - Strong knowledge of ML algorithm from a theoretical and implementation perspective\n",
      "5 - Knowledge of ML algorithm for NLP implementation\n",
      "6 - Familiar with deep learning, decision tree learning, association rule learning, knowledge of SVM, similarity and metric learning, rule based machine learning, reinforcement learning, artificial neural networks (CNN/RNN), search ranking, collaborative filtering, implementation of matching model\n",
      "7 - Able to modify and optimize already implemented algorithms\n",
      "8 - Familiar with supervised learning algorithms\n",
      "9 Salary: 4000 $ - 7000 $\n",
      "10 All questions about position ask please by phone \n",
      "11 8925-381-4219\n",
      "12  or by email: \n",
      "13 soninaeugenia@gmail.com\n",
      "Is message a vacancy post? (y/n)\n",
      "y\n",
      "Input a number of salary line:\n",
      "9\n",
      "Input down salary value:\n",
      "4000\n",
      "Input top salary value:\n",
      "7000\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 3 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 3 others\n",
      "2 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Data Scientist\n",
      "1 Санкт-Петербург\n",
      "2  - центр разработки международной рекламной сети \n",
      "3 PropellerAds Ltd., CY\n",
      "4  (\n",
      "5 https://spb.hh.ru/vacancy/23655917\n",
      "6 )\n",
      "7 Компания разрабатывает и внедряет технологические решения обеспечивающие бесперебойную работу рекламной сети и позволяющие обрабатывать более 2 миллиардов событий в сутки.\n",
      "8 Команда \n",
      "9 Research & Analytics\n",
      "10  отвечает за исследование, создание и внедрение алгоритмов и моделей машинного обучения в сфере AdTech.\n",
      "11 Вот лишь несколько примеров задач которые мы решаем:\n",
      "12 - Предсказание CTR и Conversion Rate\n",
      "13 - Разработка алгоритмов ротации рекламы и стратегий Real Time Bidding\n",
      "14 - Оценка качества трафика\n",
      "15 - Сегментация пользователей по интересам\n",
      "16 - Рекомендация контента релевантного пользователю\n",
      "17 Требования\n",
      "18 :\n",
      "19 - Знание современных методов машинного обучения (regression, classification, unsupervised learning) и их теоретического обоснования\n",
      "20 - Умение эффективно доставать, подготавливать и анализировать данные\n",
      "21 - Практический опыт разработки на R и/или Python\n",
      "22 - Хорошее знание математической статистики и теории вероятности\n",
      "23 - Умение объяснить применяемые аналитические подходы не технической аудитории\n",
      "24 - Знание английского языка\n",
      "25 - Опыт работы в команде\n",
      "26 Дополнительным плюсом будет:\n",
      "27 - Опыт внедрения моделей машинного обучения в production системы\n",
      "28 Условия\n",
      "29 - Метро Петроградская \n",
      "30 - Заработная плата не имеет четких верхних границ, все зависит от кандидата\n",
      "31 Контакты\n",
      "32 : \n",
      "33 - Пишите мне в директ\n",
      "34 - Или HR -  \n",
      "35 a.tyltu@propellerads.net\n",
      "36  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 а что за RUB100?\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Да, это мой звездный час! Ну, Одноклассники, держитесь \n",
      "1 :simple_smile:\n",
      "2  Я  \n",
      "3 собеседовался в команду Дмитрия Бугайченко. И мое итоговое впечатление от \"серии собеседований\" и от интервьюеров осталось очень неприятным: искренне считаю, что со мной поступили некорректно. По итогам я написал негативные и очень подробные отзывы:\n",
      "4 1, Русскоязычный отзыв: \n",
      "5 http://orabote.net/feedback/show/id/326370\n",
      "6 2. Англоязычный отзыв: \n",
      "7 http://www.glassdoor.com/Interview/Mail-Ru-Group-Data-Mining-Engineer-Interview-Questions-EI_IE491626.0,13_KO14,34.htm\n",
      "8 Если у кого есть вопросы, то пожалуйста, отвечу.\n",
      "9  (edited) \n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 joined #_jobs along with \n",
      "1 alll\n",
      "2 . Also, \n",
      "3 unicod3\n",
      "4  left.\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n",
      "\n",
      "0 Всем привет,\n",
      "1 Объявление о наборе на PhD, подробности ниже.\n",
      "2 2 PhD Positions in Artificial Intelligence / Machine Learning / Deep Learning Applications\n",
      "3 The Text Machine Lab for Natural Language Processing at the Computer Science Department at the University of Massachusetts Lowell invites applications for two fully-funded PhD positions in the area of computational linguistics and machine learning, available immediately.  \n",
      "4  The lab conducts research in deep learning applications to a variety of problems in natural language processing.\n",
      "5 The Text Machine lab is currently being supported by over $1.4M  \n",
      "6 external/federal research grants from NSF, NIH, ARO, and the industry.  \n",
      "7 The current externally funded research projects are in the areas of text-based temporal reasoning, computational analysis of civil conflict and informational biases in social media, and predictive modeling of patient outcomes and disease trajectories using clinical text from the electronic health records.  \n",
      "8 Students also have many opportunities to collaborate with other high profile computer science and biomedical researchers in the Boston Metro areas, including MIT, Dartmouth College, Boston University, Brandeis University, and others.  \n",
      "9 More information about the lab can be found here: \n",
      "10 http://text-machine.cs.uml.edu\n",
      "11 .\n",
      "12 The University of Massachusetts Lowell is a tier 1 public research university with a national reputation in science, engineering and technology. UMass Lowell is located about 25 miles northwest of Boston in the high-tech corridor of Massachusetts. The Department of Computer Science currently has 17 tenured and tenure-track faculty members, 3 full-time lecturers, and a few adjunct instructors serving over 700 BS students, 161 MS students, and 77 PhD students. It also offers an MS in Information Technology online program with over 100 students. It offers bioinformatics options at all levels, a robotics minor, a data science option, and a PhD in computational mathematics. The Computer Science faculty has received approximately $9M in the last two years in external research funding from the NSF, DARPA, DOD, DHE, NIH, and corporations. The department has 6 NSF CAREER Award recipients. More information about the department can be found at \n",
      "13 http://www.cs.uml.edu/\n",
      "14 .\n",
      "15 MINIMUM QUALIFICATIONS\n",
      "16 -A Master's in Computer Science or related field.\n",
      "17 -A strong background in mathematics and solid coding skills.\n",
      "18 -Previous research experience in natural language processing or machine learning is a strong plus.\n",
      "19 To apply, please send your CV, research statement, a copy of your academic transcripts to Anna Rumshisky at \n",
      "20 arum@cs.uml.edu\n",
      "21 .\n",
      "Is message a vacancy post? (y/n)\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "sample_length = 100\n",
    "\n",
    "msg_dt_false = pd.DataFrame(columns=msg_dt.columns)\n",
    "msg_dt_unknown = msg_dt.loc[msg_dt['salary_line'].isnull()]\n",
    "while msg_dt_false.shape[0] < sample_length:\n",
    "    msg_dt_unknown_sample = msg_dt_unknown.sample(n=sample_length - msg_dt_false.shape[0]).apply(manual_check, axis=1)\n",
    "    msg_dt_false = msg_dt_false.append(msg_dt_unknown_sample[msg_dt_unknown_sample['salary1_line'].isnull()])\n",
    "    msg_dt_unknown.drop(msg_dt_unknown_sample.index[msg_dt_unknown_sample['salary_line'].notnull()], inplace=True)\n",
    "    msg_dt.loc[msg_dt_unknown_sample.index[msg_dt_unknown_sample['salary_line'].notnull()]] = msg_dt_unknown_sample[msg_dt_unknown_sample['salary_line'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ключевые слова**\n",
    "зарплата\n",
    "salary\n",
    "оклад\n",
    "компенсация\n",
    "з/п\n",
    "т.р.\n",
    "гросс\n",
    "net\n",
    "yearly\n",
    "\n",
    "**Валюты**\n",
    "RUB\n",
    "UAH\n",
    "AED\n",
    "BYN\n",
    "CAD\n",
    "MYR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_messages_clear_w_dt.json\",'w') as fout:\n",
    "    msg_dt.to_json(fout, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"salary_posts.json\",'w') as fout:\n",
    "    msg_dt_true.to_json(fout, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"non_salary_posts.json\",'w') as fout:\n",
    "    msg_dt_false.to_json(fout, compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lines dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(msg_df, special_symbols):\n",
    "        \n",
    "    cols = ['id',\n",
    "            'symbol_number', \n",
    "            'word_number', \n",
    "            'line_number', \n",
    "            'number_number', \n",
    "            'len_1_lines', \n",
    "            'len_2_lines', \n",
    "            'special_symbols',\n",
    "            'isVacancy']\n",
    "    \n",
    "    feat_df = pd.Series(0, index=cols)\n",
    "    \n",
    "    feat_df['id'] = msg_df['index']\n",
    "    \n",
    "    feat_df['symbol_number'] = len(msg_df['message'])\n",
    "    words = re.split(' |;|,|\\*|\\n|\\t', msg_df['message'])\n",
    "    lines = msg_df['message'].splitlines()\n",
    "    \n",
    "    feat_df['word_number'] = len(words)\n",
    "    \n",
    "    feat_df['line_number'] = len(lines)\n",
    "    \n",
    "    feat_df['number_number'] = len(msg_df['numbers'])\n",
    "    \n",
    "    feat_df['len_1_lines'] = len([x for x in words if len(x) == 1])\n",
    "    \n",
    "    feat_df['len_2_lines'] = len([x for x in words if len(x) == 2])\n",
    "    \n",
    "    for symbol in special_symbols:\n",
    "        feat_df['special_symbols'] += msg_df['message'].upper().count(symbol)\n",
    "        \n",
    "    if not np.isnan(msg_df['salary_line']):\n",
    "        feat_df['isVacancy'] = 1\n",
    "        \n",
    "    return feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"non_salary_posts.json\",'r') as fin:\n",
    "    msg_dt_false = pd.read_json(fin, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"salary_posts.json\",'r') as fin:\n",
    "    msg_dt_true = pd.read_json(fin, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index                                            author  \\\n",
      "0     195  https://opendatascience.slack.com/team/U78BSPA4X   \n",
      "1    1313  https://opendatascience.slack.com/team/U06J1LG1M   \n",
      "10     20  https://opendatascience.slack.com/team/UJXTLNABX   \n",
      "11    665  https://opendatascience.slack.com/team/U4BH7FUCV   \n",
      "12     18  https://opendatascience.slack.com/team/U2AJE72Q6   \n",
      "13    963  https://opendatascience.slack.com/team/U1NMUV093   \n",
      "14    369  https://opendatascience.slack.com/team/U27GFN6P7   \n",
      "15    812  https://opendatascience.slack.com/team/U0TRC9F1R   \n",
      "16    522  https://opendatascience.slack.com/team/UA7D8TN9F   \n",
      "17    445  https://opendatascience.slack.com/team/U1J5L3NDP   \n",
      "18   2142  https://opendatascience.slack.com/team/U1BMURR5G   \n",
      "19    737  https://opendatascience.slack.com/team/U7A55LS5A   \n",
      "2    1340  https://opendatascience.slack.com/team/U14CTBLFJ   \n",
      "20   1538  https://opendatascience.slack.com/team/U1LHE347N   \n",
      "21   2283  https://opendatascience.slack.com/team/U3LLR910E   \n",
      "22    243  https://opendatascience.slack.com/team/UDHTGEDDK   \n",
      "23   2271  https://opendatascience.slack.com/team/U0ZHGTXP1   \n",
      "24    233  https://opendatascience.slack.com/team/U1KPNKE4E   \n",
      "25    412  https://opendatascience.slack.com/team/U1J5L3NDP   \n",
      "26    314  https://opendatascience.slack.com/team/UCTJV9MUJ   \n",
      "27    266  https://opendatascience.slack.com/team/UBUCAUEFJ   \n",
      "28    965  https://opendatascience.slack.com/team/U3LLR910E   \n",
      "29    108  https://opendatascience.slack.com/team/UDG3FGKDE   \n",
      "3     727  https://opendatascience.slack.com/team/U0DKZHJ3C   \n",
      "30    911  https://opendatascience.slack.com/team/U1J5L3NDP   \n",
      "31    252  https://opendatascience.slack.com/team/U6FNTCDUG   \n",
      "32    352  https://opendatascience.slack.com/team/U6X746Q21   \n",
      "33    435  https://opendatascience.slack.com/team/UB4ENPBM3   \n",
      "34   1019  https://opendatascience.slack.com/team/U06J1LG1M   \n",
      "35    881  https://opendatascience.slack.com/team/U3Z5KPTRQ   \n",
      "..    ...                                               ...   \n",
      "72    539  https://opendatascience.slack.com/team/U1H61HG7J   \n",
      "73   2066  https://opendatascience.slack.com/team/U043ZLY35   \n",
      "74   1151  https://opendatascience.slack.com/team/U29SWDQRG   \n",
      "75    421  https://opendatascience.slack.com/team/UCAQ4078F   \n",
      "76    300  https://opendatascience.slack.com/team/U4CUQ0BK8   \n",
      "77      1  https://opendatascience.slack.com/team/UH0KSL4ER   \n",
      "78   1601  https://opendatascience.slack.com/team/U040HKJE7   \n",
      "79    287  https://opendatascience.slack.com/team/U04422XJL   \n",
      "8     818  https://opendatascience.slack.com/team/U6FNTCDUG   \n",
      "80    210  https://opendatascience.slack.com/team/UDL0CCV8C   \n",
      "81    123  https://opendatascience.slack.com/team/U1UV86WJU   \n",
      "82   2269  https://opendatascience.slack.com/team/U298B1T19   \n",
      "83   1808  https://opendatascience.slack.com/team/U041LH06L   \n",
      "84    188  https://opendatascience.slack.com/team/U4WMJEBJL   \n",
      "85   2252  https://opendatascience.slack.com/team/U3YHTURTK   \n",
      "86    854  https://opendatascience.slack.com/team/U14L7977T   \n",
      "87    532  https://opendatascience.slack.com/team/U8ZRJBV3J   \n",
      "88    875  https://opendatascience.slack.com/team/U5FUU47GA   \n",
      "89   2028  https://opendatascience.slack.com/team/U065WG554   \n",
      "9     419  https://opendatascience.slack.com/team/U5R9LKKRS   \n",
      "90   1867  https://opendatascience.slack.com/team/U33QMUM8C   \n",
      "91    873  https://opendatascience.slack.com/team/U04ELJ0FC   \n",
      "92    647  https://opendatascience.slack.com/team/U93Q2QAGK   \n",
      "93   2317  https://opendatascience.slack.com/team/U4Z433DKJ   \n",
      "94    943  https://opendatascience.slack.com/team/U041SDH03   \n",
      "95    766  https://opendatascience.slack.com/team/U0KQ5M6KX   \n",
      "96    742  https://opendatascience.slack.com/team/U6M1KDA4A   \n",
      "97     21  https://opendatascience.slack.com/team/U0R1EKDV3   \n",
      "98     87  https://opendatascience.slack.com/team/UCLL9256C   \n",
      "99    572  https://opendatascience.slack.com/team/U52330HTK   \n",
      "\n",
      "                                                 link  \\\n",
      "0   https://opendatascience.slack.com/archives/C04...   \n",
      "1   https://opendatascience.slack.com/archives/C04...   \n",
      "10  https://opendatascience.slack.com/archives/C04...   \n",
      "11  https://opendatascience.slack.com/archives/C04...   \n",
      "12  https://opendatascience.slack.com/archives/C04...   \n",
      "13  https://opendatascience.slack.com/archives/C04...   \n",
      "14  https://opendatascience.slack.com/archives/C04...   \n",
      "15  https://opendatascience.slack.com/archives/C04...   \n",
      "16  https://opendatascience.slack.com/archives/C04...   \n",
      "17  https://opendatascience.slack.com/archives/C04...   \n",
      "18  https://opendatascience.slack.com/archives/C04...   \n",
      "19  https://opendatascience.slack.com/archives/C04...   \n",
      "2   https://opendatascience.slack.com/archives/C04...   \n",
      "20  https://opendatascience.slack.com/archives/C04...   \n",
      "21  https://opendatascience.slack.com/archives/C04...   \n",
      "22  https://opendatascience.slack.com/archives/C04...   \n",
      "23  https://opendatascience.slack.com/archives/C04...   \n",
      "24  https://opendatascience.slack.com/archives/C04...   \n",
      "25  https://opendatascience.slack.com/archives/C04...   \n",
      "26  https://opendatascience.slack.com/archives/C04...   \n",
      "27  https://opendatascience.slack.com/archives/C04...   \n",
      "28  https://opendatascience.slack.com/archives/C04...   \n",
      "29  https://opendatascience.slack.com/archives/C04...   \n",
      "3   https://opendatascience.slack.com/archives/C04...   \n",
      "30  https://opendatascience.slack.com/archives/C04...   \n",
      "31  https://opendatascience.slack.com/archives/C04...   \n",
      "32  https://opendatascience.slack.com/archives/C04...   \n",
      "33  https://opendatascience.slack.com/archives/C04...   \n",
      "34  https://opendatascience.slack.com/archives/C04...   \n",
      "35  https://opendatascience.slack.com/archives/C04...   \n",
      "..                                                ...   \n",
      "72  https://opendatascience.slack.com/archives/C04...   \n",
      "73  https://opendatascience.slack.com/archives/C04...   \n",
      "74  https://opendatascience.slack.com/archives/C04...   \n",
      "75  https://opendatascience.slack.com/archives/C04...   \n",
      "76  https://opendatascience.slack.com/archives/C04...   \n",
      "77  https://opendatascience.slack.com/archives/C04...   \n",
      "78  https://opendatascience.slack.com/archives/C04...   \n",
      "79  https://opendatascience.slack.com/archives/C04...   \n",
      "8   https://opendatascience.slack.com/archives/C04...   \n",
      "80  https://opendatascience.slack.com/archives/C04...   \n",
      "81  https://opendatascience.slack.com/archives/C04...   \n",
      "82  https://opendatascience.slack.com/archives/C04...   \n",
      "83  https://opendatascience.slack.com/archives/C04...   \n",
      "84  https://opendatascience.slack.com/archives/C04...   \n",
      "85  https://opendatascience.slack.com/archives/C04...   \n",
      "86  https://opendatascience.slack.com/archives/C04...   \n",
      "87  https://opendatascience.slack.com/archives/C04...   \n",
      "88  https://opendatascience.slack.com/archives/C04...   \n",
      "89  https://opendatascience.slack.com/archives/C04...   \n",
      "9   https://opendatascience.slack.com/archives/C04...   \n",
      "90  https://opendatascience.slack.com/archives/C04...   \n",
      "91  https://opendatascience.slack.com/archives/C04...   \n",
      "92  https://opendatascience.slack.com/archives/C04...   \n",
      "93  https://opendatascience.slack.com/archives/C04...   \n",
      "94  https://opendatascience.slack.com/archives/C04...   \n",
      "95  https://opendatascience.slack.com/archives/C04...   \n",
      "96  https://opendatascience.slack.com/archives/C04...   \n",
      "97  https://opendatascience.slack.com/archives/C04...   \n",
      "98  https://opendatascience.slack.com/archives/C04...   \n",
      "99  https://opendatascience.slack.com/archives/C04...   \n",
      "\n",
      "                                              message  \\\n",
      "0   Всем привет! Компания ID R&D (\\nwww.idrnd.net\\...   \n",
      "1   коллеги, уникальная вакансия и не от мейла -) ...   \n",
      "10  Компания: \\nPoehali.ru\\n (\\nhttps://Poehali.ru...   \n",
      "11  Привет!\\nИщем в стартап по \\nDS\\n в медицине п...   \n",
      "12  Привет \\n:ods:\\nВ нашу флотилию, на дружествен...   \n",
      "13  Cherry Labs создает продукт для домашней безоп...   \n",
      "14  Наступила моя очередь. Наконец-то \\n:slightly_...   \n",
      "15  Всем привет.\\nВ команду ВК в Санкт - Петербург...   \n",
      "16  Привет! Мы открываем \\nшесть\\n PhD вакансий в ...   \n",
      "17  Нужен чёткий Data Engineer в МТС, Москва\\nРабо...   \n",
      "18  всем привет! мопед не мой, вопросы лучше задав...   \n",
      "19  Всем привет!\\nИщем Data Scientist в международ...   \n",
      "2                          Вилка, говорят, от 180 net   \n",
      "20  Data Scientist\\nЮнит монетизации в Avito разыс...   \n",
      "21  Привет, ODS. Мы нашли себе пару соратников зде...   \n",
      "22  Всем привет! Публикую вакансию, вилка в ней пр...   \n",
      "23  Всем привет! Есть вакансия в Харькове/Львове\\n...   \n",
      "24  Machine Learning Engineer\\n в \\nBrainGarden\\nВ...   \n",
      "25  Коллеги, апдейт!\\nОчень нужен Senior Software/...   \n",
      "26  Привет, друзья!\\nПринес вам сюда новую ваканси...   \n",
      "27  Всем привет! Ищем NLP Data Scientist в команду...   \n",
      "28  Привет, ODS. В связи с расширением списка зада...   \n",
      "29  Добрый день!\\nИщем человека который поможет со...   \n",
      "3   Всем привет! Вакансия от моих друзей:\\nКомпани...   \n",
      "30  Нужен Big Data Developer / Engineer в Home Cre...   \n",
      "31  Всем привет!\\nКуда: University of Oulu\\nКого: ...   \n",
      "32  Инженер Данных: парт-тайм стажер\\nЗП 30К-50К и...   \n",
      "33  Привет! Ищем ещё одного Data scientist / Quant...   \n",
      "34  коллеги, нужен напарник на небольшой проект\\n ...   \n",
      "35  Привет! Я тут довольно много флудил под ваканс...   \n",
      "..                                                ...   \n",
      "72  Всем привет!\\nВакансия в банке Тинькофф:\\nJuni...   \n",
      "73  Data Scientist, S7, Москва\\nS7 Group реализует...   \n",
      "74  @anokhinn\\n, когда добавлял меня в чатик, прос...   \n",
      "75  Hacking aging!\\nВсем привет! Мы ищем \\nBiomark...   \n",
      "76  Всем привет!\\nВакансия \\nSenior Data Scientist...   \n",
      "77  Всем привет! Ищем талантливых продакт-менеджер...   \n",
      "78  фуллтайм, рассматриваем от джуниоров до синьор...   \n",
      "79  [вакансия в Москве]\\nВсем привет! Мы в Joom, м...   \n",
      "8   Друзья! Открыты 2 позиции аспирантов в Deep Le...   \n",
      "80  Data Scientist / Специалист в Computer Vision\\...   \n",
      "81  название вакансии\\n: (1) \\nLead Data Scientist...   \n",
      "82  всем привет,\\nищем в команду Букмейта (\\nbookm...   \n",
      "83  Вот совсем стартовая должность, кроме знаний S...   \n",
      "84  Ищем нового сотрудника в отдел анализа данных ...   \n",
      "85  Привет всем!\\nКомпания MillionAgents (\\nmillio...   \n",
      "86  Всем привет! \\nВ компании Даталитика открыты в...   \n",
      "87  Всем привет, мопед мой.\\nКоротко о главном:\\n*...   \n",
      "88  Senior Data Scientist \\nBerlin\\nMicrosoft; To-...   \n",
      "89  Всем привет!\\nМосковский офис компании Visa пр...   \n",
      "9   Всем привет!\\nМопед не мой, коллеги с соседнег...   \n",
      "90  Привет, котаны! Ищется \\nДата-аналитик\\n (\\nDa...   \n",
      "91  Всем привет! Ищем к нам в Jetlore опытных и на...   \n",
      "92  Требуется:\\n Data Engineer\\nГород:\\n Москва\\nК...   \n",
      "93  Всем привет!\\nДля стартапа в области финансовы...   \n",
      "94  Всем привет!\\nИщем Analytics Team Lead в SEMru...   \n",
      "95  Краткосрочный проект для знающих R\\nBig intern...   \n",
      "96  Всем привет! Мои друзья из стартапа \\nhttps://...   \n",
      "97  Role:\\n ML Engineer/Data scientist\\nCompany:\\n...   \n",
      "98  Вакансия\\n: DS\\nУровень\\n: джун/мидл\\nГород\\n:...   \n",
      "99  :sberbank:\\n \\n:python:\\n \\n:tf:\\n \\n:book:\\n ...   \n",
      "\n",
      "                                              numbers       date      time  \\\n",
      "0                             [2, 3, 18, 150, 300, 7] 2019-02-06   5:21 PM   \n",
      "1                       [4, 1000026490, 300, 4, 6, 6] 2016-05-31   4:02 PM   \n",
      "10  [480, 510, 7, 3, 500, 24, 3, 4, 12, 20, 30, 3, 5] 2019-05-22   5:30 PM   \n",
      "11  [90, 140, 7, 903, 685, 33, 1, 8, 965, 212, 16,... 2018-03-13   1:38 AM   \n",
      "12                                      [2, 250, 300] 2019-05-21   5:45 PM   \n",
      "13                                          [3, 3200] 2017-06-05   4:31 PM   \n",
      "14         [2, 1, 9, 2, 4, 87, 110, 2, 3, 2, 3, 5, 7] 2018-09-26  12:38 AM   \n",
      "15                                  [100, 1804, 1804] 2017-10-26   3:11 PM   \n",
      "16                                            [13, 2] 2018-07-02  10:52 AM   \n",
      "17                    [150, 200, 30, 40, 180, 240, 3] 2018-09-04   8:55 PM   \n",
      "18                                     [100, 8, 3, 6] 2017-06-10   1:44 PM   \n",
      "19                                       [2000, 3500] 2018-01-09  10:36 AM   \n",
      "2                                               [180] 2016-05-24   4:23 PM   \n",
      "20                                  [3, 5, 8, 2, 120] 2017-01-11   7:51 PM   \n",
      "21             [40, 60, 3, 150, 120, 220, 9036609524] 2017-07-12  11:40 PM   \n",
      "22                             [200, 250, 390, 11, 3] 2018-12-24   4:33 PM   \n",
      "23                                          [1, 5, 2] 2017-06-03   3:05 PM   \n",
      "24                                         [100, 200] 2019-01-29   1:09 PM   \n",
      "25                            [180, 210, 216, 252, 3] 2018-09-16   1:59 PM   \n",
      "26                          [2, 2017, 2017, 150, 200] 2018-11-14  11:45 AM   \n",
      "27                                      [200, 260, 2] 2019-01-15   9:45 PM   \n",
      "28                     [3, 150, 120, 200, 9036609524] 2017-06-08   1:07 AM   \n",
      "29                                       [2500, 3000] 2019-03-04   1:28 PM   \n",
      "3                              [2013, 2018, 100, 250] 2018-02-07  11:27 PM   \n",
      "30                                     [100, 200, 12] 2017-07-19  10:14 PM   \n",
      "31  [2, 2, 4, 15, 2019, 2, 300, 1800, 15, 0, 95, 1... 2019-01-02   6:48 PM   \n",
      "32                                 [30, 50, 28378469] 2018-10-26   5:33 PM   \n",
      "33                             [2, 1, 2, 3, 200, 300] 2018-08-29  12:31 PM   \n",
      "34               [25, 500, 20, 500, 10, 3, 4, 15, 25] 2016-10-21  11:00 PM   \n",
      "35  [800, 900, 10, 1, 1, 161, 6751, 1, 800, 5, 20,... 2017-08-28  11:29 PM   \n",
      "..                                                ...        ...       ...   \n",
      "72                                [80, 150, 25746627] 2018-06-01  11:54 AM   \n",
      "73                                        [7, 7, 200] 2017-05-23   9:44 AM   \n",
      "74                                   [160, 200, 1423] 2016-11-22   7:24 PM   \n",
      "75                                  [3, 4, 250, 1914] 2018-09-24   3:05 PM   \n",
      "76  [1, 2, 3, 0, 1, 2, 3, 4, 5, 250, 350, 0, 1, 2,... 2018-11-29   6:40 PM   \n",
      "77                                      [2, 200, 250] 2019-05-29  12:46 PM   \n",
      "78                                         [100, 200] 2015-12-30   8:50 PM   \n",
      "79                            [100, 29028978, 250, 0] 2018-11-26   4:50 PM   \n",
      "8     [2, 2, 1, 2, 4, 4, 2, 300, 1750, 5600, 1, 4502] 2017-10-31   7:56 PM   \n",
      "80                [18, 1199126741, 3, 150, 0, 300, 0] 2019-02-13   9:45 PM   \n",
      "81  [1, 2, 1, 2, 3, 1, 180, 2, 150, 1, 1118, 10138... 2019-03-13  12:56 AM   \n",
      "82                       [1, 2, 3, 80, 130, 20637598] 2017-06-03   6:42 PM   \n",
      "83                                     [70, 13306880] 2015-10-15  11:56 AM   \n",
      "84                                     [112, 60, 130] 2019-02-04  10:36 AM   \n",
      "85                               [120, 150, 19913712] 2017-03-11   3:15 PM   \n",
      "86                                 [5, 200, 300, 250] 2017-09-04  10:02 AM   \n",
      "87                          [2000, 3000, 99, 99, 100] 2018-07-11   1:42 PM   \n",
      "88                      [4, 287202, 1051338, 80, 100] 2017-09-03  12:33 PM   \n",
      "89                           [150, 116270673, 934140] 2017-05-26   8:41 AM   \n",
      "9                                       [150, 250, 2] 2018-09-21   8:15 PM   \n",
      "90                               [2, 3, 100, 1, 2, 3] 2017-01-26   2:19 PM   \n",
      "91                           [2453410, 2, 2500, 4000] 2017-09-19  10:26 AM   \n",
      "92                                      [120, 250, 7] 2018-04-12  11:22 AM   \n",
      "93                              [9, 0, 18, 0, 200, 0] 2017-07-24   8:28 PM   \n",
      "94                  [21587141, 1, 0, 0, 100, 150, 92] 2017-06-29   1:35 PM   \n",
      "95                                     [5, 300, 1000] 2017-12-07   8:32 PM   \n",
      "96   [5, 3, 5, 6, 3, 5, 17, 9, 2, 40, 60, 3, 3, 5, 1] 2018-01-17   8:08 PM   \n",
      "97    [160, 0, 200, 0, 3, 4, 2, 7, 8, 495, 797, 2472] 2019-05-23   6:12 PM   \n",
      "98                            [30526946, 64, 70, 100] 2019-04-01  10:53 AM   \n",
      "99           [19, 180, 0, 300, 0, 7, 926, 782, 4, 80] 2018-05-21   5:15 PM   \n",
      "\n",
      "    salary_line     up_fork  low_fork  \n",
      "0            23         300       150  \n",
      "1             8  1000026490         4  \n",
      "10            7         510       480  \n",
      "11           13         140        90  \n",
      "12           50         300       250  \n",
      "13           29        3200      3200  \n",
      "14           11           2         2  \n",
      "15            6        1804       100  \n",
      "16           14           2         2  \n",
      "17            6         200       150  \n",
      "18           22           6         3  \n",
      "19            4        3500      2000  \n",
      "2             1         180       180  \n",
      "20          150         120       120  \n",
      "21            7          60        40  \n",
      "22            4         250       200  \n",
      "23           13           5         1  \n",
      "24           64         200       100  \n",
      "25           14         210       180  \n",
      "26           23         200       150  \n",
      "27            3         260       200  \n",
      "28           90         200       120  \n",
      "29            6        3000      2500  \n",
      "3            15         250       100  \n",
      "30            4         200       100  \n",
      "31           13           2         2  \n",
      "32            2          50        30  \n",
      "33           38         300       200  \n",
      "34            4          25        25  \n",
      "35           40           1         1  \n",
      "..          ...         ...       ...  \n",
      "72            7         150        80  \n",
      "73           54         200       200  \n",
      "74            5         200       160  \n",
      "75           27        1914       250  \n",
      "76           24           2         1  \n",
      "77           20         250       200  \n",
      "78            1         200       100  \n",
      "79            9         250       250  \n",
      "8            21           2         2  \n",
      "80           33         150       150  \n",
      "81           32           2         1  \n",
      "82           13         130        80  \n",
      "83            0          70        70  \n",
      "84           18         130        60  \n",
      "85           11         150       120  \n",
      "86          145         300       200  \n",
      "87           12        3000      2000  \n",
      "88           25         100        80  \n",
      "89            2   116270673       150  \n",
      "9             5         250       150  \n",
      "90           21           3         2  \n",
      "91           27        4000      2500  \n",
      "92           22         250       120  \n",
      "93           17         200       200  \n",
      "94           12         150       100  \n",
      "95           26        1000       300  \n",
      "96           40           5         5  \n",
      "97            8         160       160  \n",
      "98          114         100        70  \n",
      "99          175         180       180  \n",
      "\n",
      "[100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(msg_dt_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([msg_dt_false, msg_dt_true], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['id',\n",
    "        'symbol_number', \n",
    "        'word_number', \n",
    "        'line_number', \n",
    "        'number_number', \n",
    "        'len_1_lines', \n",
    "        'len_2_lines', \n",
    "        'special_symbols',\n",
    "        'isVacancy']\n",
    "train_feat = pd.DataFrame(columns=cols, index=msg_dt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = [\"EUR\",\"USD\",\"РУБ\",\"К\",\"ТЫС\",\"€\",\"$\",\"ДОЛЛАР\",\"ЕВРО\", \"RUB\", \"UAH\", \"AED\", \"BYN\", \"CAD\", \"MYR\", \"Т.Р.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_vectorized = lambda x: get_features(x, special_symbols)\n",
    "\n",
    "train_feat = train_df.apply(get_features_vectorized, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"salary_dataset.json\",'w') as fout:\n",
    "    train_feat.to_json(fout, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradBoost Salary Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_ctbst:\n",
    "    def __init__(self, objective='CrossEntropy'):\n",
    "        '''input:\n",
    "        objective - loss function\n",
    "        eval - metric for loggigng'''\n",
    "        self.objective = objective\n",
    "        self.model = None\n",
    "        '''Try to tune it'''\n",
    "        self.model_params = dict(\n",
    "            thread_count=8,\n",
    "            iterations=2000,\n",
    "            depth=8,\n",
    "#             bagging_temperature=0.33,\n",
    "#             learning_rate=0.1,\n",
    "#             l2_leaf_reg=3,\n",
    "#             random_strength=0.7,\n",
    "            loss_function=self.objective\n",
    "            )\n",
    "        self.training_params = dict(\n",
    "            use_best_model=True,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=10\n",
    "            )\n",
    "        \n",
    "    def _set_model_(self):\n",
    "        self.model = CatBoostClassifier()\n",
    "        assert self.objective in ['CrossEntropy', 'Logloss']\n",
    "        self.model.set_params(**self.model_params)\n",
    "        \n",
    "    def train(self, X_train, y_train, X_valid, y_valid):\n",
    "        train_cat_features_indices = np.where(X_train.dtypes != np.float)[0]\n",
    "        valid_cat_features_indices = np.where(X_valid.dtypes != np.float)[0]\n",
    "        '''setting pools without weights'''\n",
    "        ctbst_train_pool = Pool(data=X_train, label=y_train, cat_features=train_cat_features_indices)\n",
    "        ctbst_val_pool = Pool(data=X_valid, label=y_valid, cat_features=valid_cat_features_indices)\n",
    "        '''logging'''\n",
    "        print('Training Model CatBoost')\n",
    "        print('X_train = %s Y_train = %s' % (X_train.shape, y_train.shape))\n",
    "        print('X_valid = %s Y_valid = %s' % (X_valid.shape, y_valid.shape))\n",
    "        print()\n",
    "        '''training'''\n",
    "        self._set_model_()\n",
    "        self.model = self.model.fit(ctbst_train_pool,\n",
    "                                    eval_set=ctbst_val_pool,\n",
    "                                    **self.training_params)\n",
    "        '''feature importances'''\n",
    "        print('Top features')\n",
    "        feature_importances = self.model.get_feature_importance(ctbst_train_pool)\n",
    "        feature_names = X_train.columns\n",
    "        for score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n",
    "            print('{}: {}'.format(name, score))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise Exception('Train your model before')\n",
    "        print('Predicting Model CatBoost')\n",
    "        print('X = %s' % (X.shape,))\n",
    "        print()\n",
    "        X_cat_features_indices = np.where(X.dtypes != np.float)[0]\n",
    "        ctbst_data_pool = Pool(data=X, cat_features=X_cat_features_indices)\n",
    "        '''predict'''\n",
    "        prediction = self.model.predict(ctbst_data_pool, prediction_type='Probability')\n",
    "        '''get pred for 1 class'''\n",
    "        prediction = pd.Series(prediction[:, 1], index=X.index)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_type, target, features, eval='logloss', n_folds=4, seed=42):\n",
    "        self.model = model\n",
    "        self.train_type = train_type\n",
    "        self.target = target\n",
    "        self.features = features\n",
    "        self.eval = eval\n",
    "        self.n_folds = n_folds\n",
    "        self.seed = seed\n",
    "        \n",
    "    def _generate_folds_(self, data, val_ratio=0.2):\n",
    "        index = np.asarray(data.index)\n",
    "        n = index.size\n",
    "        if self.n_folds == 1:\n",
    "            random_state = np.random.RandomState(self.seed)\n",
    "            i_valid = random_state.choice(range(n), size=int(np.floor(n * val_ratio)), replace=False)\n",
    "            i_train = np.setdiff1d(range(n), i_valid, assume_unique=True)\n",
    "            folds = [(i_train, i_valid)]\n",
    "        else:\n",
    "            fold = KFold(n_splits=self.n_folds, shuffle=True, random_state = self.seed)\n",
    "            folds = []\n",
    "            for i_train, i_valid in fold.split(np.arange(n)):\n",
    "                folds.append((i_train, i_valid))\n",
    "        return folds\n",
    "    \n",
    "    def _get_fold_(self, data, fltr):\n",
    "        train = data.iloc[fltr[0]].reset_index(drop=True)\n",
    "        valid = data.iloc[fltr[1]].reset_index(drop=True)\n",
    "        return train, valid\n",
    "    \n",
    "    def _get_error_(self, Y, P):\n",
    "        assert Y.shape[0] == P.shape[0]\n",
    "        if self.eval == 'logloss':\n",
    "            error = log_loss(Y, P)\n",
    "        elif self.eval == 'roc-auc':\n",
    "            error = roc_auc_score(Y, P)\n",
    "        else:\n",
    "            raise Exception('Error: unknown eval = %s' % (self.eval,))\n",
    "        return error\n",
    "\n",
    "    def train(self, data):\n",
    "        print('Training with %s' % (self.train_type,))\n",
    "        print()\n",
    "        if self.train_type == 'validation':\n",
    "            self._train_with_validation_(data)\n",
    "        elif self.train_type == 'cross-validation':\n",
    "            self._train_with_cross_validation_(data)\n",
    "        else:\n",
    "            raise Exception('Error: unknown train type = %s' % (self.train_type,))\n",
    "            \n",
    "    def _train_basic_(self, train, valid):\n",
    "        X_train, y_train = train[self.features], train[self.target]\n",
    "        X_valid, y_valid = valid[self.features], valid[self.target]\n",
    "        model.train(X_train, y_train, X_valid, y_valid)\n",
    "        pred_df = model.predict(X_valid)\n",
    "        error = self._get_error_(y_valid, pred_df)\n",
    "        print('Error %s: %s' % (self.eval, error))\n",
    "        print()\n",
    "        return pred_df, error\n",
    "\n",
    "    def _train_with_validation_(self, data):\n",
    "        print('Train with validation...')\n",
    "        print()\n",
    "        folds = self._generate_folds_(data)\n",
    "        train, valid = self._get_fold_(data, folds[0])\n",
    "        pred_df, error = self._train_basic_(train, valid)\n",
    "    \n",
    "    def _train_with_cross_validation_(self, data):\n",
    "        errors = []\n",
    "        print('Train with cross-validation...')\n",
    "        print()\n",
    "        folds = self._generate_folds_(data)\n",
    "        print('Cross-validation %d folds' % (self.n_folds,))\n",
    "        print()\n",
    "        for i_fold in range(self.n_folds):\n",
    "            print(\"Fold = %d / %d\" % (i_fold + 1, self.n_folds))\n",
    "            print()\n",
    "            train, valid = self._get_fold_(data, folds[i_fold])\n",
    "            pred_df, error = self._train_basic_(train, valid)\n",
    "            errors.append(error)\n",
    "        print('Mean %s error on CV: %s' % (self.eval, np.mean(errors)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_ctbst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['symbol_number', \n",
    "        'word_number', \n",
    "        'line_number', \n",
    "        'number_number', \n",
    "        'len_1_lines', \n",
    "        'len_2_lines', \n",
    "        'special_symbols']\n",
    "target = 'isVacancy'\n",
    "\n",
    "trainer = Trainer(model=model,  train_type='cross-validation', target=target, \n",
    "                  features=feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_division = lambda x: (x.iloc[:180], x.iloc[180:])\n",
    "(train_feat, test_feat) = train_test_division(train_feat.sample(frac=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with cross-validation\n",
      "\n",
      "Train with cross-validation...\n",
      "\n",
      "Cross-validation 4 folds\n",
      "\n",
      "Fold = 1 / 4\n",
      "\n",
      "Training Model CatBoost\n",
      "X_train = (135, 7) Y_train = (135,)\n",
      "X_valid = (45, 7) Y_valid = (45,)\n",
      "\n",
      "Learning rate set to 0.047\n",
      "0:\tlearn: 0.6576332\ttest: 0.6634671\tbest: 0.6634671 (0)\ttotal: 28.9ms\tremaining: 57.8s\n",
      "10:\tlearn: 0.4300235\ttest: 0.4781311\tbest: 0.4781311 (10)\ttotal: 416ms\tremaining: 1m 15s\n",
      "20:\tlearn: 0.3288142\ttest: 0.4054306\tbest: 0.4054306 (20)\ttotal: 944ms\tremaining: 1m 28s\n",
      "30:\tlearn: 0.2815610\ttest: 0.3862701\tbest: 0.3859717 (29)\ttotal: 1.31s\tremaining: 1m 22s\n",
      "40:\tlearn: 0.2546585\ttest: 0.3845986\tbest: 0.3820099 (33)\ttotal: 1.77s\tremaining: 1m 24s\n",
      "50:\tlearn: 0.2334605\ttest: 0.3830020\tbest: 0.3807590 (44)\ttotal: 2.27s\tremaining: 1m 26s\n",
      "60:\tlearn: 0.2271851\ttest: 0.3831757\tbest: 0.3807590 (44)\ttotal: 2.64s\tremaining: 1m 23s\n",
      "70:\tlearn: 0.2176997\ttest: 0.3855218\tbest: 0.3807590 (44)\ttotal: 3.24s\tremaining: 1m 28s\n",
      "80:\tlearn: 0.2103990\ttest: 0.3895929\tbest: 0.3807590 (44)\ttotal: 3.68s\tremaining: 1m 27s\n",
      "90:\tlearn: 0.2051319\ttest: 0.3863172\tbest: 0.3807590 (44)\ttotal: 4.06s\tremaining: 1m 25s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.3807589708\n",
      "bestIteration = 44\n",
      "\n",
      "Shrink model to first 45 iterations.\n",
      "Top features\n",
      "line_number: 47.46017760127576\n",
      "number_number: 19.08619817236783\n",
      "len_2_lines: 15.23820905520163\n",
      "special_symbols: 12.233379491428808\n",
      "len_1_lines: 5.625499619455956\n",
      "symbol_number: 0.35653606027000295\n",
      "word_number: 0.0\n",
      "Predicting Model CatBoost\n",
      "X = (45, 7)\n",
      "\n",
      "Error roc-auc: 0.9196428571428571\n",
      "\n",
      "Fold = 2 / 4\n",
      "\n",
      "Training Model CatBoost\n",
      "X_train = (135, 7) Y_train = (135,)\n",
      "X_valid = (45, 7) Y_valid = (45,)\n",
      "\n",
      "Learning rate set to 0.047\n",
      "0:\tlearn: 0.6648246\ttest: 0.6691169\tbest: 0.6691169 (0)\ttotal: 27.8ms\tremaining: 55.7s\n",
      "10:\tlearn: 0.4583394\ttest: 0.4823915\tbest: 0.4823915 (10)\ttotal: 426ms\tremaining: 1m 17s\n",
      "20:\tlearn: 0.3630244\ttest: 0.3961633\tbest: 0.3961633 (20)\ttotal: 791ms\tremaining: 1m 14s\n",
      "30:\tlearn: 0.3294677\ttest: 0.3574230\tbest: 0.3574230 (30)\ttotal: 1.1s\tremaining: 1m 10s\n",
      "40:\tlearn: 0.3021959\ttest: 0.3367848\tbest: 0.3367848 (40)\ttotal: 1.48s\tremaining: 1m 10s\n",
      "50:\tlearn: 0.2782139\ttest: 0.3254959\tbest: 0.3254959 (50)\ttotal: 1.94s\tremaining: 1m 14s\n",
      "60:\tlearn: 0.2663392\ttest: 0.3138851\tbest: 0.3125200 (59)\ttotal: 2.27s\tremaining: 1m 12s\n",
      "70:\tlearn: 0.2560923\ttest: 0.3050165\tbest: 0.3050165 (70)\ttotal: 2.77s\tremaining: 1m 15s\n",
      "80:\tlearn: 0.2406724\ttest: 0.3010798\tbest: 0.3010798 (80)\ttotal: 3.19s\tremaining: 1m 15s\n",
      "90:\tlearn: 0.2339356\ttest: 0.3017113\tbest: 0.3002967 (88)\ttotal: 3.47s\tremaining: 1m 12s\n",
      "100:\tlearn: 0.2270145\ttest: 0.2967900\tbest: 0.2961885 (96)\ttotal: 3.83s\tremaining: 1m 12s\n",
      "110:\tlearn: 0.2155262\ttest: 0.2983810\tbest: 0.2961885 (96)\ttotal: 4.3s\tremaining: 1m 13s\n",
      "120:\tlearn: 0.2087353\ttest: 0.2994167\tbest: 0.2961885 (96)\ttotal: 4.65s\tremaining: 1m 12s\n",
      "130:\tlearn: 0.1977558\ttest: 0.2959736\tbest: 0.2959736 (130)\ttotal: 5.18s\tremaining: 1m 13s\n",
      "140:\tlearn: 0.1837664\ttest: 0.2940511\tbest: 0.2940511 (140)\ttotal: 5.64s\tremaining: 1m 14s\n",
      "150:\tlearn: 0.1684219\ttest: 0.2946836\tbest: 0.2926515 (147)\ttotal: 6.25s\tremaining: 1m 16s\n",
      "160:\tlearn: 0.1592737\ttest: 0.2962015\tbest: 0.2926515 (147)\ttotal: 6.83s\tremaining: 1m 18s\n",
      "170:\tlearn: 0.1465452\ttest: 0.2984819\tbest: 0.2926515 (147)\ttotal: 7.55s\tremaining: 1m 20s\n",
      "180:\tlearn: 0.1343948\ttest: 0.2993982\tbest: 0.2926515 (147)\ttotal: 8.24s\tremaining: 1m 22s\n",
      "190:\tlearn: 0.1220371\ttest: 0.3008025\tbest: 0.2926515 (147)\ttotal: 9.13s\tremaining: 1m 26s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.292651541\n",
      "bestIteration = 147\n",
      "\n",
      "Shrink model to first 148 iterations.\n",
      "Top features\n",
      "number_number: 26.81294895897652\n",
      "line_number: 25.71701520750655\n",
      "special_symbols: 17.297072727570594\n",
      "len_1_lines: 16.762646726428205\n",
      "len_2_lines: 10.766596025844176\n",
      "word_number: 2.643720353673991\n",
      "symbol_number: 0.0\n",
      "Predicting Model CatBoost\n",
      "X = (45, 7)\n",
      "\n",
      "Error roc-auc: 0.9412955465587045\n",
      "\n",
      "Fold = 3 / 4\n",
      "\n",
      "Training Model CatBoost\n",
      "X_train = (135, 7) Y_train = (135,)\n",
      "X_valid = (45, 7) Y_valid = (45,)\n",
      "\n",
      "Learning rate set to 0.047\n",
      "0:\tlearn: 0.6500733\ttest: 0.6608053\tbest: 0.6608053 (0)\ttotal: 41.2ms\tremaining: 1m 22s\n",
      "10:\tlearn: 0.4029425\ttest: 0.4781574\tbest: 0.4781574 (10)\ttotal: 408ms\tremaining: 1m 13s\n",
      "20:\tlearn: 0.3279337\ttest: 0.4417668\tbest: 0.4417668 (20)\ttotal: 684ms\tremaining: 1m 4s\n",
      "30:\tlearn: 0.2809740\ttest: 0.4247649\tbest: 0.4247649 (30)\ttotal: 1.01s\tremaining: 1m 4s\n",
      "40:\tlearn: 0.2527460\ttest: 0.4303961\tbest: 0.4247649 (30)\ttotal: 1.38s\tremaining: 1m 5s\n",
      "50:\tlearn: 0.2308918\ttest: 0.4443493\tbest: 0.4247649 (30)\ttotal: 1.87s\tremaining: 1m 11s\n",
      "60:\tlearn: 0.2204191\ttest: 0.4521337\tbest: 0.4247649 (30)\ttotal: 2.3s\tremaining: 1m 13s\n",
      "70:\tlearn: 0.2065828\ttest: 0.4649799\tbest: 0.4247649 (30)\ttotal: 2.76s\tremaining: 1m 15s\n",
      "80:\tlearn: 0.1990047\ttest: 0.4728020\tbest: 0.4247649 (30)\ttotal: 3.16s\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.4247648849\n",
      "bestIteration = 30\n",
      "\n",
      "Shrink model to first 31 iterations.\n",
      "Top features\n",
      "line_number: 43.33086547165911\n",
      "number_number: 34.321603947173216\n",
      "len_2_lines: 16.8988707210171\n",
      "len_1_lines: 4.688550350258051\n",
      "special_symbols: 0.7601095098925303\n",
      "word_number: 0.0\n",
      "symbol_number: 0.0\n",
      "Predicting Model CatBoost\n",
      "X = (45, 7)\n",
      "\n",
      "Error roc-auc: 0.8656126482213439\n",
      "\n",
      "Fold = 4 / 4\n",
      "\n",
      "Training Model CatBoost\n",
      "X_train = (135, 7) Y_train = (135,)\n",
      "X_valid = (45, 7) Y_valid = (45,)\n",
      "\n",
      "Learning rate set to 0.047\n",
      "0:\tlearn: 0.6623575\ttest: 0.6526215\tbest: 0.6526215 (0)\ttotal: 29.6ms\tremaining: 59.2s\n",
      "10:\tlearn: 0.4672718\ttest: 0.4432048\tbest: 0.4432048 (10)\ttotal: 387ms\tremaining: 1m 9s\n",
      "20:\tlearn: 0.3688638\ttest: 0.3614294\tbest: 0.3614294 (20)\ttotal: 838ms\tremaining: 1m 18s\n",
      "30:\tlearn: 0.3242066\ttest: 0.3256878\tbest: 0.3256878 (30)\ttotal: 1.25s\tremaining: 1m 19s\n",
      "40:\tlearn: 0.2878357\ttest: 0.2918571\tbest: 0.2918571 (40)\ttotal: 1.63s\tremaining: 1m 17s\n",
      "50:\tlearn: 0.2675928\ttest: 0.2707905\tbest: 0.2707905 (50)\ttotal: 2.05s\tremaining: 1m 18s\n",
      "60:\tlearn: 0.2565199\ttest: 0.2624421\tbest: 0.2613581 (58)\ttotal: 2.41s\tremaining: 1m 16s\n",
      "70:\tlearn: 0.2419571\ttest: 0.2594098\tbest: 0.2588170 (68)\ttotal: 2.96s\tremaining: 1m 20s\n",
      "80:\tlearn: 0.2357455\ttest: 0.2596532\tbest: 0.2588170 (68)\ttotal: 3.41s\tremaining: 1m 20s\n",
      "90:\tlearn: 0.2325551\ttest: 0.2564703\tbest: 0.2564703 (90)\ttotal: 3.73s\tremaining: 1m 18s\n",
      "100:\tlearn: 0.2187412\ttest: 0.2528713\tbest: 0.2520320 (97)\ttotal: 4.22s\tremaining: 1m 19s\n",
      "110:\tlearn: 0.2115092\ttest: 0.2577861\tbest: 0.2520320 (97)\ttotal: 4.59s\tremaining: 1m 18s\n",
      "120:\tlearn: 0.2039690\ttest: 0.2530964\tbest: 0.2520320 (97)\ttotal: 5.01s\tremaining: 1m 17s\n",
      "130:\tlearn: 0.1964346\ttest: 0.2470524\tbest: 0.2462629 (125)\ttotal: 5.41s\tremaining: 1m 17s\n",
      "140:\tlearn: 0.1886809\ttest: 0.2435327\tbest: 0.2435327 (140)\ttotal: 5.85s\tremaining: 1m 17s\n",
      "150:\tlearn: 0.1816305\ttest: 0.2468022\tbest: 0.2435327 (140)\ttotal: 6.35s\tremaining: 1m 17s\n",
      "160:\tlearn: 0.1692106\ttest: 0.2497136\tbest: 0.2435327 (140)\ttotal: 6.94s\tremaining: 1m 19s\n",
      "170:\tlearn: 0.1561341\ttest: 0.2472184\tbest: 0.2435327 (140)\ttotal: 7.63s\tremaining: 1m 21s\n",
      "180:\tlearn: 0.1462284\ttest: 0.2485904\tbest: 0.2435327 (140)\ttotal: 8.35s\tremaining: 1m 23s\n",
      "190:\tlearn: 0.1328126\ttest: 0.2524873\tbest: 0.2435327 (140)\ttotal: 9.07s\tremaining: 1m 25s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.2435326853\n",
      "bestIteration = 140\n",
      "\n",
      "Shrink model to first 141 iterations.\n",
      "Top features\n",
      "line_number: 35.85470557111673\n",
      "number_number: 27.164268319701492\n",
      "len_1_lines: 13.688892885095774\n",
      "len_2_lines: 12.440627692169096\n",
      "special_symbols: 10.39226294184759\n",
      "symbol_number: 0.2952075554487571\n",
      "word_number: 0.1640350346205265\n",
      "Predicting Model CatBoost\n",
      "X = (45, 7)\n",
      "\n",
      "Error roc-auc: 0.97165991902834\n",
      "\n",
      "Mean roc-auc error on CV: 0.9245527427378113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model CatBoost\n",
      "X = (20, 9)\n",
      "\n",
      "<class 'pandas.core.series.Series'>\n",
      "     probability  isVacancy\n",
      "129     0.791696          1\n",
      "2       0.006046          0\n",
      "138     0.908479          1\n",
      "66      0.019058          0\n",
      "76      0.039095          0\n",
      "22      0.471123          0\n",
      "108     0.769766          1\n",
      "96      0.029751          0\n",
      "100     0.923234          1\n",
      "19      0.006046          0\n",
      "13      0.034849          0\n",
      "8       0.037982          0\n",
      "171     0.938585          1\n",
      "182     0.082634          1\n",
      "118     0.778121          1\n",
      "151     0.897118          1\n",
      "125     0.861520          1\n",
      "14      0.006046          0\n",
      "50      0.158191          0\n",
      "97      0.861898          0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9292929292929293"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction = model.predict(test_feat).to_frame()\n",
    "test_prediction.columns = ['probability']\n",
    "\n",
    "print(type(test_feat.isVacancy))\n",
    "\n",
    "comparison = test_prediction.join(test_feat['isVacancy'])\n",
    "print(comparison)\n",
    "roc_auc_score(test_feat['isVacancy'], test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save_model(\"ClassifierModel\",format=\"cbm\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message recognition by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f4e904bdac8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classifier = CatBoostClassifier()\n",
    "#classifier.load_model(\"ClassifierModel\", format='catboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_messages_clear_w_dt.json\",'r') as fin:\n",
    "    msg_df = pd.read_json(fin, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features_vectorized = lambda x: get_features(x, special_symbols)\n",
    "\n",
    "msg_feat = msg_df.apply(get_features_vectorized, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model CatBoost\n",
      "X = (2431, 9)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msg_df['probability'] = model.predict(msg_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"user_messages_clear_w_dt_p.json.json\",'w') as fout:\n",
    "    msg_df.to_json(fout, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_features(msg, special_symbols):\n",
    "        \n",
    "    cols = ['id',\n",
    "            'order_number',\n",
    "            'symbol_number', \n",
    "            'word_number',  \n",
    "            'number_number', \n",
    "            'len_1_lines', \n",
    "            'len_2_lines', \n",
    "            'special_symbols',\n",
    "            'msg_probability',\n",
    "            'isSalary']\n",
    "    \n",
    "    lines = msg['message'].splitlines()\n",
    "    \n",
    "    lines_feat_df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "    \n",
    "        feat_df = pd.Series(0, index=cols)\n",
    "    \n",
    "        feat_df['id'] = msg['index']\n",
    "        \n",
    "        feat_df['order_number'] = i\n",
    "    \n",
    "        feat_df['symbol_number'] = len(line)\n",
    "        words = re.split(' |;|,|\\*|\\n|\\t', line)\n",
    "    \n",
    "        feat_df['word_number'] = len(words)\n",
    "        \n",
    "        feat_df['number_number'] = len(re.findall(r'[0-9]+', line))\n",
    "    \n",
    "        feat_df['len_1_lines'] = len([x for x in words if len(x) == 1])\n",
    "    \n",
    "        feat_df['len_2_lines'] = len([x for x in words if len(x) == 2])\n",
    "    \n",
    "        for symbol in special_symbols:\n",
    "            feat_df['special_symbols'] += line.upper().count(symbol)\n",
    "        \n",
    "        if not np.isnan(msg['salary_line']):\n",
    "            feat_df['msg_probability'] = 1\n",
    "        \n",
    "        if i == msg['salary_line']:\n",
    "            feat_df['isSalary'] = 1\n",
    "                \n",
    "        lines_feat_df = lines_feat_df.append(feat_df, ignore_index=True)\n",
    "        \n",
    "   # print(lines_feat_df)\n",
    "    return lines_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"salary_posts.json\",'r') as fin:\n",
    "    train_true = pd.read_json(fin, compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"non_salary_posts.json\",'r') as fin:\n",
    "    train_false = pd.read_json(fin, compression=None, orient='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.concat([train_true, train_false], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'order_number', 'symbol_number', 'word_number', 'number_number',\n",
      "       'len_1_lines', 'len_2_lines', 'special_symbols', 'msg_probability',\n",
      "       'isSalary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cols = ['id',\n",
    "            'order_number',\n",
    "            'symbol_number', \n",
    "            'word_number',  \n",
    "            'number_number', \n",
    "            'len_1_lines', \n",
    "            'len_2_lines', \n",
    "            'special_symbols',\n",
    "            'msg_probability',\n",
    "            'isSalary']\n",
    "\n",
    "lines_feat_ready = pd.DataFrame(columns=cols)\n",
    "\n",
    "print(lines_feat_ready.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/200 [00:00<00:26,  7.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 2/200 [00:00<00:24,  8.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 3/200 [00:00<00:28,  6.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 4/200 [00:00<00:26,  7.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▎         | 5/200 [00:00<00:34,  5.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 6/200 [00:00<00:34,  5.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 7/200 [00:01<00:52,  3.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 9/200 [00:01<00:40,  4.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 11/200 [00:01<00:33,  5.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 12/200 [00:02<00:46,  4.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 14/200 [00:02<00:50,  3.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 15/200 [00:03<00:48,  3.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 16/200 [00:03<00:47,  3.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 17/200 [00:03<00:39,  4.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 18/200 [00:03<00:43,  4.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|▉         | 19/200 [00:03<00:38,  4.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 20/200 [00:04<00:34,  5.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 21/200 [00:04<00:31,  5.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 22/200 [00:04<00:43,  4.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 23/200 [00:04<00:36,  4.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 24/200 [00:04<00:31,  5.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 26/200 [00:05<00:26,  6.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▎        | 27/200 [00:05<00:23,  7.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 28/200 [00:05<00:27,  6.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 30/200 [00:05<00:24,  6.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 31/200 [00:05<00:29,  5.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 32/200 [00:05<00:26,  6.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|█▋        | 33/200 [00:06<00:35,  4.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|█▋        | 34/200 [00:06<00:32,  5.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 36/200 [00:06<00:26,  6.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|█▊        | 37/200 [00:06<00:25,  6.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|█▉        | 38/200 [00:06<00:25,  6.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|█▉        | 39/200 [00:07<00:28,  5.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 41/200 [00:07<00:21,  7.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 43/200 [00:07<00:21,  7.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▏       | 44/200 [00:07<00:20,  7.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|██▎       | 45/200 [00:07<00:19,  7.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|██▎       | 46/200 [00:07<00:21,  7.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▎       | 47/200 [00:08<00:21,  7.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 48/200 [00:08<00:23,  6.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|██▍       | 49/200 [00:08<00:24,  6.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 50/200 [00:08<00:22,  6.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 51/200 [00:08<00:22,  6.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▌       | 52/200 [00:08<00:22,  6.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██▋       | 53/200 [00:09<00:22,  6.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██▋       | 54/200 [00:09<00:24,  5.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 55/200 [00:09<00:29,  4.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 56/200 [00:09<00:25,  5.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██▊       | 57/200 [00:09<00:23,  5.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|██▉       | 58/200 [00:09<00:24,  5.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|██▉       | 59/200 [00:10<00:26,  5.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 60/200 [00:10<00:24,  5.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 61/200 [00:10<00:45,  3.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|███       | 62/200 [00:11<00:35,  3.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 63/200 [00:11<00:43,  3.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▏      | 64/200 [00:11<00:37,  3.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███▎      | 65/200 [00:12<00:37,  3.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|███▎      | 66/200 [00:12<00:32,  4.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 68/200 [00:12<00:31,  4.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|███▍      | 69/200 [00:12<00:29,  4.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 70/200 [00:12<00:27,  4.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███▌      | 72/200 [00:13<00:24,  5.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|███▋      | 74/200 [00:13<00:20,  6.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 75/200 [00:13<00:19,  6.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 76/200 [00:13<00:19,  6.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███▉      | 78/200 [00:13<00:15,  8.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 80/200 [00:14<00:15,  7.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 81/200 [00:14<00:16,  7.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████▏     | 83/200 [00:14<00:13,  8.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████▎     | 85/200 [00:14<00:12,  9.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▎     | 87/200 [00:15<00:19,  5.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████▍     | 88/200 [00:15<00:18,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 90/200 [00:15<00:17,  6.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 91/200 [00:15<00:16,  6.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▌     | 92/200 [00:16<00:16,  6.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|████▋     | 93/200 [00:16<00:15,  6.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|████▋     | 94/200 [00:16<00:14,  7.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 96/200 [00:16<00:12,  8.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|████▊     | 97/200 [00:16<00:15,  6.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████▉     | 98/200 [00:16<00:17,  5.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|████▉     | 99/200 [00:17<00:27,  3.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 100/200 [00:18<00:40,  2.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████▎    | 105/200 [00:18<00:27,  3.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▍    | 109/200 [00:18<00:19,  4.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████▋    | 113/200 [00:18<00:13,  6.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████▊    | 117/200 [00:18<00:11,  7.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 120/200 [00:18<00:08,  8.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▏   | 123/200 [00:19<00:07,  9.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▎   | 125/200 [00:19<00:06, 10.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████▎   | 127/200 [00:19<00:05, 12.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████▌   | 131/200 [00:19<00:04, 15.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████▊   | 135/200 [00:19<00:03, 18.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 140/200 [00:19<00:02, 23.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████▏  | 144/200 [00:19<00:02, 22.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████▍  | 148/200 [00:20<00:02, 19.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████▋  | 153/200 [00:20<00:02, 22.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|███████▊  | 157/200 [00:20<00:01, 24.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|████████  | 162/200 [00:20<00:01, 25.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████▎ | 167/200 [00:20<00:01, 29.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████▌ | 171/200 [00:20<00:00, 29.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 175/200 [00:20<00:00, 30.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 180/200 [00:21<00:00, 30.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|█████████▏| 184/200 [00:21<00:00, 23.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|█████████▎| 187/200 [00:21<00:00, 22.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████▌| 192/200 [00:21<00:00, 26.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████▊| 196/200 [00:21<00:00, 21.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████▉| 199/200 [00:22<00:00, 23.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 200/200 [00:22<00:00,  9.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#get_line_features_vectorized = lambda x: get_line_features(x, special_symbols)\n",
    "#append_vectorized = lambda x,y: pd.concat([x,y.apply(get_line_features_vectorized, axis=1)], ignore_index=True)\n",
    "\n",
    "for i in tqdm(train_feat.index):\n",
    "    lines_feat_cur = get_line_features(train_feat.iloc[i], special_symbols)\n",
    "    lines_feat_ready = lines_feat_ready.append(lines_feat_cur, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_model = Model_ctbst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['order_number',\n",
    "         'symbol_number', \n",
    "         'word_number',  \n",
    "         'number_number', \n",
    "         'len_1_lines', \n",
    "         'len_2_lines', \n",
    "         'special_symbols',\n",
    "         'msg_probability']\n",
    "target = ['isSalary']\n",
    "\n",
    "line_trainer = Trainer(model=line_model,  train_type='cross-validation', target=target, \n",
    "                  features=feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(lines_feat_ready['isSalary'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_division = lambda x: (x.iloc[:4*len(x.index)//5], x.iloc[4*len(x.index)//5:])\n",
    "(train_line_feat, test_line_feat) = train_test_division(lines_feat_ready.sample(frac=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7073, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_line_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with cross-validation\n",
      "\n",
      "Train with cross-validation...\n",
      "\n",
      "Cross-validation 4 folds\n",
      "\n",
      "Fold = 1 / 4\n",
      "\n",
      "Training Model CatBoost\n",
      "X_train = (5304, 8) Y_train = (5304,)\n",
      "X_valid = (1769, 8) Y_valid = (1769,)\n",
      "\n",
      "Learning rate set to 0.069103\n",
      "0:\tlearn: 0.5801831\ttest: 0.5798438\tbest: 0.5798438 (0)\ttotal: 64.7ms\tremaining: 2m 9s\n",
      "10:\tlearn: 0.1698792\ttest: 0.1677062\tbest: 0.1677062 (10)\ttotal: 679ms\tremaining: 2m 2s\n",
      "20:\tlearn: 0.1056701\ttest: 0.1006101\tbest: 0.1006101 (20)\ttotal: 1.28s\tremaining: 2m 1s\n",
      "30:\tlearn: 0.0789196\ttest: 0.0702788\tbest: 0.0702788 (30)\ttotal: 2.14s\tremaining: 2m 15s\n",
      "40:\tlearn: 0.0705390\ttest: 0.0604997\tbest: 0.0604997 (40)\ttotal: 3.04s\tremaining: 2m 25s\n",
      "50:\tlearn: 0.0682372\ttest: 0.0581574\tbest: 0.0581574 (50)\ttotal: 3.74s\tremaining: 2m 22s\n",
      "60:\tlearn: 0.0664694\ttest: 0.0564850\tbest: 0.0564850 (60)\ttotal: 4.72s\tremaining: 2m 30s\n",
      "70:\tlearn: 0.0651854\ttest: 0.0552228\tbest: 0.0552228 (70)\ttotal: 5.56s\tremaining: 2m 30s\n",
      "80:\tlearn: 0.0635619\ttest: 0.0542862\tbest: 0.0542862 (80)\ttotal: 6.44s\tremaining: 2m 32s\n",
      "90:\tlearn: 0.0620121\ttest: 0.0537600\tbest: 0.0537600 (90)\ttotal: 7.37s\tremaining: 2m 34s\n",
      "100:\tlearn: 0.0608514\ttest: 0.0535454\tbest: 0.0534584 (94)\ttotal: 8.31s\tremaining: 2m 36s\n",
      "110:\tlearn: 0.0592779\ttest: 0.0538376\tbest: 0.0534584 (94)\ttotal: 9.34s\tremaining: 2m 38s\n",
      "120:\tlearn: 0.0586981\ttest: 0.0538074\tbest: 0.0534584 (94)\ttotal: 10.3s\tremaining: 2m 39s\n",
      "130:\tlearn: 0.0576179\ttest: 0.0538611\tbest: 0.0534584 (94)\ttotal: 11.3s\tremaining: 2m 41s\n",
      "140:\tlearn: 0.0559834\ttest: 0.0538434\tbest: 0.0534584 (94)\ttotal: 12.5s\tremaining: 2m 44s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.05345835944\n",
      "bestIteration = 94\n",
      "\n",
      "Shrink model to first 95 iterations.\n",
      "Top features\n",
      "symbol_number: 21.01847028647656\n",
      "msg_probability: 18.372911718981225\n",
      "order_number: 16.561480860694584\n",
      "special_symbols: 13.331682219887766\n",
      "word_number: 11.041578219971372\n",
      "len_2_lines: 10.768544634760513\n",
      "number_number: 5.9588145141456526\n",
      "len_1_lines: 2.946517545082367\n",
      "Predicting Model CatBoost\n",
      "X = (1769, 8)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (0       0\n1       0\n2       0\n3       0\n4       0\n5       0\n6       0\n7       0\n8       0\n9       0\n10      0\n11      0\n12      0\n13      0\n14      0\n15      0\n16      0\n17      0\n18      0\n19      0\n20      0\n21      0\n22      0\n23      0\n24      0\n25      0\n26      0\n27      0\n28      0\n29      0\n       ..\n1739    0\n1740    0\n1741    0\n1742    0\n1743    0\n1744    0\n1745    0\n1746    0\n1747    0\n1748    0\n1749    0\n1750    0\n1751    0\n1752    0\n1753    0\n1754    0\n1755    0\n1756    0\n1757    0\n1758    0\n1759    0\n1760    0\n1761    0\n1762    0\n1763    1\n1764    0\n1765    0\n1766    0\n1767    0\n1768    0\nName: isSalary, Length: 1769, dtype: object,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-3b93d063209b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mline_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_line_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-286-a9b67aa53a17>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_with_validation_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cross-validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_with_cross_validation_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error: unknown train type = %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-286-a9b67aa53a17>\u001b[0m in \u001b[0;36m_train_with_cross_validation_\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_fold_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_fold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mpred_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_basic_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean %s error on CV: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-286-a9b67aa53a17>\u001b[0m in \u001b[0;36m_train_basic_\u001b[0;34m(self, train, valid)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mpred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_error_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error %s: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-286-a9b67aa53a17>\u001b[0m in \u001b[0;36m_get_error_\u001b[0;34m(self, Y, P)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logloss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'roc-auc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rancher/.local/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2126\u001b[0m         \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2127\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2128\u001b[0;31m         \u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rancher/.local/lib/python3.7/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rancher/.local/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (0       0\n1       0\n2       0\n3       0\n4       0\n5       0\n6       0\n7       0\n8       0\n9       0\n10      0\n11      0\n12      0\n13      0\n14      0\n15      0\n16      0\n17      0\n18      0\n19      0\n20      0\n21      0\n22      0\n23      0\n24      0\n25      0\n26      0\n27      0\n28      0\n29      0\n       ..\n1739    0\n1740    0\n1741    0\n1742    0\n1743    0\n1744    0\n1745    0\n1746    0\n1747    0\n1748    0\n1749    0\n1750    0\n1751    0\n1752    0\n1753    0\n1754    0\n1755    0\n1756    0\n1757    0\n1758    0\n1759    0\n1760    0\n1761    0\n1762    0\n1763    1\n1764    0\n1765    0\n1766    0\n1767    0\n1768    0\nName: isSalary, Length: 1769, dtype: object,)"
     ]
    }
   ],
   "source": [
    "line_trainer.train(train_line_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
